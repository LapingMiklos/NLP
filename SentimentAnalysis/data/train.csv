ID,review,decision
0,"The study presents a compelling approach to enhancing the diagnosis of Chronic Kidney Disease (CKD) using a data-driven method. By utilizing the MIMIC IV, a large, open-source database of electronic health records (EHRs), the research employs ML techniques to determine best approach to assess the risk of CKD. 

The methodology is comprehensive, incorporating patient-specific demographic data, vital signs, and past medical history to predict CKD status accurately. The authors meticulously detail their data sources, the process of pre-processing, and the strategies employed to handle missing data, showcasing a robust methodological framework. The training and test datasets are balanced across CKD disease stages, which is crucial for the reliability of the predictive models. The authors statistical analysis is sound and supported by clear tables and figures.

They show that the Random Forest Classifier was identified to have the best performance, achieving an accuracy (0.875), an  Area Under the Receiver Operating Characteristic Curve (0.927), and a F-1 score (0.765). These results supports authors conclusion that the  random forest CDK classifier algorithm maybe effective in identifying patients at risk of CKD, particularly those who may be under-diagnosed due to health disparities.

While the study is not about foundation models, the authors demonstrate and remind us of that simple algorithm maybe sufficient to solve pervasive healthcare problems.",1
1,"This paper studies the problem of PAC learning of multi-class function classes using proper learners. The paper shows that, unlike the improper learning case where the Daniely-Shalev-Shwartz (DS) dimension completely characterizes learnability, the learnability in the proper learning case can be more complex. In particular, the paper demonstrates the following:

1. If we are given the underlying distribution over $\mathcal{X}$ and assume the label is realizable, then the optimal sample complexity is achievable by a randomized proper learner (i.e., a Bayesian learner) up to a factor of $2$. This is achieved by representing the learning problem as a two-player zero-sum game and showing that the Bayesian learner attains an error up to only a factor of $2$ of the optimal error for any given prior over $\mathcal{H}$. The final Bayesian predictor then follows by invoking the minimax theorem.

2. The paper shows that there exists a class $\mathcal{H}$ such that its proper learnability is undecidable under ZFC. The construction follows from a simple manipulation of the EMX instance from Ben-David et al. (2019).

3. Finally, the paper shows that proper learnability is non-local and not monotone. This is achieved by augmenting a special function to the class constructed in point 2.

**Assessment:** This is clearly a solid paper and well within the scope of ALT. I find the results to be interesting and non-trivial. On the other hand, many of the proof ideas are not particularly surprising, e.g., the idea of expressing the proper learning problem as a zero-sum game has appeared in Darnstadt and Simon (2011), and the construction of hard instances follows too closely to Ben-David et al. (2019). However, as far as I know, these constructions are new.

Overall, I'm leaning toward accepting this paper. I also have some technical questions outlined below, which I hope the authors can address.

**Questions:**

1. (Major) I did not quite follow your proof of Lemma 25 (modulo the many typos), even after reading the reference in (Asilis et al., 2024b). Particularly, why is it true that ""the transductive error incurred by B on S is equal to precisely the expected error incurred by A...""? From what I understand, the PAC error bound of $A$ is evaluated over $\text{Unif}(S)$, not the particular $x_{\text{test}}$. For example, if learner $A$ simply memorizes $S'$, its population error under $\text{Unif}(S)$ is upper bounded by $\frac{1}{n+1}$.

   I recommend the authors provide a step-by-step derivation of these claims, particularly writing explicitly the errors for $A$ and $B$ using mathematical formulas, not words.

2. (Minor) It seems your Theorem 13 holds only in expectation. What about high-probability sample complexity? (The repetition trick can only give an upper bound.)

3. (Minor) The hard instance in Proposition 20 uses uncountable labels. What if the label space is countable? Is it still impossible with a finite-dimensional measure to charaterizes the proper learnability?

4. (Minor) Can you provide any intuition as to why you believe Conjecture 16 is true?",1
2,"## Paper summary

The task of predicting whether a reddit user who first starts posting on Anxiety subreddits will later also start posting on ADHD subreddits is used as a proxy for identifying people with anxiety who might also have ADHD. Classification performance of a fine-tuned RoBERTa model is presented which is shown to be better than keyword based baselines. Some explainability experiments are promised in the future.

### Strengths
1. Misdiagnosed comorbid ADHD is an important issue.
1. Data collection and processing is sound -- the 6 month gap in user postage history between their first post in ADHD subreddits and the data gathered from anxiety subreddits is a reasonable choice.

### Weaknesses
1. The authors have acknowledged the weaknesses and assumptions in the proxy task -- subreddit posting behavior is a very weak link to whether the user actually has a high risk of having comorbid ADHD. There seems to be no method for verifying the link between this proxy task and actual comorbid ADHD.
1. The practical benefits of how the proposed study can better enable diagnosis of comorbid ADHD in the future is not discussed.

### Feedback to authors
* In order to refine the ground truth for the proxy task, a Chat-GPT or equivalent LLM can be used to query whether the user believes that they have ADHD and/or anxiety from their posts alone. This may clean up the collected data significantly.",-1
3,"Pros:
---
- I am a big fan of this idea. Correcting the gradient for sparse training is novel and well-motivated.
- The paper provides not only empirical results but also theoretical analysis.
-  The writing is lucid, and the paper is well-structured.
- Though AGENT inevitably adds extra FLOPs, which seems contradictory to the efficiency goal of sparse training, the authors offer potential solutions to this concern.

Cons:
---
- Formatting requires further polishing, e.g., a missing period before ""However"" in line 84. Also, the first letter be capitalized in figure 1 but not in other figures.
- I am curious if AGENT also improves the gradient norm which is important for sparse training as mentioned in [1].
- It would be intriguing to see experiments conducted on larger scale models or datasets, for example, the ViT model on ImageNet.

[1] Gradient Flow in Sparse Neural Networks and How Lottery Tickets Win, AAAI. U Evci. et al.",1
4,"This paper investigates online mistake-bound learning under the constraint that the learning rule must be computable. This is a natural and basic question in learning theory. 

The authors introduce a computable variant of the Littlestone dimension, adapting the concept of effective dimensions specifically for online learning settings. They demonstrate that finite effective Littlestone dimension is necessary, though not sufficient, for computable online learning, and identify specific cases where it characterizes the optimal mistake bound. Furthermore, they establish that finite effective Littlestone dimension guarantees that the class consists only of computable functions.

The paper is well-written, with clear explanations and proofs that appear correct.

However, I believe the basic setting of (computable) online learning and the definition of online learnability are not satisfactorily addressed. The authors define a class as online learnable if there exists an absolute finite bound on mistakes, regardless of input sequence length. From a learning theory perspective, it’s more natural to consider settings where the number of mistakes is sublinear in the sequence length, with the learner aware of the “horizon” or length of the sequence. Indeed, Littlestone’s classical result provides a dichotomy: either the adversary can force Omega(|S|) mistakes when the class is not learnable, or the learner can guarantee O(1) mistakes when it is. However, I don’t think the dichotomy in this theorem should dictate the definition of online learnability, which should instead account for sublinear mistake bounds.

Will relaxing the definition of online learnability in this way affect the impossibility result? Could it be that, with this definition, the effective Littlestone dimension fully characterizes online learnability?

Additionally, considering randomized learners and whether the adversary should be restricted to be computable might lead to a more complete theory of computable online learning in this context.",1
5,"The study conducted benchmarking to demonstrate progress in both computational complexity and prediction accuracy by combining group convolution with hyperparameter optimizations, which is a strength of this paper. However, the authors' claim of a reduction of N-MSE from 0.054 to 0.031 should be clarified. It appears that the benefit of reduction by introducing the group convolution should be calculated as the reduction from 0.043 to 0.031, resulting in a 27.9% reduction, especially concerning the same number of Fourier layers (i.e., block) used.

While the theoretical aspects are clear, the paper lacks clarity regarding the practical memory efficiency gained during actual computations. However, the dataset and problem are well-defined, aiding understanding.

The authors justify its originality in combining group convolution with the F-FNO architecture. This approach contributes to the field by proposing a novel method for addressing computational efficiency and prediction accuracy simultaneously.

The use of the proposed method can enhance prediction accuracy and computational efficiency, as demonstrated in the study. The performance improvements observed in a case study involving Maxwell's equations in the nanophotonic structure domain underscore the importance of accelerating FNO to other scientific domains governed by partial differential equations (PDEs). However, it remains unclear whether the proposed architecture can achieve similar improvements in prediction accuracy across other domains, which warrants further investigation.",1
6,"The paper is well written, particularly in its coverage of background, motivation, and experimental details. The experiments are thorough and well-detailed. However, it is unclear in the explanation of the entire loss function, which is not explicitly outlined.

While the idea of weighting and/or adjusting the residual term is not novel, the proposed approach shows its simplicity and effectiveness. However, it remains unclear whether the proposed method outperforms the effectiveness of the approach discussed in the referenced paper by Liu et al. (2024), which introduced gradient-dependent weights to capture solutions of PDEs. A clearer comparison with existing methods would strengthen the originality aspect of the paper.

The promising results observed in both discrete and continuous experiments highlight the potential effectiveness of the proposed solution. Particularly the proposed weight scheme is effective especially in scenarios where the reaction rate coefficient is smaller. However, the authors fall short in providing a benchmarking case that demonstrates the importance of solving the addressed problem using the proposed solution compared to other existing PINN approaches. Clarifying the extent to which the weighting scheme enhances PINN capabilities would help the significance of the contribution.",1
7,"Summary:

This paper introduces Diffusion-based methods into Amodal Instance segmentation for the first time. By leveraging the shape knowledge, the authors propose Diffusion Shape Prior Estimation (DiffSP) to estimate the potential shape knowledge of various object for amodal mask prediction. Moreover, the proposed method can be applied on various detectors and show the effectiveness on three different datasets. 


Strength:

1, The first work that explores the diffusion model for amodal segmentation and mask prediction.

2, The motivation is clear since diffusion models are pre-trained with huge object level data which can be used to predict missing masks or shape of amodal objects.

3, The overall writing is good and easy to understand.

4, The proposed method achieves consistent improvements on various detectors and datasets, which is convincing to me.


Weakness:

1, Missing analysis on computation cost or run time analysis. 

2, Better to show different diffusion model’s effects, such as Stable-XL.",1
8,"This paper introduces a deep learning methodology to optimize energy recovery in reservoir management by addressing the computational challenges of traditional numerical simulations. The proposed approach utilizes a neural operator in Fourier space to more efficiently predict fluid flow behaviors, significantly reducing computational time from hours to seconds. The authors evaluate the methodology on simulations of steam injection in high-viscosity oil reservoirs.

In general, the present study is of interest for the reservoir energy management and machine learning communities. Although the aim of the paper is clearly defined in the manuscript, it does so repeatedly on different sections. The text can be substantially improved. Particularly, the manuscript can substantially benefit from a clearer structure and logic, as well as avoiding repetitive details. Moreover, the result section clearly lacks a proper description of the results (e.g., highlighting key findings), and the actual analysis is quite limited (e.g., different metrics and diagnostics to evaluate the performance of the ML model would be desired). The theoretical concepts are vaguely presented in the main text. Although further details are described in the appendix, they are not linked with the main text. The figures and the experiments are in general poor, e.g., missing units and confusion between what is a numerical model and different simulations. The results barely support the conclusions (i.e., further analyses and diagnostics are required). Finally, the manuscript lacks a proper discussion to put this work into a broader context, as well as to highlight the limitations of this approach and potential future work. 

Specific comments:
- Introduction section. In general, references to support the description of the previous work is missing. Moreover, what are those “handful of ML-based surrogate approaches”?
- Introduction section. The description about the approach of this work does not belong here, and is repeated later on.
- Objective section. This can be a couple of sentences at the end of the introduction, therefore, saving quite same text for better describing the results.
- Simulation of the steam injection process section. Currently the text is misleading. I understand that the authors are using just one physical model (CMG STARS) with 5 different setups and running one simulation for each configuration. If this is the case, there are not five different models to train the ML algorithms, but rather 5 different simulations with specific set of properties. Please, clarify and point to the appendix for a detailed description of the physical model.
- Neural network architecture section. A minimum information about the DNN architecture is required to understand the method, and therefore, the results. Pointing to the original paper is not enough.
- Results and discussion section. This section needs to be extended substantially. By re-writing the former sections and avoiding repeating information, this section should present and discuss (currently is lacking) the results in greater detail. For example, different metrics and diagnostics to evaluate the performance of the ML model would be desired.
- Conclusion section. Although a summary of the results is presented, this section may be missing a discussion about the limitation of the present approach and potential future work.",-1
9,"### Summary:
A guided autoregressive diffusion model is introduced to forecast and assimilate PDE dynamics. The model makes use of conditional frames that provide context of the problem and can be trained on short slices of long sequences.

### Strengths:
- Very appealing to see that GuARD benefits from more context frames that are provided (i.e., using higher Markov orders). This actually matches people's intuition, but seems not to be the case for Amortized.
- Detailed information in the appendix (I did not check it thoroughly)

### Weaknesses
- Despite the concrete second paragraph of the introduction, I could not quite extract the contribution and novelty of this work. Can you elaborate more specifically what is new and in what way?
- GuARD only marginally improves over the standard Amortized technique. Nevertheless, GuARD is faster and slightly better.

### Questions:
1. Is $x(0)$ the noise-free state? Maybe make more explicit in the **Continuous-time diffusion models** paragraph.
2. How it the density $p_t$ of $x(t)$ calculated, or what does it concretely represent?
3. How do Langevin Monte Carlo (corrector) steps look like?
4. In Figure 2, bottom right, why is the Amortized AR model worse if conditioning on many frames an producing a single frame (1|8) than when conditioning on a single frame and producing many frames (8|1)? At the same time, why is GuARD worse than Amortized in the (7|2) configuration?

### Minor comments:
- Equal sign missing before $\Pi$ in second line of page 3?",1
10,"I found the idea straight forward and the work was carried out well. Sections on interfacing with simulators and formal methods are a little dry and can be cut shorter to talk more about limitations, adaptations to new domains, next steps, etc.",1
11,"Summary:

This paper considers the problem of self-directed node classification in graphs, where the learner can select a node to classify in each round. This paper mainly considers the unknown labeling of nodes is a convex bipartition (or halfspace) and also generalizes to the nearly convex and convex k labeling. Here, the labeling is called convex iff for any two nodes $u,v$ have the same label, the nodes on the shortest path between u and v have the same label. Ben-David et al. (1997) showed that the halving algorithm makes $O(h(G) \ln n)$ mistakes for convex bipartition. However, this algorithm is not computationally efficient. Here, $h(G)$ the Hadwiger number of $G$, which is the size of the largest clique minor in $G$.

The paper introduces a polynomial time algorithm, GOOD4, which is shown to achieve a mistake bound of $3(h(G)+1)^4 \ln n$ for graphs with two convex clusters. The algorithm is also robust in cases where clusters are nearly convex. The labeling is $M^*$ nearly convex if by flipping at most $M^*$ labels of nodes, the labeling can be converted to convex. They show that this algorithm achieves a $3(h(G)+1)^4 \ln n + 4M^*$ mistake bound. They also provide an algorithm for the multi-class classification.  Additionally, the paper presents lower bounds on the number of mistakes for certain graph families and explores the problem in the context of homophilic labeling.
 
Pros:

(1) The proposed algorithm, GOOD4, achieves polynomial runtime with mistake bounds that scale well, particularly for graphs with bounded Hadwiger numbers. The algorithm is surprisingly easy to implement and achieves a good mistake bound (close to the previous bound by the halving algorithm, which is not efficient. ). 

(2) The algorithm’s robustness to nearly convex labelings, with mistake bounds that account for minor deviations from convexity, enhances its applicability. The paper also covers extensions to more complex 𝑘 k-labeling scenarios, expanding the relevance of the algorithm to a wider range of labeling structures. 

(3) The analysis of lower bounds on mistakes for various graph families provides the theoretical understanding of self-directed node classification.

Cons:

(1) The mistake bound achieved by GOOD4, $3(h(G)+1)^4 \ln n$, is significantly higher than the $O(h(G) \ln n)$ bound of the halving algorithm, particularly for graphs where the Hadwiger number $h(G)$ is large. This difference stems from the $h(G)^4$ factor in GOOD4’s bound, which can lead to considerably more mistakes in graphs with high Hadwiger number, $h(G)$.

Minors:

(1) Algorithm Line 18: It should be if $\hat{y}_c \neq y(c)$.

(2) Proposition 11: two learning typo

(3) Appendix A, Observation 7 proof, use definition 5 instead of observation 7.",1
12,"### Summary:
An explainable DDPM is introduced to learn relevant components in three different tasks. Compared to other baselines, xDDPM is superior, yet several points remain unclear to me, as detailed below.

Overall, the paper organization and structure would benefit largely from a focus on nailing down the task concretely (what is the model supposed to produce) and describing how xDDPM accomplishes it.

### Strengths:
- Link to code and resources provided (not carefully checked, though)
- Nice to see how xDDPM finds the 

### Weaknesses
- Given that ""Random"" is superior to many other methods, it appears unclear how suitable the other methods are in solving this task. Aren't there other methods in the literature that are better suited and allow for a stronger competition?
- The same argument also holds for the chosen metrics. For example, how does IoU measure whether the method extracts relevant components $S$ of the signal $X$? Also, it is unclear what goes into the metrics. Do you evaluate the generated mask $M$ or the actual output of your method?
- Unclear what price xDDPM introduces to the performance. That is, how accurate is xDDPM compared to DDPM in, e.g., fluid flow forecasting?
- Experiments is extremely vague/short and results section is missing.
- It remains unclear to me, how the method performs and what it is actually supposed to produce as output.

### Questions:
1. How does the forcing around the jelly fish-like robot look like in a normal DDPM?
2. How is mutual information, denoted as $I(\cdot;\cdot)$ defined?
3. What does $S$ represent intuitively? The pixels that change the most, or parts in the signal that effect other parts, or something completely different? Maybe you can provide some handy examples.
4. Wouldn't a baseline already perform well that computes parts in the scene that change least?

### Minor comments:
- Figures seem to lap over the left margin. Maybe correct for improved presentation.",-1
13,"In this paper, the authors proposed a novel approach to understanding complex simulations by learning high-level causal explanations from low-level models.
It is a well-organized paper containing an algorithm and diagrams to help the readers understand the proposed scheme. Moreover, it contains the limitations and future work parts.
However, a comparison with existing methods is unavailable. Comparison with the latest and existing work will highlight the benefits of the proposed method and help the readers understand different aspects of the proposed method.",1
14,"The paper is less clear in describing how PINNs-JAX contributes to speeding up processes beyond incorporating Hydra. A clearer delineation of the novel aspects of the work should be highlighted. Additionally, it remains unclear whether the authors made improvements to the JAX compiler. But, in general, the development of a computational library optimizing PINNs addresses an important problem and has the potential to benefit the entire community. Highlighting the unique contributions of PINNs-JAX and clarifying any enhancements to the JAX compiler would enhance the quality of the work.

The study conducts a comprehensive benchmarking of standard DNN libraries for various PINN applications, thereby raising awareness within the community regarding the trade-offs between speed and model sizes. Furthermore, it provides insights into the further development of DNN libraries. However, it remains unclear how PINNs-JAX differs from the performance achieved by the original JAX library. Addressing this aspect would improve the significance of PINNs-JAX proposed in this study in the context of existing libraries and contribute to a clearer understanding of its potential impact.",-1
15,"This paper analyzes Genomic Foundation Models' effectiveness in gene pathogenicity prediction, highlighting Nucleotide Transformer's superior performance. It showcases the potential of direct genomic sequence classification, offering a significant advancement over traditional methods. The study is innovative and has a practical impact but lacks broad model evaluation, external validation, and discusses potential biases minimally.

**Pros**
- Innovative Approach: The paper pioneers in evaluating Genomic Foundation Models for gene pathogenicity prediction, showcasing a significant shift from traditional methods.
- Comprehensive Benchmarking: It rigorously benchmarks across different models, providing a detailed comparison of their performance on a widely recognized dataset.

**Cons**
- Model Specificity: The study's focus on a limited number of models might not capture the full spectrum of potential genomic foundational models.
- Dataset Limitations: Reliance on the ClinVar dataset alone could introduce bias or limit the generalizability of the findings across different genomic contexts.
- Lack of External Validation: The study does not provide external validation of the models' performance on datasets outside of ClinVar, which could further establish their utility and robustness.",1
16,"This paper presents an interesting and impactful approach to improving drug recommendation systems and reducing drug drug interactions.

I would be happy to raise my score if the weaknesses and questions are addressed. 

Strengths: 
1.  The paper is well-organized and was very enjoyable to read.
2. The idea appears to be novel and methods are thoroughly explained
3. Figure 2 is a clinically relevant and easy to interpret example that demonstrates the utility and transparency of this approach to assist healthcare workers. It would be nice to see a similar example of how DDI are assessed for the predicted medications.

Weaknesses:
1. Potential harm of drug-drug interactions and expected benefits of drug recommendation systems are not discussed. A couple sentences would suffice. For example, statistics regarding prescription errors and effects would help emphasis the importance of this research area. 
2. Paper does not explain novel contributions compared to prior work, particularly longitudinal drug recommendation methods that consider the effect of DDIs. I am assuming it is the use of cross-attention, transformer architectures, and a cycle-embedding module for healthcare but this should be explained as gaps in prior work. New loss function could also be referenced as a contribution. 
3. Results demonstrate impressive gains over baselines but do not include confidence intervals. Including averages across multiple runs or random seeds is important to convey significance of results. If there is a reason this is not feasible, then that should be mentioned.
4. Diagram is fairly clear but duplicate inputs and labels, such as for 'drug_embd' and 'sym_embd', in the drug transformer and symptom transformer is confusing and makes diagram more difficult to parse than it need be. I would recommend reworking the figure to reference common inputs once outside of the modules. Also there are two colors for drug_embd used (blue and pink). One color should be used for the same input. The acronyms and colors should be explained in the image description.
5. DDI rate is not explained concretely. This is a very important term in pharmacology so more information regarding how the DDI detector is crucial.
6. More information regarding the classification task is needed. For example, use of the precision metric implies some score threshold is set to convert probabilistic outputs. 

Questions:
1. How is DDI rate measured? The author mentions that ""A lower DDI often implies the set of drug combinations should be as small as possible"". Is set refer to a specific combination or number? Drug drug interaction rate should measure the extent to which drugs interact and not the number of drugs. Assuming the number of drugs given is a proxy for drug interaction rate is not a valid assumption. Can the author elaborate on their assessment of DDI and provide references if possible?

Other:
1. It seems that predicted drug predictions learn from historical data/prescriptions. It would be interesting to see extensions of this work that also consider patient outcomes in the prediction. The model may suggest alternative medications not administered, although these predictions would need to be verified by medical professionals.",1
17,"## Summary

**Setting**: For a distribution $P$ on $\mathbb R^d$, a finite subset $C$ of points in $\mathbb R^d$, an integer $k \geq 1$ and a real $z \geq 1$, let $\mathcal W_{k,z}(C,P) = \int \min_{c \in C} \|x-c\|^2 dP(x)$ be the quantity that measures the cost of approximating $P$ by the set $C$. Using that notation, $\min_{C \subset \mathbb R^d : |C|=k}\mathcal W_{k,z}(C,P)$ represents the best cost of approximating $P$ using $k$ points. When $P$ is a discrete distribution on some set $S$, the previous problem is also known as $(k,z)$-clustering. In the setting of this paper, there is a sequence of distributions $P_1,P_2,\ldots P_T$  (each satisfying $Pr_{X_t \sim P_T}(\| X_t\| \leq 1/2)= 1$ ) and the goal is to approximate $P_T$ by a set $C$ of $k$ points as accurately as possible in the sense of minimizing $\mathcal W_{k,z}(C,P_T)$. One obvious approach for this is to use a window (i.e., solve the $(k,z)$-clustering problem on the last $w$ samples). What is known by prior work for that (cf. Lemma 1) is that this solution incurs some extra cost which consists of two parts: a statistical error part, and a part that depends on how much the distribution shifts in consecutive steps. The first term decreases with $w$ while the second increases. A desired solution would be to use the best window size $w$ that optimizes the trade-off between the two terms. The goal of this paper is to qualitatively achieve that, despite the fact that the distribution shifts are unknown.

**Result**: The paper provides an upper and lower bound for this problem. For the upper bound, it provides an algorithm that, given the availability of another black-box algorithm for $(k,z)$-clustering up to a multiplicative $\beta$ factor, outputs a set of $k$ points whose cost $\mathcal W_{k,z}(C,P_T)$ for approximating $P_T$ is at most 
$$\beta \cdot\mathcal W^*_{k,z}(C,P_T) + \beta \cdot O \left(\min_{1 \leq w \leq T} \left(\sqrt{z^2k/w} + \max_{0 \leq t <w} \epsilon_{t,w}\right)\right),$$
where the first term is the best possible cost (with knowledge of $P_T$) and the second term consists of two parts: a term $\sqrt{z^2k/w}$ that resembles statistical error and a term where the quantities $\epsilon_{t,w}$ quantify the distribution drift in the last $w$ steps (see Theorem 2 for how these $\epsilon_{t,w}$ are defined). Qualitatively, this bound captures the best trade-off discussed in the previous paragraph. The authors show a lower bound for $z=2$ that almost matches the cost from the upper bound.

**Approach**: The algorithm uses a sliding window but adaptively determines its length $w$. It starts with a small window and iteratively doubles its length until there is evidence of a distribution shift. This evidence is quantified by comparing the solutions of the black-box $(k,z)$-clustering algorithm for different window sizes. Once a large enough gap is detected, the algorithm stops and uses that window size for its output. The lower bound consists of constructing a family of sequences of distributions and reducing the problem of learning this family (where by learning we mean approximating it with $k$ points) to a binary hypothesis testing problem for which standard information-theory machinery like Le Cam's lemma can be used.

I enjoyed reading this paper and found it generally well-written and clear. Although I am not an expert in this specific area, the introduction provided a compelling narrative, with a  review of prior work and justification for the problem’s importance. The statements of the results were clear and are followed by discussion that facilitates interpretation. I have not read carefully the details (Appendix) but the proof sketches made sense. One potential weakness (or question for the authors) is that the algorithm requires all distributions to be supported within a constant-radius Euclidean ball. Is this assumption common in the literature? How natural is it, and what changes might be expected under more specific (e.g., parametric) distribution families? Including a discussion on this assumption in the paper would be useful.",1
18,"This work presents an innovative approach to atmospheric modeling by leveraging Clifford algebra-based neural operators within ResNet and UNet architectures. The application of these methods to predict atmospheric variables, including U10, V10, surface pressure, U500, V500, and Z500, from a key reanalysis dataset, is a significant contribution to the field of Earth science. The use of neural networks to approximate the solutions of partial differential equations (PDEs) is a promising direction, potentially offering a more computationally efficient alternative to traditional numerical schemes.
However, the issue of increasing errors and resultant model instability author had observed warrants careful examination. This instability could be attributed to several factors inherent in the modeling approach or data handling processes.

In conclusion, this study represents a meaningful step forward in the application of advanced neural network architectures for atmospheric modeling. Addressing the observed instability requires a multifaceted approach, examining data preprocessing, model architecture, regularization, and validation strategies. Further research in this direction could significantly enhance our capability to model complex atmospheric phenomena efficiently and accurately.",1
19,"This paper analyzes Genomic Foundation Models' effectiveness in gene pathogenicity prediction, highlighting Nucleotide Transformer's superior performance. It showcases the potential of direct genomic sequence classification, offering a significant advancement over traditional methods. The study is innovative and has a practical impact but lacks broad model evaluation, external validation, and discusses potential biases minimally.

**Pros**
- Innovative Approach: The paper pioneers in evaluating Genomic Foundation Models for gene pathogenicity prediction, showcasing a significant shift from traditional methods.
- Comprehensive Benchmarking: It rigorously benchmarks across different models, providing a detailed comparison of their performance on a widely recognized dataset.

**Cons**
- Model Specificity: The study's focus on a limited number of models might not capture the full spectrum of potential genomic foundational models.
- Dataset Limitations: Reliance on the ClinVar dataset alone could introduce bias or limit the generalizability of the findings across different genomic contexts.
- Lack of External Validation: The study does not provide external validation of the models' performance on datasets outside of ClinVar, which could further establish their utility and robustness.",1
20,"This paper considers the very challenging scenario in material science where one hopes to obtain a predictor of yield strength (YS) of high-entropy alloys (HEAs) when high quality real-world measurements are very scarce and simulation results are not very accurate. 

The paper makes 2 main contributions: 
1. The authors compiled a new benchmark dataset “X-Yield” that represents the scenario described above.

2. The authors proposed a new sparsity-regularized training scheme (Bi-RPT) which achieves better results than plain pre-training under the setup of strong domain gap and huge dataset size difference between pre-training and fine-tuning.

Overall, the paper is well written and easy to follow. The experimental results are clear and convincing. I do have a few questions and suggestions to the authors which I will detail below:
It is interesting that the proposed Bi-RPT method can improve the transfer performance. My understanding is that this method outperforms baseline pretrain-and-transfer only under strong domain gap settings. From a scientific point of view, a proof-of-concept experiment needs to be included to show a setting where Bi-RPT doesn’t help. For example, when transferring from ImageNet to ImageNetV2, sparsity regularization would likely underperform plain pretrain-transfer. If otherwise, this method should be considered to be a better transfer learning method in general.
From the experimental results in Table 1, it seems that sparsity at the transfer stage doesn’t change the result significantly. Pre-training sparsity helps the result a little bit, and allowing optimization of pre-training sparsity masks on fine-tuning data provides additional gains. This still holds in Table 4,5,6,7 in supplementary materials, although sometimes tuning the transfer sparsity helps, the difference is very minor. Could it be possible that not using the transfer mask in Bi-RPT produces identical results and the method can thus be simplified？
When applying Bi-RPT to X-Yield dataset, the authors transformed the composition of the material and the temperature parameter to a pseudo-image, then used the same image classification Convnet to solve the problem. My concern is that this method is unnecessarily complex, given the material-science problem considered is mostly low-dimensional, could it be that classical regression method like LASSO, or simple MLP works equally well or even better? Since in that setting, similar sparsity constraints can be applied, and the number of parameters is much less. Either way, it would be nicer to include some baseline comparisons to simpler methods to show the necessity of employing a deep CNN.

I’ll update my score if the questions above are sufficiently addressed by the authors.

Disclaimer: I have no expertise in material science and none of my evaluation is based on the material science significance of this paper.",1
21,"This paper considers the problem of fair clustering, in which each vertex is assigned at least one of $\ell$ colours, and each cluster $C$ containing more than one vertex is required to satisfy  $|C\cap V_i| \leq a_i|C|$ for all $i$, where $V_i$​ denotes the set of vertices of the $i$-th colour. This paper presents an algorithm that achieves a constant-factor cost approximation with fairness constraints throughout the reading of the input stream of the graph, where each vertex is given one by one.

The paper achieves both fairness and online guarantees with tight recourse. Some core algorithmic procedures are based on the previous work of Cohen-Addad et al. on online correlation clustering, but this submission simplifies the analysis in that paper.

Overall, this paper is a solid work in online clustering, and I recommend its acceptance.

Questions:
- The introduction begins by discussing the application of fairness, but fairness in clustering specifically is not mentioned. Please provide some background on fairness in clustering to better motivate the problem.
- Is there a guarantee on the number of clusters created by the algorithm?
- It seems to me that the recourse of Algorithm 1 is $O(\log n/\epsilon)$, where the $1/\epsilon$ factor comes from the logarithm base of $1+\epsilon$. Is it assumed here that $\epsilon$ is a constant? Otherwise the dependence on $\epsilon$ cannot be omitted.
- What would the dependence on epsilon be in Lemma 5 if epsilon is not constant?
- In the main theorem stated on Page 2, what is the dependence of recourse and approximation ratio on a_i and rho? Many things seem to be ignored by assuming that the parameters are constants.

Minor comments:
- Page 2, Theorem statement, last line: $\rho$-fair has not been defined at this point. In fact it is not defined throughout the paper.
- Page 8, Definition 1, second line: Should $N_{G_{t_{u_{C,t}}}}$ be $N_{G_{\tilde{t}_{u_{C,t}}}}$? 
- Page 8, line after Lemma 3: providing -> provide and “Lemma 2in Appendix B” -> “Lemma 2 to Appendix B”.
- Page 8, proof of Theorem 1, line 4: delete “equal to”
- Page 8, Line -5: “there \exists” -> “there exist”
- Page 9, $C_t^{agreement}$ should be $C_t^{agr}$
- Page 9, Line 1: “\forall t” -> “for all t”
- Page 9, Line 13: what does “\simeq” mean?
- Page 10, Theorem 4 statement: Is the number of colours denoted by $\ell$ or $L$? Please be consistent.
- Page 12, Line 6: should “$k+1$ clusters” be “the $(k+1)$-st cluster”?
- Page 12, Line -11: belong -> belong to
- Page 12, Line -5: in any case -> in both cases",1
22,"This paper proposes a novel framework for learning neural operators that can leverage historical information from previous time steps to improve the accuracy and stability of long-term predictions for time-dependent partial differential equations (PDEs). The framework, called Mixture of Neural Operators (MoNO), consists of an ensemble of neural operators, each dedicated to processing the solution from a distinct previous time step, and a gating network that dynamically weighs and aggregates their outputs. The paper demonstrates the effectiveness of MoNO on the Kuramoto-Sivashinsky equation, a challenging nonlinear PDE that exhibits complex and chaotic behavior.

## Pros
1. The paper introduces a new and innovative approach for incorporating historical information into neural operators, inspired by traditional multistep methods in numerical analysis. The paper also provides a clear explanation of the motivation and intuition behind the proposed framework, as well as the challenges and limitations of existing methods.
2. Performance: The paper shows that MoNO outperforms standard single-step neural operator baselines, such as U-Net and Fourier Neural Operator, across various step sizes and history lengths, in terms of reducing one-step prediction errors and increasing high-correlation time.

## Cons
1. The paper only evaluates MoNO on one PDE, the Kuramoto-Sivashinsky equation, which limits the generalizability and applicability of the proposed framework. The paper could benefit from testing MoNO on other PDEs, especially those with higher dimensions, different boundary conditions, or different types of nonlinearities, to demonstrate its robustness and versatility.
2. The paper only compares MoNO with standard single-step neural operator baselines, which may not be the most relevant or competitive methods for incorporating historical information. The paper could benefit from comparing MoNO with other data-driven methods that use historical information, such as recurrent neural networks, attention mechanisms, or memory networks, to provide a more comprehensive and fair evaluation.
3. The paper could benefit from providing more insights and explanations of why and how MoNO works, such as the role of the gating network, the effect of the history length, the trade-off between accuracy and stability, or the potential sources of error and instability. The paper could also provide more quantitative and qualitative measures of the performance and the behavior of MoNO, such as error bounds, convergence rates, sensitivity analysis, or error propagation.",1
23,"This paper studies the model of computable learners in online learning (mistake-bound model).

Context: Recently, the model of computable learning was studied within the PAC framework, where the key change is that we require the learning algorithm (mapping a sample $S$ and input $x$ to a prediction) to be computable by a Turing machine. In this case, the VC dimension no longer characterizes learnability. Delle Rose et al. (COLT’23) recently showed that an ""effective"" (computable) VC dimension addresses this issue: if the VC dimension is $d$, then there must exist a Turing machine that, given $d+1$ examples, outputs a labeling that cannot be realized by the original concept class.

A natural extension is to define a ""computable"" Littlestone dimension for the online setting. Specifically, given a binary tree of depth $L+1$ (where $L$ is the Littlestone dimension), there exists a Turing machine that outputs a labeling that is impossible for the concept class.

Contributions:

- Showing that online computable learning implies a finite effective Littlestone dimension.

- Proving that the converse is false: there exists a class with Littlestone dimension 2 for which no online computable learner exists.

- Showing that if we relax the online game by allowing an arbitrarily large but finite range for the inputs, then both directions hold. This also holds if the effective Littlestone dimension is $1$.

This paper addresses an interesting question with nontrivial analysis (for example, in the proofs of Theorems 7 and 9). I would be happy to see it accepted, though I believe the following writing issues should be addressed.

Writing improvements:

- It seems unusual that the online learning setting is not formally defined, given that it is the primary model in this paper.

- Definition of Littlestone Tree: The definition provided differs from the ""standard"" definition (see ""A Theory of Universal Learning,"" STOC'21). Typically, when we say there is a Littlestone tree for $H$ of depth $d$, we mean that every path from root to leaf is realizable by $H$. In this paper, however, this is not the case. The tree has a similar full binary structure but does not require that every path is realized by $H$, which may be confusing.
Is that correct?

- It would be helpful to include an intuition or overview for the proof of Theorem 7. Since the tools used in the proof are not easy to digest, the writing would benefit from a clearer explanation (especially as there is room for this within the first 12 pages).

- Typo in Lemma 1: ""an d"" should be ""and.""",1
24,"## Summary

This paper compares three Genomic Foundation Models (HyenaDNA Tiny, GenaLM, and Nucleotide Transformer) against each other on the ClinVar dataset for gene sequence classification. Then the best model is compared against the state-of-the-art traditional genomic model (SNPred). I do not work in the genomics space; I work in adjacent domains (healthcare, language models), so I can see that the comparisons the authors are trying to make may be valuable to other genomics researchers. However, this manuscript reads more like a review paper than one describing new research. It is missing key details of experiments and a clear description of fine-tuning and evaluation datasets is missing, making it hard to interpret results.

## Pros
* Well written detailed description of prior work in this domain
* Detailed metrics comparison of transformer-based foundational models in genomics against state-of-the-art traditional models like SNPred.
* tSNE embedding visualization helps visually explain performance gap between models

## Cons
* Too much of the manuscript is focused on introduction/background/related work and too little on experiment and discussion. Some of the background is helpful to readers not in the genomic space, but overall should be reduced by at least 1 page to make space for experiment and broader discussion of results. Otherwise, this submission reads like a review paper rather than an original experiment paper.
* Nit pick: Formatting of text in Table 1 is suboptimal. To make it more readable, consider using abbreviations and describe abbreviations in table legends.
* Nit pick: Formatting of Table 3 is odd. There are 6 significant figures reported for SNPred and the other models, but only 2 significant figures for Nucleotide Transformer. Be consistent.
* Table 2 reports comparison of three Genomic Foundational models using Accuracy, Precision, Recall, and then the best one (Nucleotide Transformer 250M) is compared against SNPred in Table 3 using AUC ROC and AUC PR.  It seems like it would be more straightforward and clearer to just report AUC ROC and AUC PR for all 3 models in a single table along with SNPred.
* Authors describe that 10 models were fine-tuned, but then only report a single result per model. It is unclear whether there was further model selection from the 10 models or if evaluation results were aggregated, etc.
* Larger HyenaDNA models were not compared due to compute resource constraints.
* Surprising to me that Nucleotide Transformer 500M performs worse than Nucleotide Transformer 250M and there is no discussion of why this is the case.
* Fine-tuning and Evaluation datasets are not well described. Would recommend a table that describes pertinent statistics for each dataset and split that is used.",-1
25,"### Paper Summary
This paper implements LORA and fin-tuning to achieve inference of medical images segmentation on laptop. The result is better than the baseline LiteMedSAM.
### Paper Strength
The introduction and method are relatively complete. The result is promising. 
### Paper Weakness
The paper is not complete in discussion.  There is no qualitative result, no discussion, no conclusion. Simply speaking, the paper was not finished.",-1
26,"The paper presents a novel method for learning interpretable safety constraints from expert demonstrations using one-class decision trees. Pros of the approach include 
- Interpretability of the learned logical constraints
- The ability to reduce manual specification of constraints 
- Improved safety and performance over baselines in experiments

However, some limitations exist as well:
- The approach relies heavily on demonstration quality
- The tree depth likely requires careful tuning for each environment to prevent overfitting while ensuring reasonable performance 
- Needs more analysis on transferability of learned constraints, which the authors have mentioned as a future research direction",1
27,"The paper proposes to use the idea of resolution invariant learning of operators in quantum field theory, thereby enabling the use of a single model on multiple discretization (lattice) of the same underlying system. 

While, the idea has been explored in many different use cases, I am unaware of it's specific use in quantum field theory.

The description of quantum field theory is adequate, given this might be new to readers of a ML venue.

However, I think the experimental section is very poorly written, and it is not easy to understand what the paper is trying to achieve in one go. I do suggest, more details on what the core experimental section is be added, plots can be moved out if needed. Without a clear message in the experimental section, the efforts made for the paper are futile. 

The experimental results are somewhat convincing.",1
28,"In this work, the authors develop and present preliminary results regarding an identification system based on magnetocardiography. The method for using MCG is an interesting non-invasive technique and significant effort has been shown in developing the system. However, there are several comments to be made regarding the work in the context of the symposium:

- First, the limited sample subjects does question the robustness of the results. Evaluation over a larger cohort would strengthen the conclusions of the paper
- The modality of MCG is novel, but given the size of the apparatus shown, it is questionable where such a system would be practical and needed.
- In addition, although the authors claim that MCG-based identification would be more robust and reliable, it is uncertain whether this is true given a lack of comparisons to other mentioned methods, such as facial features or ECG.
- The authors utilize a CNN with features extracted from a wavelet transform for the identification, it’s unclear that such a method would be scalable to large populations that would be necessary for practical deployment.
- Moreover, there doesn’t seem to be any significant innovation related to MCG or ML for healthcare in general.

Although the method of MCG is novel and interesting, further results and evaluation to other existing approaches is recommended",-1
29,"This paper describes a comparison between leading LLMs (GPT-4 and Llama-3) and the Abductive Rule Learner with
Context-awareness (ARLC), a neuro-symbolic approach, in solving Raven’s progressive
matrices (RPM). In particular, the authors extend the RPM tests to larger matrices, so that out-of-distribution evaluation can be carried to better test the models reasoning ability.

Strength:
- comprehensive empirical study of various models on this interesting reasoning task.
- mostly well-written, not hard to follow.

Weakness:
- not much to take away as LLMs are already known to be bad at arithmetic reasoning
- it would be nice to see a few more words about why the I-RAVEN dataset matters and if the ARLC can be applied beyond this RPM task.",1
30,"Summary: This paper trained the RoBERTa model to predict whether individuals discussing anxiety in their posts will subsequently express interest in ADHD. They showed that it shows high performance (76% correct), which can give insights into their comorbidity. 

Comments:
1. It is unclear what the ability of the RoBERT model to classify the groups implies. There could be many ways that drawing some clinical insights from the model performance can go wrong or be indefinite. The examples are below
- Some symptoms of anxiety are also indicative of ADHD. The RoBERT model captures the terms related to the comorbidity. However, it still seems unclear if they are just associative or if they have a causal relationship.
- ADHD patients have some features in common in their posts (not related to disorder symptoms)
- Or it could just imply selection bias as the reddit is not prospective data. 
I think the implication should be more clearly stated. Also, I think modification of the experimental design could be necessary.

2. “Social media such as Reddit provides publicly available text data of anonymous
first-person experiences (Low et al. 2020).” This sentence at the end of the first paragraph in the introduction section looks abrupt. The first paragraph is mainly about the problem of misdiagnosis of ADHD and anxiety, so I think this sentence on the data source of this study should be discussed in the next paragraph.",1
31,"# Summary
The paper applies a meta-learning approach for efficiently adapting hybrid ODE and PDE models across multiple environments.

# Strengths
1. The problem studied by the paper, of generalizing hybrid models across environments, is interesting and impactful.
2. In general, the paper is easy to read and the figures, algorithms, and tables are well presented.
3. The range of experiments is good, and they appear to verify the effectiveness of the method.

# Weaknesses
1. As far as I can tell, the meta-learning strategy proposed here is identical to CoDA [1].
The primary contribution of this paper is therefore not the meta-learning strategy itself, but rather its application in a hybrid setting.
While applying CoDA to hybrid rather than purely data-driven models is a valid and interesting contribution, it nonetheless raises serious questions regarding the presentation of this paper.
In particular, **it would be easy to read the paper and think that the meta-learning strategy itself is a novel contribution**.
For example, the abstract states, 
> ...we introduce a meta-learning strategy that captures context-specific variations inherent in each system, enhancing the model’s adaptability to generalize to new PDE parameters and initial conditions,

    while the introduction says, 
    > To tackle this generalization problem, we propose a framework that can be viewed as a meta-learning approach for rapidly adapting the data-driven components of a hybrid mode [sic].

    In Section 2.3, ""A Two Stage Framework"", the paper's meta-learning algorithm is introduced *without any reference to CoDA*. 
    In fact, CoDA is referenced only in the Appendix, where the authors state,
    > We propose a similar approach, but extends to more complex dynamical systems where partial knowledge is assumed.

    It's possible that I've missed some novel aspect of the proposed meta-learning algorithm other than its application to hybrid systems; if so, it still needs to be made very clear how the proposed algorithm relates to prior work, especially CoDA.
    As it stands, I unfortunately have serious doubts about the originality and the presentation of this work.
1. Both CoDA and CAVIA are used as baselines but without reference to the relevant papers, requiring some detective work by the reader.

# Other Comments
1. In many places, such as the abstract and introduction, the paper is written as if it were about PDEs only, but the experiments consider both ODEs and PDEs. 
1. In the results in Table 1, it seems strange that ""CoDA + Phys loss"" performs strictly worse than CoDA, in many cases by multiple orders of magnitude.
If the physics loss were properly motivated, implemented, and trained, shouldn't it generalize at least as well as CoDA?

# Conclusion
Given my concerns about originality and presentation, outlined in the first weakness above, I cannot recommend this paper to be accepted in its current form.
In my opinion, the paper is presented as ""a new meta-learning framework for hybrid models"", while the reality is closer to ""an existing meta-learning framework applied to hybrid models"".
That being said, I still find the work relevant and interesting, and I look forward to seeing future versions.

# Citations

[1] Matthieu Kirchmeyer, Yuan Yin, Jeremie Dona, Nicolas Baskiotis, Alain Rakotomamonjy, and Patrick Gallinari. Generalizing to new physical systems via context-informed dynamics model. *International Conference on Machine Learning*, 2022.",-1
32,"Summary

This paper studies the problem of private density estimation for mixtures of Gaussians in the agnostic setting. This problem was previously studied by (Afzali et al., 2024) in the realiazable setting but remained open in the agnostic setting.

The paper provides upper bounds on the sample complexity of privately learning GMM in the agnostic setting. Their techniques are inspired from existing work on private supervised learning where private algorithms are designed using algorithms that satisfy different notions of stability. In particular, the algorithms in this paper build on the notion of list global stability.

The authors prove their main result via two main steps: first, they show a reduction from agnostic private density estimation to list globally learnable learning, and then they propose a list globally stable algorithm for density estimation of GMM. 

Strengths

Overall I think the paper provides some nice results and techniques that would be of interest to the ALT community. The paper solves an interesting problem, providing the first upper bounds on the sample complexity of private density estimation for mixtures of Gaussians in the agnostic setting. Moreover, the results in the paper also improve the sample complexity in the realizable setting over the prior work of Afzali et al. (2024). 


Weaknesses


I have two minor complaints about the paper: 

1. Clarity\writing: while most of the paper is very clear and easy to read, I think section 4 needs a little more work: currently, three algorithms are listed in that section without providing some description or intuition to help the reader. 

2. While the sample complexity bounds are interesting, they are still achieved by algorithms with exponential runtime (in d) as the list size of the stable algorithm is exponential in d. It would be interesting to see if there is a poly-time algorithm that can solve this problem, potentially with a slightly worse sample complexity.",1
33,"This work proposes a method combines ARC solutions from Large Language Models and a
Program Synthesis solver. Its performances are verified on the ARC and AugARC dataset. 

As an ensemble method, it is not surprising to see better performances than methods that only use LLM or DSL solver. This work goes one step further by combing the 2 together to complement each other to achieve better performances. This is achieved by a reflection model.

Q: if the reflection model and the solver are the same LLM, will the reflection model prefers its own answer?

Agree with the authors that Claude 3 (sonnet) may have seen the ARC data and should be treated separately. However, this does not impact the final conclusion.",1
34,"Summary:

In standard PAC learning, the adversary can select any distribution. PAC-learnability is then known to be equivalent to uniform convergence, and also to density estimation (the task of estimating the true distribution in a total variation metric that is restricted to a set of events determined by the hypothesis class).

The paper studies a less adversarial ""Distribution Family"" version of PAC learning where the adversary is restricted to select a distribution from a known set of distributions. It shows that:
  a) Distribution family PAC-learnability is harder than weak density estimation, but easier than intermediate density estimation.
  b) If the distribution family has uniformly bounded metric entropy, then a distribution family variant of density estimation is equivalent to uniform estimation.

Here, weak and intermediate density estimation are learning tasks in which the goal is to estimate the probability that two classifiers make different predictions, for most pairs of classifiers in the hypothesis class; they differ in the details of defining 'most'. Uniform estimation is the task of uniformly estimating the risk for all hypotheses in the hypothesis class.

Significance of the results:

PAC learning is a central topic in learning theory, and its relaxation to a distribution family is natural and practically significant. As far as I am aware, all main results are new. They give interesting fundamental insights into the relations between various notions of distribution family learnability. This work will therefore clearly be of interest to the ALT community.

A limitation of the work is that it is not shown whether the derived relations between sample complexities are optimal. But this would also not be expected in a first work to establish the relations.

Correctness: I have selectively checked part of the proofs, and found no mistakes.

Question for the authors:

Q. I got the impression that intermediate and weak density estimation are new learning tasks. Is this correct or have they been considered before? And the distribution-family versions of density estimation and uniform estimation?

Presentation and clarity: the paper is generally well-written. I have a few minor suggestions to improve the clarity and presentation, which are described below.

All in all, I believe this is interesting work that gives new insights into fundamental learning tasks, and I recommend it for acceptance.

High-level suggestions to improve the presentation:

* I strongly feel that the purpose of 'Theorem', 'Definition' and 'Proposition' should remain to identify formal statements, as it is throughout mathematics. So even though I really like the informal paraphrasing of several theorems and definitions in the introduction, the authors should avoid labeling them with self-contradictory phrases like 'informal theorem' or 'informal definition'. This is especially problematic in cases like Proposition 7, where the 'informal' version is not just paraphrasing the formal result, but it is also leaving out essential conditions that are necessary for it to hold.

* The structure of the paper is not clear at the start. I would suggest to add a brief outline at the end of the introduction that summarizes the technical contributions and discusses the structure of the paper. I would further suggest to rename section 3 to 'Main Results'. Then, for i=1,2,3, I would suggest to rename Section 3+i to ""Detailed Proofs for Section 3.i"".

* The long and short versions of the proofs are a bit repetitive, with many sentences repeated verbatim. This is not the most elegant. If possible, it would nice to break things up in a way that avoids too much repetition. Otherwise, the current form is acceptable as is.

Minor comments:

* The abstract uses cal{H} whereas the rest of the paper uses H
* Definition 2: ""exists"" -> ""exist""
* Please define H Delta H. The description in footnote 1 is not clear.
* Footnote 2: uniformly bounded metric entropy of what?
* p.5: In definition of growth function, define H_{|S} (even though it is well-known)
* Definition 15: state that G_{T,D} is random. Its existence should also be stated before '1.' because '2.' also refers to it.
* p.6: ""classical problemS in statistics""
* Section 3: please start section with short overview of its structure
* Proposition 21: recall that Pi_H is the growth function (it took me a while to find its definition)
* Theorem 27: typo in delta' = O(delta/Pi_H(...)): the part in place of ... should be an integer, probably you meant n_UE(eps/4, delta/2).
* A conclusion with suggestions for future work at the end of paper could make a nice addition.",1
35,"This paper tackles the challenge of biased predictions in machine learning systems within the clinical domain, where demographic information may be unavailable due to privacy concerns. It introduces an adversarial weighting architecture that utilizes model gradients to identify and prioritize underrepresented groups, offering a novel approach to improving fairness without relying on demographic data. Unlike conventional methods, this approach provides a robust mechanism that significantly enhances fairness while preserving overall accuracy, marking a notable advancement in the quest for fair and reliable machine learning systems in healthcare.",1
36,"The paper presents a foundation model based on a custom dataset called CheXinstruct. The authors train a BLIP-2 model on the proposed dataset and evaluate on several downstream tasks. For the metrics the authors choose accuracy as stated in table 1, which seems to be ill-chosen in the chest x-ray domain since there is a massive class imbalance. Also in the proposed evaluation benchmark a comparison from the generalist BLIP-2 model based on mistral 7B  to expert models specific to the individual tasks as a quasi upper bound is missing. Especially for the classification tasks this might provide some better perspective on the difficulty of the task. Similarly, a simple baseline might be beneficial to get a grasp of the lower bound of each task.
Overall there are some serious concerns regarding the evaluation protocoll of this paper which might be resolved by the use of better suited metrics and comparison models.",1
37,"This work compares a range of state-of the art machine learning methods used for the emulation of weather prediction systems. This is a rapidly growing field with several different groups producing highly skilled models, all built using different core architectures. This paper’s novelty is directly comparing the skill of each architecture on a single system using similar training setups for each model to reduce the factors contributing to skill. The paper looks at three configurations of the system and training data to compare results. The topic of the paper is interesting as a comparison like this has yet to be performed on data from a climate system.

However, several flaws with the idealized testbed and training/testing methodology bring into question the usefulness of the paper’s results. 

Major Concerns
1)	The two cases of homogenous isotropic forced 2D turbulence selected for the paper lack the multi-scale complexity present in true atmospheric flows. The flows selected are borderline turbulent, in addition to lacking other important characteristics such as rotation or mean flows. 
a.	In experiment 1, with Reynold number of 1000, the flow looks to be close to laminar, with a single pair of vortices dominating the domain and no visible small scales. Given that the initial condition for the simulation appears to be from the spin up of a simulation, it is also possible the run has not had sufficient time to develop turbulence.  
b.	In experiment 2, the flow does appear to be turbulent, however it still is dominated by a small number of large vortices.
2)	Choices the authors make while training the model may impact each architecture differently and differ to the implementations of the corresponding methods by the groups who have shown success with them.
a.	An example, providing the model with the previous 10 time-steps of history is not a common practice in weather predictions and may have both positive or negative effects on model prediction. These effects also may be a function of architecture. 
3)	Ultimately the paper draws conclusions outside of the scope of the work done, investing more time into understanding the key features of climate/weather emulation and choosing a more suitable testbed (e.g. higher Reynolds numbers, including rotation, or even dynamics across multiple depths/layers as in quasi geostrophic models) would make this an important contribution to the field.
Minor Concerns	
1)	The persistence RMSE is computed against a snapshot of undeveloped flow, this does not give a good baseline for the performance of the models as the system has not yet reached a steady state. In fully developed flow (which is the case for the atmosphere), the large vortices would persist longer and likely would give the system a longer decorrelation timescale and meaningfully change the values of RMSE. 
a.	The use of persistence as an initial condition is not the most representative of problems in the atmosphere as learning how flow will develop is not the same as how it will evolve.
2)	Be careful with language in the paper, some statements are not correct.
a.	“the atmosphere is modeled by means of incompressible Navier-Stokes equations” – the atmosphere is not considered to be an incompressible flow, typically it is assumed to be an ideal gas in the dynamical core of climate models. Furthermore, the actual atmosphere reflects dynamics including moisture and radiation, which are not components of the Navier-Stokes equations.",-1
38,"The paper proposes a specialized NeSy architecture based on the SOFAI model, inspired by Kahneman's ""Thinking, Fast and Slow"" paradigm. This architecture, referred to as Plan-SOFAI (Slow and Fast AI), aims to address various planning problems across multiple scenarios by leveraging both fast and slow planning approaches while incorporating a metacognitive process for governance.

The paper is well-written and easy to follow, with clear technical explanations. The authors have demonstrated a seamless integration of different AI techniques (symbolic and end-to-end Machine Learning) within a single architecture, including its risk aversion parameters and the process for adopting solutions proposed by System-1 (S1) and System-2 (S2) solvers. The straightforward integration of the system shows promise in addressing real-world planning problems. The proposed architecture is compared with state-of-the-art planners, displaying a good balance in terms of solving plan optimality, which is crucial for practical applications.

However, the paper mentions postponing the investigation of the optimization of the Plansformer, a key component of System-1. Although this could limit the current effectiveness of the system, the authors have expressed their interest in further improvements and optimizations as the next step in future work. Furthermore, while the paper evaluates the architecture against established planners, the testing scenarios and domains may not fully capture the diverse range of real-world applications and challenges. For instance, it is not clear from the experiments whether the architecture's effectiveness is constrained by the quality and quantity of past solved problems used in its memory, especially in addressing new or significantly different scenarios.

In summary, Plan-SOFAI, as a NeSy Planning Architecture, contributes to AI research by effectively integrating diverse planning techniques. While it requires further enhancement in optimization and testing across diverse scenarios, I believe the paper qualifies for presentation at the NuCLeaR workshop.",1
39,"The paper explored the application of LoRA fine-tuning of Mistral 7B Instruct to classify TNM staging from unstructured pathology reports for triple negative breast cancers. Several baselines and tuning strategies are compared on a real-world data task to demonstrate the proposed fine-tuning approach could achieve better accuracy using small amount of training data. 
- Quality: the paper is technically sound and of good quality. Most claims in the paper are well supported by experiment results. 
- Clarity: the paper is well-structured and clear in experiment process and results discussion, despite that the paper lacks clarity on the clinical knowledge of TNM  categories (pls refer to the suggestion #1 below). 
- Originality: the paper demonstrates an interesting application of well-established techniques to a specific clinical task. Though fine tuning  is not a novel idea, the application to the specific TNM staging seems to be novel from practical perspective. 
- Significance: the paper mentioned potential generalization possibility of the proposed approach other clinical tasks, given the low cost and high reliability with comparison to other large language models.
Cons, suggestions or questions to the authors:
1. It'll be better to include a brief introduction of TNM staging (e.g. T stands for size of tumor, etc.) at the beginning of the paper for non-clinical audience, and also why TNM staging of triple negative breast cancers is challenging and demands the help of ML modeling and application. It will also improve the significance of the work from the clinical application perspective.
2. The paper mentioned manual labeling from subject matter experts. Would you pls provide more information on 1) how many experts are involved, 2) whether each document was labeled by multiple experts and how the final label is determined (e.g. if there's any disagreement) . More importantly, could you pls comment how to ensure the reliability and robustness of the proposed fine tuning approach towards label noise in the training data?
3. In table 1, different fine-tuning results show increasing accuracy but decreasing in confidence for ""UNKNOWN"" class. Does it indicate over-fitting problem?",1
40,"The paper addresses the challenge of adapting generalist foundation models like SAM to medical image segmentation tasks, crucial for diagnostic and treatment processes. Despite initial promise, the specific adaptation model, MedSAM, fails to consistently outperform SAM in medical task-specific contexts. However, the introduction of LoRaMedNet, a novel parameter-efficient approach, demonstrates the potential for enhancing SAM's adaptability and achieving superior performance in medical tasks. The findings underscore the significance of exploring adaptation techniques for generalist models, suggesting that they can excel in specific medical applications even without dedicated medical pre-training.",1
41,"**Summary**


The authors introduce a generalization of current notions of delayed rewards in adversarial bandits. The problem is motivated by online learning where the outcome of the action is not observed immediately, but the reward can be estimated. This estimation can evolve over time. 

They propose and analyze algorithms for both the full information and bandit settings. Then, they demonstrate how commonly analyzed delay/corruption assumptions can be implemented in their framework.

**Pros**


-	The authors propose an interesting and useful generalization of adversarial delayed feedback. The bandit literature has many different assumptions on rewards and observations, and in my opinion, unifications like the ones proposed in this work are often helpful. 
-	Standard algorithms can be adapted simply to this setting.
-	The result is related back to delayed, corrupted, and composite feedback so it can be compared to prior results. 


**Cons**


-	The authors have some discussion of asymptotic optimality in the delayed setting, but it could include a more comprehensive discussion (e.g. is the algorithm optimal in the corrupted setting?)",1
42,"#### The approach involves a sophisticated hierarchical model that synthesizes high-resolution 3D medical volumes from textual descriptions found in radiology reports. This process is segmented into several core components, emphasizing the integration of a pre-trained text-encoder (Medical BERT) for linguistic feature extraction, a text-guided low-resolution 3D diffusion model for initial volume synthesis, and a super-resolution 3D diffusion model for enhancing detail and anatomical accuracy.


### Strength 
#### 1. the paper utilizes a hierarchical diffusion model that begins with low-resolution image synthesis, advancing to detailed high-resolution outputs. This methodology ensures both the efficiency of computation and the integrity of generated volumetric data.

#### 2. By incorporating Medical BERT for text feature extraction, the model effectively leverages deep learning advancements in NLP to understand complex medical terminology and descriptions, enriching the synthesis process.

#### 3. The inclusion of segmentation masks for core anatomical structures (lung lobes, airway, vessels) within the synthesis process significantly enhances the anatomical plausibility and detail of the generated images, setting a new standard for medical image generation fidelity.

### Weakness 

#### 1. The model's performance is directly tied to the quality and detail of the input radiology reports. In scenarios where such reports are lacking in detail or contain inaccuracies, the system's ability to generate precise and anatomically accurate images may be compromised.

#### 2. Despite efforts to manage memory use efficiently, the model's advanced capabilities and the need for high-resolution outputs inherently demand considerable computational resources, which may limit accessibility for some research and clinical settings.

### Questions: 
#### 1. Could you elaborate on the steps you've taken to simplify the implementation of your hierarchical model for users without a deep technical background in AI or medical imaging?

#### 2. How does the model handle variations in the quality of textual descriptions in radiology reports? Are there mechanisms in place to ensure the reliability of image synthesis when faced with ambiguous or incomplete textual data?

#### 3. The paper focuses on lung CT images. Can the methodology be adapted for other types of medical imaging or conditions? If so, what modifications would be necessary?

#### 4. Could you discuss any measures taken to address potential biases in the datasets used for training the model? Additionally, how do you ensure the model's robustness across diverse patient demographics?",1
43,"The authors suggest using a combination of diffusion model and a cross-attention layer to learn latent variables in a neural PDE formulation. Despite a more complicated architecture that must have resulted in more GPU-hours than the baselines, the numerical results were not noticeably different. The authors should provide a comparison on training time of their model vs the baseline and further numerical justification for their idea.",-1
44,"This paper proposes a comprehensive analysis, aiming to evaluate different components of Dynamic Sparse Training(DST) in Continuous Learning (CL).  Extensive experiments are conducted to support the findings. 

Pros: 

1. The work of evaluating the different settings of DST in CL scenarios can be a guide for later research.

2. The experiments on the different initialization of DST and the prune-and-grow approach are comprehensive.

Cons & Question

1. Do the findings proposed in this paper help increase the performance of previous work like SparCL, NISPA, and WSN?  It would be great to have some comparisons with other methods.

2. The findings are based on ResNet structure. Can similar results be found in VGG and MobileNet?  

3. It is interesting that adaptively choosing DST methods can improve performance, as shown in 5.3. Does this finding exist in all the sparsity levels (Low sparsity and high sparsity)?

4. Most of the findings apply to DST (e.g. ERK distribution can reach higher accuracy, and gradient- and momentum-based growth provide better performance), and I would like to know what is uniquely specific to CL. 

5. As ITOP systematically evaluate the impact of topology update frequency, I am curious about the effect of update frequency on CL.",1
45,"Pros:
- The authors present a thorough evaluation of applying quantization to the Segment Anything Model
- The authors experimented with various runtime engines to optimize inference speed

Cons:
- Low results compared to non-quantized methods with no real reduction in inference time

Overall, the writing is good, but the results are not promising.",1
46,"Correlation clustering is a popular clustering objective, where given a graph the aim is to find a partition/clustering of the vertices such that the number of inter-cluster edges plus the number of intra-cluster non-edges is minimized. In the online version of the problem, vertices arrive sequentially one-at-a-time, and the objective is to maintain a good correlation clustering in the currently available induced subgraph for every time instance. This online version of correlation clustering is also well-studied, and algorithms are known that maintains a constant factor (eg, 0.5) competitive ratio in each time instance - while maintaining a logarithmic recourse (the number of time the cluster membership of any vertex changes).

On the other hand a ``fair'' version of correlation clustering has also been studied, where the objective is to ensure vertices of a predefined type (one of l colors) in any cluster to not be more than a certain fraction. Given a set of l fractions, a $\rho$-fair algorithm maintains the fairness constraint up to a multiplicative factor of $1+\rho$.

This paper combines these notions and asks for a *fair online* correlation clustering algorithm. It proposes an online algorithm, that is constant-factor competitive, has logarithmic recourse, and at the same time maintains the fairness constraint up to a multiplicative factor of $1+\rho$ in every step. Due to this being the optimal recourse for even a non-fair algorithm, the only scope of improvement here is the competitive ratio and $\rho$.

The algorithm seems non-trivial, because the previous online algorithms can produce far from fair algorithms. The main technical contribution is to splitting the resultant highly non-fair clusters into singletons.

Overall this seems to be a decent and timely contribution.",1
47,"The paper discusses machine learning for chronic kidney disease prediction. Multiple baselines are tested. The strength of the paper includes the detailed background introduction and problem-driven study, with thorough data analysis and experiment discussion. The code is made available online. The weakness of the paper includes too few baselines being tested, not standardized and lacking comparison to some foundation models (that are not specifically for chronic kidney disease but can be easily tailored to do so). Figure 1 is too small, especially with too small fonts. The Discussion section lacks more tables/figures/statistics to back up the sentences.",1
48,"The study presents a compelling approach to enhancing the diagnosis of Chronic Kidney Disease (CKD) using a data-driven method. By utilizing the MIMIC IV, a large, open-source database of electronic health records (EHRs), the research employs ML techniques to determine best approach to assess the risk of CKD. 

The methodology is comprehensive, incorporating patient-specific demographic data, vital signs, and past medical history to predict CKD status accurately. The authors meticulously detail their data sources, the process of pre-processing, and the strategies employed to handle missing data, showcasing a robust methodological framework. The training and test datasets are balanced across CKD disease stages, which is crucial for the reliability of the predictive models. The authors statistical analysis is sound and supported by clear tables and figures.

They show that the Random Forest Classifier was identified to have the best performance, achieving an accuracy (0.875), an  Area Under the Receiver Operating Characteristic Curve (0.927), and a F-1 score (0.765). These results supports authors conclusion that the  random forest CDK classifier algorithm maybe effective in identifying patients at risk of CKD, particularly those who may be under-diagnosed due to health disparities.

While the study is not about foundation models, the authors demonstrate and remind us of that simple algorithm maybe sufficient to solve pervasive healthcare problems.",1
49,"This paper introduces an encephalitis query-document dataset along with an embedding model used for retrieval. The experimental results demonstrate the superiority of the embedding based model over traditional key-based search engines. 

**Pros:**

(1) The dataset and the model are valuable to the community. 

(2) The code is clear and easy to read. 

**Cons:**

(1) The experimental results only present some cases, instead of the performance on the whole dataset. It would be better to list a series of numbers in a table. For example, for the baselines, choose keyword-based search engines, as well as OpenAI’s text-embedding APIs. The metrics can be recall, etc. Also, the authors can explore whether the cheaper model developed by users (like the one proposed in this paper) can be on par with the OpenAI text-embedding API models. 

(2) The layout of this paper can be further improved. For instance, move the “Links” parts as the footnotes. For the case study paragraphs in the appendix, it would be better to wrap them with a blockquote. It would be more convenient to use latex templates to modify these things, compared with Word.

(3) The title is too long and can be shorten, such as “Enhancing Encephalitis Research Retrieval: Leveraging GPT-4 for Semantic Query-Document Alignment Beyond Keywords.”",1
50,"This paper presents an interesting framework for long-term human motion prediction. The idea of combining VQ-VAE and diffusion policy makes sense. The reachability guidance is also suitable for this problem.

Suggestions: texts in the figs are not very clear. It would also be interesting to explore other conditions, e.g. social and scene.",1
51,"The authors train self-supervised vision foundation models on a very large set of pathology data and show that the embeddings they produce yield much better performance on downstream tasks compared to those trained on general image data, specifically ImageNet. The writing is clear, the presentation is thorough, and the results are strong. The work has potential for broad impact. I didn't read the supplementary sections in detail, but the thoroughness is appreciated. I am not familiar with pathology, so I will leave it to other reviewers to assess the selection of downstream tasks.

There are elements of the experiments and presentation that could be improved. While it should be straightforward to improve presentation, I understand that, since the experiments themselves are costly to run, additional experimental runs may not be able to be included in this submission, which is fine - it can be taken as feedback for further development of the work.
1. It is not necessary to show all the results across epochs. It makes the figures unnecessarily large and difficult to interpret, and it masks the effect of model selection, e.g. using a validation set to determine which checkpoint's model to actually use. In particular, the overlapping lines make Supplementary Figure 1 a bit hard to read. Perhaps just one figure to make the point about saturation and overfitting would be enough. The rest could be tables or bar charts or similar for the selected models.
2. It does not seem appropriate to draw conclusions about the effect of data quantity from the loss curves shown. I don't think you can reasonably disentangle the effects of training time and data quantity in these results. The best approach would be to train additional models on subsamples of the data set, but I understand this is costly.
3. It's unclear why not all models are shown in Figure 2.
4. Supplementary Figure 1 contains the main results of the study. These should be in the main paper. Just a table would be fine.
5. It's not clear what is tRes50 vs Res50.
6. The baseline model should have the same architecture (ViT) as the experimental models in order to isolate the effect of the pre-training data. It is even acknowledged by the authors that ResNet may be overfitting due to the architecture itself.
7. It is explained that DINO-ViT-large is excluded due to training cost, but why is there no MAE-ViT-small or MAE-ViT-base?
8. I would expect that the data cannot be released, but why can the pretrained models not be released? Regardless, the intention to set up an API to get embeddings is appreciated.

Minor nitpicks:
1. In the pre-training section, you mention that your data is an order of magnitude larger than any previous effort. It would be nice to cite the largest previous effort here.
2. Please define pseudo-epoch and explain why it is used instead of standard epochs (I am guessing it is to increase checkpoint frequency?).
3. Typo, first paragraph of discussion section: ""SLL""
4. In the discussion section, you say you trained DINO only on ViT-small, but you report results also for ViT-base.",1
52,"This paper proposes a new PAC-Bayesian generalization bound for models trained with gradient flow or gradient descent. Compared with previous de-randomized PAC-Bayesian bounds assuming specific model structures, this work’s analysis applies to a more general family of models. The authors prove a continuous-time bound first, then extend it to discrete time gradient descent. They also computed the explicit form of their bound for random feature model and NTK. Detailed comparisons with previous generalization bounds are provided.

Strengths:
- Obtaining a general PAC-Bayes bound for deterministic algorithms such as gradient descent is always an exciting topic.
- The paper is well written, with detailed comparison with previous literature.

Comments & Questions:
- It seems unclear how fast the PAC-Bayes bound converges. A general unconditional sample rate of $\tilde{O}(\frac{1}{m})$ should be intractable. I wonder when does Theorem 4 achieve this rate, and when does it imply only the slower rate of $\tilde{O}(\frac{1}{\sqrt{m}})$? It is argued that the faster rate is guaranteed assuming $\mathcal{L}_s\sim 1/m$, but the authors should justify why such an assumption is reasonable.
- How does the result compare with previous deterministic PAC-Bayes bounds such as [1]?
- In Section 7.1, the third line below eq (6), $R$ should be $\Gamma$.

References.
[1]. Luo, Xuanyuan, Bei Luo, and Jian Li. ""Generalization bounds for gradient methods via discrete and continuous prior."" Advances in Neural Information Processing Systems 35 (2022): 10600-10614.",1
53,"This paper applies the  Generative Pre-trained Transformer (GPT) model for photoplethysmography (PPG) signals. This is interesting and valuable. The point of using a logit-Laplace loss, instead of a MSE loss to train the model is also very insightful. My main concern about this paper is how can we make sure the converge when only using 5% of the data. We know transformers are data-hunger architectures. What is the limitation of such a model? As the paper mentioned in the future they will train the model using more data, I assume we will get the answer later. In general, this is an interesting and valuable paper for PPG-related tasks.",1
54,"Summary of Contributions:

The work proposes a Foundation model for (as the title suggests) “assessing diverse physiological functions, using only photoplethysmography signals”. The authors encode vast numbers of 30s of PPG samples @40Hz and train a GPT like foundation model with the next sample prediction pre-training objective. Then they fine-tune this model for solving downstream tasks such as heart rate estimation, atrial fibrillation detection, blood pressure estimation, and detecting false arrhythmia alarms.

Strengths:
1. The paper is well written and easy to follow. The block diagram is representative of the method presented in the paper.
2. The proposed method is sound and it stands to reason that with the increase in the model parameters and the training set, more emergent behaviour should be witnessed.
3. The qualitative results in the appendix are quite impressive.

Weaknesses:
1. Details such as number of model parameters, training time, GPUs used, etc. are missing from the paper. They often provide some indication on how scaling up might improve the results, and also about the feasibility of using the model.
2. The fine-tuning time requirements when compared to the training time (from scratch) of SOTA specialist models are also missing in the paper.
3. Some ablation studies are missing. For instance, it was mentioned that (in the decoder) the  RMSNorm was preferred over LayerNorm, then PoPE was used instead of Positional Encoding from the original transformers paper. Some indicator on how these choices would have affected the foundation model training might have been good. (Although the feasibility of these ablations will depend on the pre-training computational requirements, which again cannot be inferred unless disclosed in the paper)",1
55,"This paper proposed a new algorithm for Hyperplane (2D subspace) clustering algorithm called hyperplane arrangement descent (HARD) that is both efficient and robust to outliers. This new family of algorithms solve a robust version of the Generalized Principal Component Analysis (GPCA) objective that uses a L1 norm for improved robustness against outliers, this new objective is called GPCA-l1.

This proposed GPCA-l1 objective can be optimized by a coordinate-wise algorithm called HARD-l1, however, this algorithm contains an inner optimization step that itself is cumbersome to optimize. Therefore the authors proposed to relax the inner optimization problem to a smoothed upper bound that can be efficiently solvable by SVD. The resulting algorithm is called HARD-l1+. The authors then study a smoother version of the GPCA-l1 that is called GPCA-Huber. Similar to HARD-l1, the authors relaxed the inner optimization of HARD-Huber to obtain a faster algorithm HARD-Huber+. 

The authors move on to prove that the ground truth hyperplane arrangement minimizes the GPCA-l1 objective, and that the HARD-l1, HARD-Huber and HARD-Huber+ algorithm can successfully find critical points of GPCA-l1, GPCA-Huber and GPCA-Huber+ respectively at convergence. However, the authors find it difficult to prove that the practical HARD-Huber+ algorithm converges to a critical point.

Lastly, the authors used synthetic datasets to show that HARD-l1+ and HARD-Huber+ achieves better clustering accuracy as well as significantly superior runtime compared to other subspace or hyperplane clustering algorithms. The new algorithms also outperform previous algorithms on a more difficult and realistic clustering problem involving latent embedding learned by a self-supervised learning algorithm on CIFAR-10.

Overall, the paper is very well written and clear, the logic is easy to follow. Although the practical algorithms don't have theoretical guarantees, their benefit is clearly demonstrated. I look forward to seeing more applications of those algorithms in the ML community.",1
56,"This paper addresses the issue that general-purpose search engines have inaccurate retrieval results for medical field content, especially for encephalitis research. Thus, they introduce a query-document set based on PubMed data. They further use GPT-4 to generate queries query varies that conceptually aligned but with different phrases and terms. A model is trained on the introduced data with contrastive loss. Results show the retrieval capabilities are enhanced.

Pros: 
* The motivation is strong and work on the task is urgently needed
* Dataset is sampled, the model is trained, and results show the model works. The entire lifecycle is demonstrated with sufficient information

Cons:
* Now info on the collected dataset is limited, it would be great to show the data distribution and provide some samples
* Evaluation result is brief, more interpretation and analysis are appreciated
* How the contrastive loss is calculated, and how the data variants are used for the loss calculation needs to be clarified",1
57,"This is good work, and the authors must show the error bounds when kappa is a function of solution itself.",1
58,"The paper is well motivated and showcases a convincing application of its proposed novel approach. It does lack a bit in terms of the details of the method, it would have been useful to get a deeper understanding of the way the physics constrained are introduced into the basis.",1
59,The paper is complete and accurate in describing what has been done. The proposed method seems to be working for experiments tested in the paper.,1
60,"Summary
-- the paper applies LoRa fine-tuning of a Mistral model to perform TNM phenotyping using pathology reports. 

Pros
-- they perform data augmentation using 200 real world pathology reports. They synthesize new reports by stripping relevant sentences from existing reports and replacing them with example sentences that were mapped to certain label classes a priori
-- the inclusion of an UNKNOWN label class in cases where the relevant information was missing
-- the use of JSON-enforced output 
-- reporting of training time as well as performance
-- the ability of the model to cite the relevant information
-- the use of LoRa here is interesting

Cons
-- While the data augmentation method is creative, the methodology is not described clearly enough and the quality of the resulting data is not examined. For example, ""These sentences were then injected into the template reports at randomly selected marker locations"" -- does this mean that the data is being pulled from a finite list of sentences in the JSON? If so, this is clearly not sufficiently representative of the diversity of natural clinical language.
-- unclear how the path reports were labeled -- what exactly was being labeled, and what were the qualifications of the labelers?
-- how did you strip the report of all info relevant for TNM using a script? How did you validate the accuracy of this process?
-- unclear how many data examples were generated in total. Also not clear whether or not the resulting dataset was high quality. It sounds like you replaced the parts relevant to TNM with random TNM ratings to augment the dataset. Were the resulting pathology reports realistic? It's not obvious that this procedure would result in realistic pathology reports.
-- Some irrelevant text, eg. there is no Section 5
-- This is an interesting application of LoRa, but it's just one task. A more comprehensive evaluation across several tasks would be much more compelling. 
-- ""We also attempt to develop a more generalized approach, so that our work can be applied to other NLP tasks within the medical field"" -- it's not clear where this was done",1
61,"**Summary**

The authors propose a clustering method which doesn't use any domain knowledge, i.e., does not use augmentation and is interpretable, i.e., centroids can be visualized and are semantically meaningful. They propose a skip connection that encourages the interpretability of centroids and use an auxiliary variable to optimize. Results support their claim, and consistently perform better than the baselines mentioned.

**Strengths**
1. Present a simple way to encourage interpretability using the skip connection.

2. Convergence analysis, ablation study and effectiveness of different loss components are presented in the paper. 

**Weakness**
1. The claim that the method is universal to any modality is incorrect. You need to change the architecture of auto-encoders for different modalities. 

2. Optimization section (3.1.1.) could be improved. I'm unsure if the optimization decomposition steps are done for different batches

**Minor**
Avoid using the term 'skip connection' as it holds a particular meaning in the literature.",1
62,"Quality: The evaluation is comprehensive and convincing. The authors first chose the best evaluator agent using dataset from Omiye et al. Then the evaluator was used to assess candidate responses from 10 LLMs across 13 questions. The authors also studied different combinations of prompts, and showed GPT-4 with simple prompts is the best evaluator.

Clarity: The paper is well structured and easy to follow.

Significance: Race-based beliefs in healthcare can be harmful and it constructs a major concerns for doctors to apply LLMs in clinical settings. Conclusion from this paper is important to guide doctors to choose the best LLMs in practice.",1
63,The concept being discussed in the paper regarding effect of the numerical method for solving the forward problem affecting the inverse problem is not novel and a widely known numerical analysis fact. The authors do not contribute significant experimentation to justify that they furthered the understanding of this phenomena.,-1
64,"Summary:

This paper proposes an auto-encoding architecture that implements convolutional sparse coding layers with weighting sharing between the encoder and the decoder. Trained with CTRL, the model exhibits decent scalability, structured representation, and superior sample-wise alignment.

Merits:

1. The paper is well written, carefully introducing and discussing technical details.

2. The direction toward more powerful white-box models is relevant and essential in the era of large black-box models.

3. The proposed approach is well-grounded with principles. Each component has a clear interpretation, including the convolutional kernels shared by the encoder, the decoder, and the CTRL objective.

4.  The method exhibits stronger scalability and reconstruction performance than its precursor CTRL.


Disadvantages:

1. I am unsure about the experimental comparison with popular deep-learning generative models like VAEs and GANs. If I understand it correctly, the proposed approach can also perform reconstruction, whereas VAEs and GANs are designed to sample novel samples from the training distribution. Therefore, the comparison in Table 1 seems unfair (or not comparable) to me. Plus, the lack of the capability of sampling novel samples is undesirable in comparison.

2. The encoding process involves iterative algorithms, which may significantly slow the training and induce numerical instability. On this aspect, it would be appreciated if the authors could offer training time reports contrasting the evaluated approaches.",1
65,"1.	The effort to control confounding factors by selecting participants with similar characteristics in this preliminary study is understandable. However, it's important to consider the potential trade-off between controlling variables and ensuring the model's generalizability to the broader population. With similar age and sex, the model may face increased difficulty in identifying individuals due to potential underlying differences in ECG patterns among different age groups and sexes. Given the limited diversity in the sample, there may be challenges in extrapolating the findings to a more diverse population. Future research could explore strategies to balance control over confounding factors with the need for dataset diversity to enhance the model's applicability across different demographics.

2.	Please further clarify the methodology employed to augment the dataset. Specifically, how were the repeated measures conducted and combined to generate such a large dataset (3276 sets) with 5 participants? Providing insights into this process would enhance the transparency of the study and offer valuable guidance to researchers interested in implementing similar data augmentation techniques in their work.

3.	I recommend the inclusion of measurements from ECG devices for comparison with the innovative self-manufactured device. To strengthen the evidence of the device's validity, it would be beneficial to authors include a figure comparing the measurements obtained from the new device with those from traditional ECG. This visual comparison could provide valuable insights into the device's accuracy and reliability.

4.	To ensure the robustness of the findings, it's crucial to provide details on the validation process for the model. Please elaborate on the validation dataset used to assess the model's performance.

5.	I suggest the authors consider using universal anatomical terms, such as transverse, coronal, and sagittal planes, to describe the human anatomy. Additionally, providing a fixed reference point when describing magnet induction intensity would be beneficial to prevent confusion and ensure the reproducibility and interpretation of the results. These adjustments could enhance clarity and consistency in the terminology used.

6.	I appreciate the authors' insightful approach to adding noise to mimic real-world environments. This strategy is particularly valuable as it reflects the common scenario where sensors encounter significant noise levels alongside the signal of interest. By incorporating noise into the study, the authors have taken a crucial step towards enhancing the realism and applicability of their findings to practical settings.",1
66,"The paper focuses on the Case-Based Reasoning (CBR) approach fused with Deep Learning (DL). The authors aim to address the persisting problems such as explainability, performance, and huge training data requirements, of DL approaches by the possibilities in the neuro-symbolic fused approach. The authors provide a brief literature review as a background of their research developments. The paper is well-written and explains the objective clearly. However, the paper needs attention to the following issues.

1. The Title does not match with the focus of the paper. It is stated as a short survey but emphasizes more on the developmental works by the authors. The survey naming is inappropriate as it only serves as a literature review.
2. The background works or literature does not delve deep into justifying the approaches and outcomes.
3. The ongoing research by the author is not explained very clearly and lacks numerical evaluative support. One accuracy graph and architecture diagram is provided. The architecture is not explained clearly and is not self-explanatory. 
4. There are no clear takeaway points from the research descriptions and conclusions.",-1
67,"**Summary:**

The paper proposes SleepFM, a foundation model for sleep, trained using contrastive learning on a self-curated dataset consisting of EEG, ECG, and respiratory signals. The authors evaluate their model on downstream tasks like sleep stage classification and apnea event classification, showing performance superior to end-to-end trained CNN models. They also perform retrieval tests, showcasing their model’s ability to retrieve one modality’s closest embeddings from the test set based on another modality’s embeddings. The embedding layer in their model consists of three CNN encoders for each type of signal data, and the model is pretrained on a contrastive learning objective. The paper also evaluates the impact of pairwise contrastive learning vs leave-one-out contrastive learning objective, showing better performance on the downstream tasks using the latter. For classification, the model uses the embeddings from the pretrained model and uses them to train a logistic regression classifier to evaluate downstream performance. The model shows good performance compared to the baseline in the paper across a wide set of experiments.

**Strengths:**

1. The authors introduce a fairly large-scale multi-sensory dataset of simultaneous measurements of EEG, ECG, and EOG signals, focused on training a foundation model from scratch. This dataset seems well-curated, and based on the downstream results, the embeddings from the pre-trained model have a positive impact on the performance on given tasks.

2. The motivation for using a contrastive-learning-based pre-training methodology using all three types of time-series data is sufficiently articulated and well-grounded with prior work in the paper. 

3. The pre-training, fine-tuning, validation, and test splits for the dataset are well-defined, mitigating the risk of any data contamination in the evaluation pipeline.

4. Owing to the availability of various types of paired time-series data in the pre-training dataset, the comparison of pairwise contrastive learning vs leave-one-out contrastive learning as the training objective was relevant and interesting.

5. The k-shot analysis of the model’s performance for classification was relevant, explicitly showcasing that contextual information learned during pretraining can improve downstream performance.

**Weaknesses:**

1. I am not sure I would call this model a “multi-modal” model, since the model is primarily trained on paired multi-variate time-series across different domains. EEG, ECG, and EOG data all lie in the time-series modality and are similarly modeled using the same type of encoders.

2. Experimental comparison with other recent statistical and deep learning methods for the given downstream tasks is necessary to have a more holistic understanding of the proposed model’s performance.

**Other recommendations:**

1. In future work, interpretability experiments to show what the model in learning would be interesting, and evaluating the model potentially in zero-shot settings would be appreciated as well.

2. Leave-one-out contrastive learning is not a new approach, and prior works from other domains [1,2] should be cited for the same.
  
    [1] Sanchez-Fernandez, A., Rumetshofer, E., Hochreiter, S. et al. CLOOME: contrastive learning unlocks bioimaging databases for queries with chemical structures. Nat Commun 14, 7339 (2023). https://doi.org/10.1038/s41467-023-42328-w
  
    [2] Xiao, T., Wang, X., Efros, A. A., & Darrell, T. (2021). What Should Not Be Contrastive in Contrastive Learning. International Conference on Learning Representations. https://openreview.net/forum?id=CZ8Y3NzuVzO",1
68,"**Summary:** This paper examines the learnability—specifically, the lower and upper bounds on the optimal decision rule—for aggregating binary predictions from conditionally independent experts. The authors' key contribution lies in establishing sharp upper and lower bounds on the total variation distance between two product Bernoulli distributions with arbitrary means.

**Strength:**

1. **Theoretical Contribution with New Bounds**: This paper provides new upper and lower bounds on error probabilities in the asymmetric case, extending previous work on aggregate expert error. These bounds contribute to a deeper understanding of error probability in cases where sensitivity and specificity differ, addressing a previously less-explored aspect of the problem.
2. **Careful Mathematical Approach**: The authors present proofs and derivations systematically, with supporting lemmata and auxiliary proofs that strengthen the findings. This structured presentation is well-written, which helps readers follow the reasoning clearly through the mathematical arguments and supports the reliability of the results.

**Weakness:**

1. **Lack of Empirical Validation**: Although the paper’s theoretical contributions are well-developed, it lacks empirical validation or simulation studies to demonstrate the real-world applicability of the bounds. I understand that this conference primarily emphasizes theoretical perspectives; however, I believe that theory should ultimately enhance our understanding of practical models. Simulation studies could clarify how the derived bounds perform in practice, especially across diverse scenarios (e.g., naive Bayes and crowd-sourcing). Including a simulation section to demonstrate the tightness of the bounds across varying sensitivity and specificity conditions would allow readers to better assess the practical utility of these results.
2. **Limited Discussion of Practical Applications**: Although the theoretical results have potential applications in fields like crowd-sourcing and ensemble learning, there is minimal discussion of these possibilities. A more detailed application section would benefit readers interested in practical use cases. The authors briefly mention the relevance to decision theory but do not elaborate. Expanding on this could make the implications clearer for applied researchers.
3. **Dependence on Conditional Independence**: The assumption of conditional independence among experts is central to the derived bounds. It would be insightful to explore whether the bounds still hold when allowing for dependencies structured by a finite-dimensional covariate $Z$, i.e., $X_i\perp X_j\mid(Y,Z)$, where $Z$ denotes some finite-dimensional covariates.

**Minor issues**

1. **Complexity of Notation**: The paper makes extensive use of notation, which, while mathematically rigorous, could be redundant. For example, I think the introduction of $\gamma_i$ is not necessary in Theorem 3; explicitly write the bound with respect to $\pi_i/\bar{\pi}_i$ is easier to follow.
2. **Reference Style**: Ensure uniform citation styles throughout the document; some references seem to vary in formatting.",1
69,"CRoW is an interesting benchmark for commonsense reasoning published at EMNLP (I could not find the proceedings to check). Evaluating the capabilities of commonsense knowledge seems relevant to the topic of the workshop. The extended abstract gives a good overview of the paper, and the results are interesting and useful for this community. 

The only thing I'm missing is an example of (one of the) tasks to get a better idea of what the benchmark looks like.",1
70,"I am impressed by the use of the Swin transformer to accelerate inference through the application of appropriate training protocols, achieving high accuracy. However, I believe there is a need for more detailed information about the dataset. Providing a comprehensive overview of the sources of the various datasets used in the challenge would greatly enhance the clarity and replicability of the research.",-1
71,"The paper provided clear understanding of problem statement, and necessary background information to understand the challenge faced by less accurate techniques for detecting co-morbid ADHD. The data used for training, however, is from a platform that is biased in representation of general population, which is also acknowledged by the authors, and also appropriately explained the limited scope of the application of the results discovered by the authors.
The quality of work is good and meets the expectation. I do not consider myself to be able to comment on the originality of the work, as I need more experience in the field to be fair in my evaluation, however, the work is fairly original in my opinion. Significance of study presented is that it provides the comparison of three different models in performing classification for the task at hand, and find a model that outperforms the other two by a significant margin. 
Pro of the paper is that it has found a model that has significantly higher prediction accuracy over other models.
Con of the paper is that the data set is biased and the visualizations cannot be published to protect the patients.
However, the results of the study are significant enough to outweigh the cons. This paper deserves publication in the esteemed conference.",1
72,"The authors use so called dynamical neural network that are analytically fit to a LTI system. It thereby lifts a restriction of previous work that did not allow for clustered eigenvalues in the LTI system. Each eigenvalue block thereby maps, effectively, to an independent neural network.

The authors clearly state that they consider the present work as a stepping stone for more complex predictions. As such I can accept that no neural network training is involved in their work. Nonetheless, it poses for me the fundamental question why the maps considered in the paper with ""neurons"" that are ODES are neural networks and not just nonlinear maps that correspond to a LTI.

Minor: based on the usage in the text, most citations should be (X, 20XX) and not X (20XX",1
73,"This paper addresses a variant of the best-arm identification (BAI) problem where the best arm is defined as the one with the highest q-quantile reward, with a key communication constraint: feedback from the sensor to the learner is limited to a single binary (1-bit) response. Specifically, the learner sends threshold queries of the form, ""Is the reward smaller than a given threshold?"" to the sensor, which responds with a single bit indicating whether the threshold was exceeded. The authors relaxed the problem into identifying ϵ-best arm(s). A crucial assumption in the paper is that the q-quantiles of all arms are bounded by a known constant, an assumption that may be questionable in cases where rewards are unbounded.

The authors propose an algorithm capable of identifying the best arm with a specified confidence level and derive an upper bound on the sample complexity. This upper bound consists of three main terms: the first matches a lower bound for the case without communication constraints up to a logarithmic factor, the second depends on the logarithm of the inverse optimality gap, and the third is a logarithmic term influenced by a tuning parameter, the number of arms, the quantile bound, and the relaxation margin ϵ. The dependence on the first term suggests that the 1-bit restriction does not significantly affect the algorithm’s performance in the ""low error probability/high confidence level"" regime. Additionally, the authors present a hardness result, showing that the third term is unavoidable in the worst case if the threshold query model is used. The authors conclude with a discussion on solvable instances based on the sub-optimality gap, modified to account for ϵ-relaxation, along with a review in the appendix on how traditional sub-optimality gaps are less effective under this relaxation setting.

Major concerns:
1. Inverse-Square-Based Problem Complexity: I recognize that bounds of this type are common in the BAI literature (e.g., Mannor and Tsitsiklis, 2004; Nikolakakis et al., 2021 for QMAB). However, I am concerned about the practicality of such bounds in this context. For instance, a closer examination of Theorem 13 reveals a 1/27 factor hidden in the big-O notation. Similarly, while the authors did not show it explicitly, I suspect large constants are also present in Theorem 11. Such large hidden constants can undermine the practical relevance of improvements in sub-optimality gaps, as they reduce the actual efficiency gains compared to prior work.
2. Focus on Sharp, Constant Optimality in Recent BAI Advances: Recent developments in BAI have emphasized not only order optimality but also sharp, constant optimality, particularly in the asymptotic low-error probability regime (e.g., Garivier and Kaufmann, 2016, and follow-up works). These works introduce a clear and explicit form for problem complexity measures instead of relying on big-O notation and inverse-square-gaps, along with a discussion on the connection to gap-based complexity measures. I find this approach more informative and practical, as it provides more accurate insights into algorithm efficiency.
3. Strong Assumption on Bounded Quantiles: The assumption that quantiles are bounded appears overly restrictive and seems introduced primarily for analytical convenience. For instance, in parameterized settings (e.g., normal distributions), high quantile values naturally arise without necessarily increasing problem complexity. Such a restriction appears especially limiting as the bound must be directly accessible to the algorithm. 
4. Lack of Clarity in Algorithm 2 Description: The description of Algorithm 2 lacks clarity. For instance, Line 1 iterates over t from 1 to O(1/\Delta^2 \log(n/\delta)). Using big-O notation within an algorithm is problematic - how would this bound be specified in practice, especially given its direct relationship to sample complexity? Furthermore, including more details from Gretta and Price (2024) would enhance completeness and credibility, as many details critical to implementation are currently hidden.
5. No Numerical Evaluation of the Proposed Algorithm: The absence of numerical results raises concerns about the practical applicability of the proposed algorithm. Numerical experiments would help illustrate the algorithm's practical performance, especially compared to existing algorithms. Given the claim that ""restricting to 1-bit feedback has a minimal impact,"" empirical validation would strengthen this claim by demonstrating the algorithm’s comparative performance under full feedback conditions.

Additional concerns:
1. Complexity of Gap Definition: The gap definition in (13) is significantly more complex than in prior work. While using the upper quantile level may improve gaps in cases of discrete support, the improvement for continuous distributions (e.g., normal) is unclear. How does considering all subsets S improve the gap? Simple examples illustrating this would be helpful. Also, a discussion on when these gaps are positive would clarify the practical implications of this definition.
2. Implications of ϵ-Relaxation: The use of ϵ-relaxation changes the problem fundamentally from standard quantile-BAI. Specifically, the potential for multiple correct answers (Degenne and Koolen, 2019) introduces additional challenges, as this scenario is known to be more complex than conventional BAI. For QMAB, could exact quantile-BAI potentially be easier than the ϵ-relaxed version? Furthermore, the paper lacks a discussion on setting an appropriate ϵ value, which is a crucial factor in applications of ϵ-relaxation.",-1
74,"The paper proposes an unsupervised method for learning a unified representation that serves both discriminative and generative purposes enjoying the mutual benefits of having both. Their work illustrates that the structured representation learned is discriminative and simple classifiers applied to learned features yield high classification accuracy. In addition, it poses enough diversity to recover raw inputs, and
46 structure that can be exploited for sampling and generating new images. Some key positive and weakness are listed as:

Strength:
1. Their formulation benefits from the mutual benefits of both discriminative and generative properties.
2. It is interesting that closed-loop transcription through the maximin game between the encoder and decoder has the potential to offer a unifying framework for both discriminative and generative representation learning, across supervised, incremental, and unsupervised settings.
3. The paper is very well written and it includes many interesting ablation studies + experimental details (eg. cluster analysis in the appendix).

Weakness:
1. Table3 indicate that the performance U-CTRL still lags behind in comparison with traditional purely discriminative self-supervised learning methods like SimCLR, MoCo, etc. Although, I agree that it carry the benefits of both world. Can authors add more recent beaslines like oCoV3 etc.
2. Results should be included with standard deviation, and how closely the evaluation setting of baselines relate with the proposed method is not yet clear.
3. Additional results on classical image generation datasets will make the paper more convincing.",1
75,"## Strengths:

### 1. Comprehensive Evaluation:

The paper provides a thorough comparison of multiple models (EfficientSAM, LiteMedSAM, MedSAM) across various medical image modalities, highlighting the strengths and limitations of each model.


### 2. Methodological Rigor:

The incorporation of advanced techniques such as model quantization, ONNX format for runtime optimization, and fine-tuning strategies like Sharpness-aware Minimization demonstrates methodological rigor and a strong understanding of the field.

### 3. Practical Relevance:

By focusing on CPU deployment and evaluating performance in real-world clinical settings, the study has significant practical implications for making advanced segmentation models accessible in resource-constrained environments.
## Weaknesses:

### 1. Efficiency:

While the challenge is to deploy the MedSAM on a laptop, the proposed method's efficiency is only slightly better than that of baseline. (only 10% improvement on case 3DBox_CT_0566).",1
76,"The work ""Benchmarking Common Factors in Psychotheraphy Using AI Systems to Enhance Provider-to-Patient Dynamics to Improve Patient Outcomes"" is a really interesting paper that comprises a kind of a foundation model for neuro-symbolic AI connected with physchotherapy. However, there are several points that need to be clearly addressed before the work can be accepted for publication. To be clear enough, the general reviewer remarks are given in the form of numbered list provided below.

1. The Authors in the section ""Method"" wrote ""(...) We built our initial models using labeled data derived from (...)"". This statement is not really clear. The Authors need to address what was the structure of the data and how much of them were taken into account when it comes to the training/testing dataset. Right now, the overview of the data is missing.
2. In section ""Method"" one can also read that the Authors used methodologies for generation of the synthetic samples. However, once again, the description of the used algorithms and methods is missed. It is unclear what was the approach to generate these samples. The Authors must specify what kind of AI models or methodologies were consumed to generate the synthetic data. On the other hand it is also unclear how much samples were generated in that manner. This information is also needed to appropriately validate the worked-out models.
3. Section ""Preliminary work"" - there is information that Machine Learning models were used to create NLP algorithms. However, once again the details are missing. The Authors have to provide information about the algorithms that were used in their approach. Right now, it is impossible to understand the approach.
4. ""Findings to be Reported"" - one can read information about the levels of accuracy in detection of Appreciation and Toxicity/Confrontation - however, once again there is no sufficient details. How the algorithms were evaluated? What kind of approach was used for this aim? How the database was split and how much samples were consumed. All these questions need to be addressed.

To sum up, I would like to recommend the work for publication but only after major revision that will address all the statements given above.",-1
77,"The paper presents ""SleepFM,"" a multi-modal foundation model for sleep analysis using large-scale polysomnography (PSG) data, including EEG, ECG, and respiratory signals. The model is trained via contrastive learning and demonstrates superior performance in tasks like sleep stage classification and apnea detection compared to traditional CNN methods. The innovative aspect of using a leave-one-out approach in contrastive learning for multi-modal data integration is highlighted, showing significant improvements in model performance.

As author stated in the limitation section, more external datasets are needed to prove the work as a foundation model. Also, it would be great to see the performance of using only one kind of signal as downstream task, e.g. ECG-only for sleep staging.",1
78,"Image encoder is replaced with EfficientVit, and distilled from the original baseline. Validation results seem to rank among the top 10.

The C++ implement using OpenVino seems to significantly improves over the baseline.

One concern seems that the C++ implementation needs custom built on the authors' computer, whether that works the same in the docker in the test will affect the final results.

Some drawbacks:

In Fig 1 upper graph, MBC and F-MBC blocks are not explained in this paper.
In Fig 1 lower graph, the algorithm framework has no difference with the baseline.

In loss function, how did you derive the 20:1 ratio of Focal loss and dice loss?",1
79,"## Overview: 

In this paper, the authors ""propose a framework for understanding linear models in tangent feature space where the features are transformed"". This enables them to gain new insight on settings that have challenged the traditional neural tangent kernel analysis, particularly in realistic, finite size neural networks that are trained on standard data (e.g., MNIST, CIFAR-10). 

## Strengths:

1. The paper deals with an interesting and important goal of extending analysis beyond the NTK, where the gradients are fixed.
2. The authors develop a general framework, which enables them to study a range of problems.
3. The authors are upfront with their models' assumptions and limitations. They should be applauded for their honesty and directness.
4. The analysis provides enhanced (by an *order* of magnitude) low-sample performance of feature learning, as compared to the traditional fixed gradient analysis. 

## Weaknesses: 

In general, I found this paper challenging to follow. I think this is mostly a failing on my end (hence, my low confidence), but I do think there are several ways in which the authors could make their work more clear. 

1. Low-rankedness: How do the assumptions shape the identified ""low-rank perturbation"" in Theorem 1? Is it a direct consequence of the assumptions, or a more general aspect of the adaptive feature perspective? I am also unclear whether the low-rank perturbation necessarily counts as a low-rank solution, as the phrasing in the abstract suggests (""with structured regularization that encourages approximately low rank solutions"" [lines 6-7]). 
2. A little more detail on how, in the structureless feature learning case (where features are able to evolve) the same solution as the standard NTK analysis emerges, would be helpful. From the motivation of the work in the introduction, I found this surprising, as I was under the assumption that changes in features would necessarily lead to a departure from the NTK.
3. More discussion surrounding the results of Theorem 2 would also be helpful. I found them challenging to interpret, and the numerical examples, while seemingly promising, were not explained in as much detail as I needed to fully understand them. Particularly, I did not feel like I fully understood Figure 3. 

## Summary: 

This paper tackles an interesting and important question, which is relevant and aligned CPAL's research areas.  While the numerical results seemed promising, I did not feel like I fully understood them, nor the analytical theory. If the authors could provide some additional insight, I would very much consider increasing my score.",1
80,"The authors propose a methodology using differential evolution combined with covariance matrix adaptation to optimize physical numerical simulations efficiently and then employ the samples collected to train a surrogate model, namely fourier neural operator (FNO). This surrogate may be used to enhance the optimization process by accelerating sampling. Although this approach was successfully applied to optimize a hydrodynamic numerical simulation, it has potential for application in other disciplines requiring physical simulation optimization.

The present study is potentially of interest for calibrating and tuning numerical simulations across different research fields, such as climate science. While the aim of the paper is clearly defined in the manuscript, the text would benefit from further specific details to better understand the results and their implications. The theoretical concepts are concisely presented. The figures and the experiments are in general sound, but the text can better highlight key points (Section 4.1). 
Specific comments:
- Section 2 – Approach. The mutation factor (αm) and the crossover factor (αc) seem to be arbitrarily chosen to 0.5 and 0.2, respectively. A motivation or strategy defining these factors is missing. Moreover, how sensitive are the results presented here to these factors. 
- Section 2 – Approach. How is the loss defined (selection)?
- Section 4 – CMA-DE on Simulation data. Why is the fixed point in time defined as 0.2 µs?  How do the population size and training sessions affect the results?
- Section 5 – FNO. Non-linear activation function “such as ReLU”, is this the function used? “Trained overnight” can be better defined, it is a bit vague.
- Limitations. To me this approach requires to a good extent expert knowledge (e.g., defining control parameters and their likely ranges, or “crash”).",1
81,"**Summary of the paper:** The authors present a neural tangent kernel (NTK) approximation for training physics-informed deepOnet more accurately and faster, by computing a conjugate NTK with only the last layer of the network. The proposed method achieves similar performance as full NTK computations but allows for much faster training.

**Strength of the paper:** The paper does a good job at introducing the main differences between NTK and conjugate kernel, and the motivation behind developing fast NTK approximations. It also describes well key aspects of physics-informed deepOnet, and how they fit within NTK computations. The results are sound: the conjugate gradient achieves similar accuracy as NTK, with a significant training time gain.

**Weakness of the paper:** My understanding is that NTK/CK are only used to compute weighing terms in the loss function, but the deepOnet weights are updated using a standard gradient descent. For someone not familiar with NTK, this is somewhat confusing, as equation 1 and 3 may intuitively lead to think that NTK updates neural network weights in a different fashion than standard gradient descent. In table 1, it is also unfortunate to use the term ""weight"" to refer to $\lambda_i$, as this may be mistaken with the network weights/parameters. 

I wish the authors had expanded on the accuracy results for CK and low viscosity Burgers equation. It is surprising that CK achieves better performance than NTK, given that CK is an approximation of NTK. Do the authors have an idea why this happens?",1
82,"In this work the authors bundle a pre-training dataset consisting of several open source cohorts, a vision-language model trained on said dataset, and a suite of benchmarking tasks to compare performance of foundation models in the space of chest X-rays interpretation.

The work is impressive and might have benefited from a longer write-up as with the 2 page constraint it is challenging to thoroughly describe all aspects of the work. I would have liked to see a less succinct explanation of the model and the datasets, in particular how the splitting between training and testing was done. Additionally, a section regarding limitations of the current work and ways into clinical application would have been appreciated.",1
83,"The paper revisits the problem of obtaining generalization bounds for neural networks with non-linear Lipschitz activation functions at each layer. Specifically, by analyzing the Gaussian complexity of a network, they show that for deep multi-layer networks, the generalization error is bounded by a term that involves the minimum of the ranks of the weight matrices at each layer (plus other terms like the product of appropriate spectral norms).

The analysis proceeds by using a chain rule expression for Gaussian complexity that was developed in the work [Maurer 2016]. This lets them bound the Gaussian complexity by the product of the _spectral norms_ of the weight matrices, times the minimum rank. Compared to previous work that has the product of Frobenius norms (e.g., due to Golovich et al.), this bound can be significantly better as it avoids a ""product of the ranks"" type term.

The proof itself is quite clean: it follows from the chain rule, along with bounds on (a) the diameter of the images of inputs, and (b) the term R() that arises in the chain rule, that is related to the coefficients.

Overall, the result is nice in that it can significantly improve the known generalization bounds for rank-constrained networks (which are well-motivated in applications). The weakness is that the paper appears to be a fairly simple consequence of the chain rule for Gaussian complexity. I lean towards accepting the paper overall.",1
84,"This paper studies the problem of computing center-based approximations of distributions that change over time, a.k.a, drifting distributions.
Specifically, for a given positive integer parameter k, the goal is to output k centers that best represent the current distribution, meaning that they minimize the average, for a point sampled from the (unknown) distribution, of the z-th power of the L2-distance between the point and its closest center.
The paper formalizes this setting and provides both an algorithm and a lower bound.
The algorithm proceeds by running any given approximate clustering algorithm on a sliding window of points, where the window size is dynamically set as a function of the (unknown) drift of the underlying distribution. The paper proves a clean upper bound on the error this algorithm (Theorem 2 and Lemma 3) in terms of the approximation factor of the given clustering algorithm as well as the statistical and drift errors.
On the lower bound size, the paper shows for the k-means objective and in the regime where the approximation factor goes to 1 and the dimension goes to infinity, their upper bound is asymptotically tight.
Finally, the paper runs an empirical evaluation on a synthetic dataset.

The strengths of this paper are:

1) The algorithm is quite natural, and it is plausible that a variant of it could be used in practice.
2) The results are neat, and the paper is well-written.

The weaknesses of this paper are:

1) It’s unclear how natural the lower bound construction is.
2) It’s unclear how tight the lower bound is in general (in terms of the exponent of k and Delta).
3) It's not very clear how valuable the lower bound is in the regime as the approximation factor goes to 1, since k-means clustering is NP-hard in that case. I feel that the paper would benefit of some discussion of this. 
4) The empirical evaluation is limited to a synthetic distribution. (This is unfortunate as it would have been valuable to see how well the algorithm performs on a real dataset. That said, this shouldn’t be held against the paper given the scope of ALT.)

Overall, I feel that the strengths of this submission outweigh its weaknesses, and that it would be a good addition to ALT. I support acceptance.",1
85,"Strengths:
1. The table in the paper very clearly shows the test results on the benchmark.
2. As per shown by the results, the benchmark provides a reasonable evaluation of the capability of LLMs on commensense reasoning.
3. The designed workflow is reasonable.
4. The quality of the data is high, with a clearly defined task and human benchmark.

Weakness:
1. The length of the paper is relatively short, as there could be more imperial analysis done to further demonstrate the characteristics of the benchmark.
2. There could be more in-depth tasks designed based on the benchmark besides a binary task to further demonstrate the reasoning capabilities of the LLMs.",1
86,"**Summary**   
This work studies the sparsity in the input image as well as the model parameters in vision transformers. Specifically, this paper focuses on the transfer learning from a pre-trained Masked Autoencoder (MAE) and ViT, where the backbone ViT encoder is fixed and only a MLP is trained on image classification tasks. With empirical study, it firstly finds that applying a fixed mask pattern on patches of all examples can achieve comparable or even better performance of applying random mask to different examples at different iterations. This finding suggests that dataset can be stored in reduced size by removing some patches, i.e., masked images. Secondly, this paper finds that masked images can even enhance the performance from original images. Lastly, this paper proposes to train the model in a distributed setting via Independent Subnetwork Training (IST), where a subnet of the dense net is deployed and trained on different nodes/sites. This distributed setting can further reduce the workload per worker. 


**Strengths**   
The findings of utilizing fixed mask pattern or random mask pattern in transfer learning is interesting, and the proposed masked image storage is also helpful in practice.  


**Weaknesses**   
1. Most conclusions of this paper are based on transfer learning, where the ViT backbone is fixed and only a shallow MLP is trained. Thus, whether these conclusions can generalize to training from scratch. For example, when training MAE with a fixed mask pattern, can we get a similar conclusion? Meanwhile, this paper does not mention this transfer learning setting in the abstract and summaries, but try to claim these findings are generalized conclusions. To this end, it would be better if the authors can fix the overall tone of this work. 

2. The need for distributed training of the MLP layer in transfer learning is in doubt. This paper only evaluates a two-layer MLP in transfer learning, which can easily fit  into any modern GPUs or even edge computing. Thus, the usage of distributed training, which splits this lightweight MLP into several subnets, may not be necessary. Thus, the contribution of this part can be challenged. It would be more meaningful if this paper shows that the proposed distributed training pipeline can be generalized to some heavy models, such as LLM and Stable Diffusions, where we even can not load the entire model into a single GPU. 

3. Some contents in this paper are kind of redundant. For example, Figure 5 and Figure 6 is just the visualization of all data in Table 4. Since this paper only aims to show the linear relationship between the mask ratio and the dataset size, which can be easily concluded from the equation in Line 261. Besides, Figure 6 aims to help claim the relationship between mask ratio and performance (Line 265), but shows it with dataset storages and performance, which is kind of misleading.",-1
87,"This paper studies domain generalization via nuclear norm regularization.

**Quality:** 
The paper is technically sound with extensive experiments and some theoretical analysis. The method is simple but effective, and results are strong across diverse datasets.

**Clarity:** 
The paper is well-written and easy to follow. The method and experiments are clearly explained.

**Originality:** 
Applying nuclear norm regularization in this context is novel and provides a useful regularization technique for domain generalization.

**Significance:** 
This technique could have a practical impact given the strong empirical results. The theory also provides new insights.

## Pros
1. Simple and efficient method that consistently improves over baselines.
2. Strong performance across a wide range of benchmark datasets.
3. Theoretical analysis offers insights into benefits of nuclear norm.
4. Easy to implement and combine with other methods.
5. No need for domain labels or changes to model architecture.

## Cons
1. Theoretical assumptions are restrictive; analysis is only for linear models.
2. Gains over existing methods are incremental, not a dramatic breakthrough.
3. Needs some hyperparameter tuning of regularization weight.
4. Sensitivity to hyperparameters could be analyzed more.
5. More analysis to connect theory to deep networks would be beneficial.",1
88,"This paper introduces a new PyTorch interface, PINA, for developing ML models based on the PINN and/or NO methodologies. PINA is built upon Lightning, and therefore benefits from its features. This is achieved mainly by providing a Trainer class wrapping Lightning’s trainer. Details are provided about the API, and a few results are shown.

The proposed framework seems useful for implementing various existing ML methods for solving PDE-based problems. The engineering effort behind PINA provides a productive way to develop new methods and can facilitate the deployment of those methods on different hardware setups.

While the engineering effort deployed to compose the interface with Lightning can be useful, the originality/novelty of the proposed framework is questionable and there are a couple of flaws in the mathematical formulation of the problem (see below). More specifically, the main contribution is to provide a wrapper around Lightning’s Trainer class and most of the claimed advantages of PINA over related methods in the literature (e.g., multiple device training, modern model compression techniques, gradient accumulation, logger insertion for monitoring, etc.) are consequences of having a Lightning backend and do not result from new features introduced in this work. Also, the paper mentions that existing packages can’t combine the PINN and NO methodologies. However, the DeepXDE package [1] provides support for PINNs as well as DeepONet, a well-known type of NO. In addition, further experiments comparing PINA against competitors from the literature could improve the dissemination of the package.

As for the related works, the paper misses out on prior works on the subject of software for PDE learning, see [2, 3], which should be included.

Lastly, the paper contains several flaws in the mathematical formulation of the problem:

- There are a few problems with equation 1:
	- z is said to indicate the spatio-temporal coordinates, however $z \in \Omega$, where $\Omega$ is the spatial domain. In fact, equation 1 is effectively a steady problem, i.e. with no time dependency, which is a pretty restrictive assumption for software tackling PDEs.
	- $\mathscr{B}$ cannot be used for initial conditions given that the problem is time-independent.
	- $d_{z}$ is not defined
	- $\Omega \in \mathbb{R}^{d_{z}}$ → $\Omega \subset \mathbb{R}^{d_{z}}$
	- the spaces $A$ and $U$ are not defined

- In equation 2, $u^{\prime}$ and $u$ are not defined. I assume you meant $G(u\prime_{i}) = u_{i} \quad \forall 1 \le i \le N$ ?


[1] Lu et. al, DeepXDE: A deep learning library for solving differential equations, SIAM Review, arXiv.1907.04502, 2021.

[2] N. Bouziani and D. A. Ham, Physics-driven machine learning models coupling PyTorch and Firedrake, ICLR 2023 Workshop on Physics for Machine Learning, arXiv.2303.06871, 2023.

[3] P. Kidger, Diffrax - On Neural Differential Equations, University of Oxford, arXiv:2202.02435, 2021.",1
89,"## Summary

In **"" OneSAM: One model for segment anything model in medical images on Laptop,""** the authors propose the use of a combination of models, i.e., LiteMedSAM and their proposed model (OneSAM). OneSAM differs from LiteMedSAM in using image encoder adapters and an alternative mask decoder. Specifically, they add image encoder adapters to each transformer block of LiteMedSAM. Additionally, they replace the LiteMedSAM mask decoder with the SAM-HQ mask decoder. OneSAM is then trained using the training dataset provided by the challenge and is evaluated against the baseline. LiteMedSAM or SAM-HQ are chosen for final inference, given their individual results across modalities. The best model for a specific modality is selected for final inference. Overall, I don't think the manuscript provided enough information for **reproducibility**.  Below, I give several suggestions to improve the manuscript's **completeness** and **reproducibility**. 
 ## Detailed Comments
**Abstract:** 

1- The abstract does not contain any information about the author's proposed method for the challenge, and it does not contain any results whatsoever. 

**Introduction:** 

2 – Background: The authors state ""... enhances the performance of *conventional* LiteMedSAM"". However, LiteMedSAM is not a conventional method. Here, the authors could provide more background information about the difference between MedSAM and LiteMedSAM and rephrase this sentence.  
3 – Related work: The transition between the second and third paragraphs seems odd, as you moved from discussing SAM to MedSAM and then back to SAM. Additionally, this section lacks related work on model adapters and SAM-HQ as mask decoder, which seems more relevant if included, given that these are the approaches used by the authors. 

**Method:** 

4 – Preprocessing: There are missing details about input data dimensions.  
5 – Proposed method: Given that, as the authors say ""the proposed method is derived from LiteMedSAM"", I'd expect at least a small description of LiteMedSAM so the authors could indicate where their innovation lies.  
6 – Image encoder adapter: Could the authors provide what the acronyms in equation 1 stand for? 

**Experiments:** 

7 – Dataset and evaluation measures: The authors say, ""The same dataset is used for both tasks"". What are ""both"" tasks?   
8 – Table 1: The provided code link is for a GitHub account profile.  
9 – Training protocols – data sampling strategy: When the authors mention ""the number of training samples increased"", could they mention by how much and compared to what?  
10 – Table 2: is the initial learning rate 1 or .001? Additionally, the authors did not provide a number of flops or CO2 footprint.  
11 – Training protocols – Training procedure: It is unclear in the text whether you are just training the model adapters and mask decoder, which is what I had to assume. However, by inspecting Table 2, I see that the number of trainable parameters is virtually the same as the number of model parameters, which makes me think that you are not just tuning the model adapters and mask decoder. I would expect more detailed information here.  

**Results and Discussion:** 

12 – In the Results section, it is clear that the authors only used OneSAM for a few modalities and LiteMedSAM for others, where LiteMedSAM provided more accurate results. Then, I'd say their approach is a combination of modality-specific approaches. This should have been clearer early on, e.g., in the abstract.  
13 – Is ""+ SAM-HQ mask decoder"" equal to LiteMedSAM with replaced mask decoder? That is, without adapters? Can you provide more detailed information in the table caption?  
14 – In ""Segmentation efficiency results on validation set"", is ""the average used GPU memory is 2478 MB"", correct? I assume these results are determined under the challenge condition, i.e., edge device settings, which do not include a GPU.  
15 – Figure 2 **only** shows examples where the authors' approach performed well.  
 
Checklist table:  
-	The title is unclear and confusing.   
-	Validation scores are not presented in the abstract or the proposed approach.",-1
90,"This paper presents a significant study focusing on the lexical characteristics of the healthy aging population using natural speech datasets and psycholinguistic metrics. The results reveal that parts of speech distribution vary with gender, while lexical concreteness correlates with age, contributing valuable information to the understanding of language variation in aging. The following points could be considered:
1. It would be beneficial to include a comparison with existing studies on younger populations or those with cognitive impairments.
2. Given that the study is based on Singaporean English speakers, how do you anticipate the findings to generalize to other English-speaking populations or languages?
3. How were the audio recordings standardized across participants to minimize environmental and technical variations?",1
91,"The paper considers the problem of neurosymbolic learning and aims to improve it by improving the training of the embedding model for logical statements, evaluating the quality of the embeddings to determine if they model the original semantics and finally improving the reasoning using a downstream scoring function.

The paper is well written and is quite relevant to the topic of the workshop. I would certainly like to see this presented at the workshop and get some more detailed feedback from the poster session.

Of course, standard improvements including improving the empirical and theoretical analyses, adding different types of KGs and baselines are possible which I am sure that the authors would consider before submitting this to a conference. 

Over all, this is quite exciting work that I enjoyed reading.",1
92,"This paper explores a center-based approximation approach for handling drifting distributions. Given a pre-defined k, the authors approximate recent observations in a sequence using k-center clusters. This approach is applied to a two-dimensional sequence of Gaussian mixtures with varying means, assuming independence between the dimensions and equal variance. 

However, the motivation behind using a center-based approximation for a drifting distribution is unclear. For such sequences, a changing slope model would be a better fit. Changing slope models typically struggle with high-dimensional data sequences due to the complexity of parameter estimation, particularly for the covariance matrix. Yet, in this study, which focuses on two-dimensional data with a scaled identity matrix as the covariance matrix, these challenges do not arise, making the changing slope model an ideal fit.

Alternatively, even a change point model would be preferable to the k-center approximation. Unlike the k-center approach, a change-point model accounts for temporal information, clustering observations that are temporally close – an essential aspect of drifting distributions.

Furthermore, the reliance on a pre-defined k renders the model somewhat ad hoc. In contrast, both the changing slope and change-point models provide data-driven methods to determine the number of change points, enhancing flexibility and adaptability to the data.",-1
93,"Summary of Contributions:

The work proposes a new way to efficiently fine-tune SAM for medical image segmentation, i.e. a custom lightweight ConvNet head after the SAM encoder. The SAM encoder undergoes parameter efficient fine-tuning by using Low Rank Adaptation. The authors claim and demonstrate that fine-tuning SAM is better than fine-tuning MedSAM, i.e. for successful adaptation, medical pretraining is not necessary.

Strengths:
1. The authors challenge the popular belief that foundation models should be pre-trained with data from the domain where they are to fine-tuned, and successfully demonstrate that (in their own words) “generalist models like SAM need not be abandoned in favor of models with medical pre-training” 
2. The work experiments with various decoder networks for fine-tuning SAM and MedSAM.
3. The paper is easy to follow and the Block Diagrams are representative of the methods provided in the work.
4. Preprocessing steps, training hyper-paramters, along with memory requirements have been provided.

Weaknesses:
1. The work does not provide quantitative comparisons with specialist models (i.e. models trained from scratch on the given dataset, say UNet, which inspired the Convent decoder)
2. The work only provides fine-tuning results for a single dataset. Ideally two more medical image segmentation dataset (such as BraTS, VerSE, etc.) should be included.

Questions, Suggestions, Comments:
1. What are the input and output dimensions for the images?
2. It is not very clear that how the decoder from UNet is used, more specifically: the UNet decoder uses a prior from the encoder after each upscaling step (in the form of residual connections). What priors (if any) are being used in the proposed decoder ConvNet?
3. Addressing the weakness will definitely improve the quality of the work, and make the author’s claim more substantiated.",1
94,"1. The author's ORCID is missing.
2. The equation on page 6 is not numbered.
3. The complete code link is not provided.",1
95,"# Review to 17
Strength:
- This paper studies the problem of generating medical data while preserving privacy. This is an interesting and important problem.
- The idea of combining Bayesian optimization and privacy-preserving generative models to generate informative and differentially private data is novel.

Weakness:
- The optimization specification and pseudo-code is a bit hard to follow. Here are some questions/problems: 
-- definition of $K$
-- I assume $\mathcal{X}_i$ is the $i$-th dimension of the input space. Is my understanding correct? If yes, please define the notation.
-- When sampling from $[\alpha_i, \alpha_i+\beta_i]$, I assume a uniform distribution is used. Is this correct? If yes, please specify.
- The empirical results are not so impressive. 
-- It seems that the data augmentation, both standard and PriSHA, can only improve the AUC marginal (85.30%);
-- When DPGAN is selected, the benefit of including Bayesian optimization, which inevitably increases computation complexity, is not so significant (only 2 out of 8).

Problems
- The benchmark with 88.87% AUC is claimed to be obtained using $D_{AB'}$. Is this distribution $D_{AB}$?
- Could you provide some details of the used dataset? For instance, how many samples are included? What is the ratio of different ethnical groups?",1
96,"Summary:

This work introduces a modified Mixup technique to address domain generation. Specifically, the mixup is performed over domain-invariant features (generated by DANN), and a large margin loss is introduced to complement the Mixup loss. Thorough experiments are conducted, together with theoretical insights.

Advantages:

• The approach is simple and easy to implement.

• Experimental evaluations are rather complete and showcase the method's efficacy.


Downsides:

• Despite the empirical improvement, the motivations are unconvincing to me. Specifically, the arguments made for Figure 1 all hinge on the fact that the toy example is very low dimensional. I am skeptical that the mixed samples will likely overlap with existing clusters. Also, I am unsure why the domain information becomes an issue -- the same argument could be made for vanilla classification tasks in one domain. 

• The approach, in essence, combines several pieces of existing techniques, including domain-invariant features, manifold mixup, and margin loss, together with their hyper-parameters. So, I am unsurprised to witness the empirical gains, given the additional degrees of freedom for hyperparameter tuning.

• I would appreciate a comparison with another mix-up-based approach for distribution shift [1].


[1] https://arxiv.org/pdf/2201.00299.pdf",-1
97,"This submission deals with fixing the caveats of transformer networks for solving PDEs. Some of the caveats include generalization to PDE parameters not seen during training,(ii) spatial and temporal zero-shot super-resolution,(iii) continuous temporal extrapolation, (iv) dimensionality generalization of PDEs, and (v) efficient inference for longer temporal rollouts. To solve these issues this work utilizes the attention mechanism to design conditional vectorized neural fields (VCNeF) that can achieve fast training and inference by parallelization on GPUs. The performance is compared with FNO and OFormer and it shows some gains. 

This submission addresses an important and timely problem. The proposed solution is also meaningful. The comparison with FNO doesn't seem fair. There are new versions of FNO such as AFNO [1] based on transformer networks and attention that is scalable and fast to train. Also, SFNO [2] seems to improve the role out. I would recommend the authors to compare these two works and compare in the experiments  if possible.

[1] Guibas J, Mardani M, Li Z, Tao A, Anandkumar A, Catanzaro B. Efficient token mixing for transformers via adaptive fourier neural operators. InInternational Conference on Learning Representations 2021 Oct 6.

[2] Bonev, Boris, et al. ""Spherical Fourier Neural Operators: Learning Stable Dynamics on the Sphere."" arXiv preprint arXiv:2306.03838 (2023).",1
98,"The work proposed an interesting work on using MCG signals to conduct individual identification. While several more steps needs to be considered as a foundation model

1.  ""Our system (shown in Appendices Figure ??) has two BellBloom OPMs as a gradiometer to sense the cardiac magnetic
field."" There is a reference issue.

2. More related work about MCG signal can be introduced to give readers a more comprehensive view of MCG.

3. In the introduction, the authors state that ECG quality can be influenced by physical activities etc, will MCG will also be influenced by those factors?

4. The most concerning issue is the model is tested on 5 subjects, it can hardly be called Foundation model.",-1
99,"### Summary 
The paper introduces a novel method named AGENT for implementing the adaptive gradient correction technique to accelerate and stabilize the convergence of sparse training. The author provides a theoretical analysis and conducts extensive experiments, demonstrating up to a 5% improvement.

### Quality, clarity, originality
The algorithm is novel , and the code for reproducing the experiments is provided. The paper is well-written, clear, and comprehensive.

### Strength and weaknesses:
Strength:
+ A good level of novelty
+ Extensive experiments
+ Solid theoretical analysis

Weaknesses:
+ While convergence is faster and more stable, there is no improvement in final accuracy on large datasets.",1
100,"Evaluation
-------------------------
**Quality:** The paper introduces a novel approach, Bayesian Experimental Design (BED), for optimizing experiments in the setting of inverse problems for partial differential equations (PDEs). It presents a thorough explanation of the proposed method, including mathematical formulations and implementation details. The approach is evaluated through numerical experiments, demonstrating its effectiveness in various scenarios. Additionally, the paper discusses the implications of the results and compares them with existing methods, providing insights into the strengths and limitations of the proposed approach. Overall, it is a high-quality work. 

**Clarity:** The paper is generally well-written and organized, with clear sections outlining the problem statement, methodology, experiments, and discussion. Technical terms and concepts are defined and explained adequately, enhancing understanding for readers with varying levels of expertise. Figures and tables illustrate key points and present experimental results. However, some sections could benefit from additional clarification, particularly regarding the training process of implicit neural representations and energy-based models. This is not a problem for this short piece, especially because a very good supplementary material is provided for further clarification & details.

**Originality:** The paper introduces a novel approach to Bayesian Experimental Design for optimizing experiments in inverse problems for PDEs. It leverages implicit neural representations and energy-based models to model the joint posterior distribution efficiently, offering a unique perspective compared to existing simulation-based inference approaches. Integrating these techniques for experimental design in the context of PDEs is innovative, in my opinion, and extends the current SOTA in the field. 

**Significance:** The proposed approach addresses significant computational barriers in optimizing experiments for inverse problems in PDEs, offering a computationally efficient alternative to existing methods. The potential applications of the proposed methodology are broad, spanning various domains where PDEs are used for modeling complex systems. Besides, the paper opens avenues for future research in neural operator learning and Bayesian experimental design, with implications for accelerating scientific discovery and solving real-world problems.

Pros
-------------------------
1. Introduces a novel approach to BED for optimizing experiments in the setting of inverse problems for PDEs.
2. Leverages implicit neural representations and energy-based models to model the joint posterior distribution efficiently.
3. Demonstrates effectiveness through numerical experiments on boundary value problems and diffusion equations in 1D and 2D.
4. Offers a computationally efficient alternative to existing simulation-based inference approaches.
5. Provides insights into the potential applications and future research directions in neural operator learning and BED

Cons
-------------------------
1. Some sections could benefit from additional clarification, particularly regarding the training process of implicit neural representations and energy-based models.
2. While the numerical experiments demonstrate effectiveness, further validation on more diverse datasets and real-world applications may be needed.
4. The computational cost of training implicit neural representations and energy-based models could be high, especially for larger-scale problems.

Typos and grammar issues
-------------------------
- ""coupled random variables"" - consider adding a hyphen for clarity (""coupled-random variables"").
- ""Equipping a with a prior distribution"" ---> ""Equipping 'a' with a prior distribution""
- ""Each MCMC step necessitates at least one solve of the underlying PDE"" - ""solve"" should be ""solving""?
- ""Design points kb"" - unclear heading, needs clarification or correction.
- ""experimental design task in which, based on three initial observations"" --> ""experimental design task involves using three initial observations""
- ""results inferred from optimally chosen points are visually more similar to the ground truth"" --> ""results inferred from optimally chosen points closely match the ground truth""
- clean the bib; missing entries, capital letters. This is a nice tool btw: https://flamingtempura.github.io/bibtex-tidy/.",1
101,"This paper addresses the issue that general-purpose search engines have inaccurate retrieval results for medical field content, especially for encephalitis research. Thus, they introduce a query-document set based on PubMed data. They further use GPT-4 to generate queries query varies that conceptually aligned but with different phrases and terms. A model is trained on the introduced data with contrastive loss. Results show the retrieval capabilities are enhanced.

Pros: 
* The motivation is strong and work on the task is urgently needed
* Dataset is sampled, the model is trained, and results show the model works. The entire lifecycle is demonstrated with sufficient information

Cons:
* Now info on the collected dataset is limited, it would be great to show the data distribution and provide some samples
* Evaluation result is brief, more interpretation and analysis are appreciated
* How the contrastive loss is calculated, and how the data variants are used for the loss calculation needs to be clarified",1
102,"This paper uses the distillation to distill the MedSAM into RepViT-MedSAM version, which is much efficient architecture than TinyViT of LiteMedSAM. The results look good with faster inference speed.

Comment:
The only concern of mine is that 9 epochs of distillation and training is sufficient?
What is the memory peak for distillation, as we need to load both models.",1
103,"1. With the introduction of 3D Gaussians, the significance of conducting Active View Selection for NeRF may not be as substantial.
2. Can this set of strategies be transferred or adapted to work with 3D Gaussians?
3. How robust is the method? Is it capable of functioning effectively on datasets such as Tanks & Temples or aerial photography data?",1
104,"This paper explores incorporating Clifford neural operators into two types of backbones ResNet and UNet, for Earth forecasting task on MERRA-2 dataset.

Pros
1. The visualization on model design is clear and easy to follow.
2. The visualization on performance comparison helps indentify the areas where the model fail to predict accurately and help analyze the potential causes.

Weaknesses
1. Some expressions are not clear enough. E.g., there lacks descriptions on the notations in Eq(1)(2).
2. The performance drops significantly when the forecasting horizon gets longer. Besides the potential causes discussed in Section 4, the single-input-single-output formulation is also a possible cause that leads to distribution mismatch and accumulated errors.
3. The major contribution is the usage of Clifford neural operator and its application to Earth forecasting. However, there is no evidence that it really results in performance gain. Ablation studies on Clifford neural operator, e.g., comparisons to the original ResNet and UNet, could be helpful.",-1
105,"The paper introduces SwiftMedSAM, a proposed ultra-lightweight model for medical image segmentation designed for resource-constrained environments. The approach focuses on reducing the computational demands of the LiteMedSAM model by adjusting the block depths of the image encoder, transformer depth, and dimensions in the mask decoder, and reducing the number of attention heads and the depth of the IoU head. However, the paper lacks empirical evidence to support the efficacy of the hyperparameter optimizations. There is a notable absence of comparative analysis with other state-of-the-art models in similar resource-constrained settings. The practical impact of the proposed optimizations on real-world clinical settings is not adequately demonstrated. While SwiftMedSAM proposes an approach to reducing the computational requirements of medical image segmentation models, the paper falls short in presenting a compelling case for its novelty and effectiveness.",-1
106,"Strengths:

1. This paper proposes direct preference optimization via automated feedback (DPO-AF), a novel method for planning that uses formal verification to create preference data and then fine-tunes the LLM-based controller with this data using DPO algorithm.

2. The authors use autonomous driving system as the environment to develop this method and results using Carla simulator shows the performance improvement

2. Overall, this is a well-rounded paper, with strong motivation, technical contribution, and evaluation section. The paper is clearly written and the contributions are well-positioned with respect to existing research.




Weaknesses:

1. Only one environment is used for experiments",1
107,"This paper studies clustering identification with bandit feedback. The setting is as follows: K arms – each associated with a random multi-dimensional distribution – are partitioned into $K$ clusters, with the property that two arms share the same cluster if and only if their distributions share the same average. A learner is tasked with uncovering the clustering. To do so, it is allowed to query arms and observe i.i.d. samples from their associated distribution. Given a precision $\delta$, the goal is to design an optimal learning strategy, in the sense that needs as few queries/samples as possible to uncover the correct clustering, with probability at least $1-\delta$.

In the batch version of the problem – when data are generated by a mixture of $K$ gaussians that need to be identified – it is believed that in high-dimension there is a gap between the sample complexity needed by poly-time algorithms and the information theoretical requirement. 
The contribution of the authors is two-fold. First, they construct a poly-time algorithm which, in the balanced case (all groups have a similar size), outperforms the the simple batch algorithm. Second, they prove that such bound is information-theoretical optimal, meaning that there is no computation-information gap for clustering with bandit feedback in high-dimension.

The algorithm combines in a nice way many ideas, which seem to be quite standard. Although I am not an expert I enjoyed reading the paper and followed easily the intuition behind the technical part. On the negative side, I am not totally convinced by the relevance of the question: recovering clustering structure is an important task, but I am not sure how relevant is perfectly identifying all the clusters, i.e., also the ones that are extremely close. For instance, imagine that there are 3 clusters, one very far apart and two extremely close. The algorithm and the results presented in this paper depends polynomially on the distance between the two close centers, while the well separated cluster can be easily identified. This is not captured by the model, nor by the techniques.",1
108,"### Methodology:
- **Section 2.1 and 2.2**: These sections describe the preprocessing and the proposed method, but a more detailed algorithm description and pseudocode are needed for the reader to better understand the specific steps of the proposed method.
- In the quantization process, it is necessary to detail the basis for the choice of quantization strategy, as well as how to balance accuracy and efficiency.

### Experiments:
- **Section 3.1**: The datasets and samplers mentioned need a more detailed description, including the source, diversity, and scale of the datasets.
- **Section 3.2**: The evaluation metrics and loss functions used need a deeper explanation, including why these specific metrics and functions were chosen.
- **Section 3.3**: The training protocol needs a more detailed parameter setting and adjustment strategy.

### Results:
- **Section 4.1**: The inference speed results need to be compared with existing technologies to show the advantages of the proposed method.
- **Section 4.2**: The quantitative results need a deeper analysis, including the performance differences of the model on different modalities and possible reasons.
- **Section 4.3**: The qualitative results need more case studies to show the performance of the model in different situations.",-1
109,"This paper describes a framework to train a neural embedding model for logical inference tasks. The core idea is through 'anchor mutation': triplets such (anchor, positive, negative) are generated via mutation, and an embedding model learns to embed unifying atoms (anchor and positive) closer (on the embedding space), and non-unifying atoms (anchor and negative) far away. This is closer to the idea of contrastive learning to me, which makes a lot of sense. 

Strength:
- well-motived task
- clearly presented algorithm

Weakness:
- I would love to see a more formal definition of repeated term atoms (RTAs) and perhaps a few more words on its effect on the downstream tasks.
- More explanations on Table 2. How is the new embedding strategy different from the previous embeddings? Would it be correct to say that over large KBs the new embeddings only improve upon the mean nodes metric while stay the same upon the median metric? Would it be possible to perform worse over even larger KBs (on the medium nodes explored metric)?",1
110,"1.	The effort to control confounding factors by selecting participants with similar characteristics in this preliminary study is understandable. However, it's important to consider the potential trade-off between controlling variables and ensuring the model's generalizability to the broader population. With similar age and sex, the model may face increased difficulty in identifying individuals due to potential underlying differences in ECG patterns among different age groups and sexes. Given the limited diversity in the sample, there may be challenges in extrapolating the findings to a more diverse population. Future research could explore strategies to balance control over confounding factors with the need for dataset diversity to enhance the model's applicability across different demographics.

2.	Please further clarify the methodology employed to augment the dataset. Specifically, how were the repeated measures conducted and combined to generate such a large dataset (3276 sets) with 5 participants? Providing insights into this process would enhance the transparency of the study and offer valuable guidance to researchers interested in implementing similar data augmentation techniques in their work.

3.	I recommend the inclusion of measurements from ECG devices for comparison with the innovative self-manufactured device. To strengthen the evidence of the device's validity, it would be beneficial to authors include a figure comparing the measurements obtained from the new device with those from traditional ECG. This visual comparison could provide valuable insights into the device's accuracy and reliability.

4.	To ensure the robustness of the findings, it's crucial to provide details on the validation process for the model. Please elaborate on the validation dataset used to assess the model's performance.

5.	I suggest the authors consider using universal anatomical terms, such as transverse, coronal, and sagittal planes, to describe the human anatomy. Additionally, providing a fixed reference point when describing magnet induction intensity would be beneficial to prevent confusion and ensure the reproducibility and interpretation of the results. These adjustments could enhance clarity and consistency in the terminology used.

6.	I appreciate the authors' insightful approach to adding noise to mimic real-world environments. This strategy is particularly valuable as it reflects the common scenario where sensors encounter significant noise levels alongside the signal of interest. By incorporating noise into the study, the authors have taken a crucial step towards enhancing the realism and applicability of their findings to practical settings.",1
111,"This paper considers the the sampling process with differential privacy guarantee. In the paper, the authors propose several algorithm focusing on the cases of single sampling, weak sampling and strong sampling with privacy gurantee and accuracy in total variation. The authors also provided lower bounds for the multi-sampling problems.

**Strength:**

1. The paper is easy to follow. The authors make a clear list of the various definitions in the paper. 

2. The accuracy of the output sample is in the strong sense of the total variation distance. 

3. The authors discuss in details of different regimes with different information on the input distribution.

**Weakness and Suggestions:**

1. The model is only based on the k-ary distributions and Gaussian distributions. I wonder if similar method is also applicable to other distributions. Is the TV distance is the bottleneck?

2. There are lots of materials on private histogram algorithm, where the algorithm takes iid data as input and output a distribution with approximate histogram distribution. Take arxiv.org/abs/0811.2501 for example, which measures accuracy in L2 and Kolmogrov distance. There are also private synthetic data algorithms which takes an input dataset and output a new dataset with similar distribution, e.g. arxiv.org/abs/2302.05552. It seems that private sampling (especially weak multi-sampling) is in some sense very similar to these two problem. It would be better if the authors includes the comparisons of the different goals.

**Minor Suggestions:**

1. In Algorithm 2, based on the output line it seems that condition $m<n$ is needed.

2. In Section 3, the DP mainlt comes from random shuffling. Why single sampling part uses pure DP yet multi-sampling part converts to approx DP? Is there a barrier

3. In first paragraph of Section 4.1.2, Algorithm 3 should be 4.

4. In Section 5.3. \|D,\hat{D}\| should be \|D - \hat{D}\| to maintain the notation in the paper.",1
112,"Summary

This paper proposes architectural variants of transformers, pretraining, and fine-tuning methods for PPG domain.

Strengths

- Experiments are extensively conducted in PPG domain.

Weakness

- Lack of comparison with other transformer architectures for timeseries data
- Writing could be improved. For example, the difference between linear prediction head and attention-based prediction head is unclear, and it’s hard to identify SOTA algorithms in experiments.",-1
113,"The authors' ideas in the abstract, introduction, method, and conclusion sound very interesting. Moreover, they explain the idea clearly. 

However, the authors did not update the result and discussion section (Section 4) from the template. Essentially, Section 4 is missing any new content or the validation results. Moreover, Table 5, which can be understood as the submission checklist, is also not filled out. As far as I understand, both should have been filled out by now, and it would be important to understand the impact of the contribution. 

### Other Feedback:

* In the introduction, the reference for EdgeSAM and the reference (GitHub Link) for LiteMedSAM are missing. 
* The caption in Figure 1 needs to be updated. Otherwise, the overview diagram is very nice! 
* In Section 2.1, a table showing all the numbers described in the text would be very beneficial. 
* Regarding the method described in Section 2.1, the relation to stratified sampling/splits and/or the application thereof might be beneficial to put your method into context.
* In Section 2.3, the first sentences are still from the template.
* In Section 2.3., the reference for LoRA is missing. 
* Providing more details on how you perform inference concurrently in the CPU setup might be beneficial. 
* In Table 1, Python 3.20 is likely a typo. 
* The provided code could benefit from a better readme that reflects the methods described in this paper. 
* The footnotes in Table 2 are broken. I think this is a problem with the table environment.",-1
114,"This paper presents a unified complexity that characterizes learnability in the case of bounded losses. I looked over the main results and believe the proofs are correct; however, I have not yet had a chance to check parts (ii) and (iii) of Theorem 8 nor the proof of Lemma 15.

There recently have been many papers looking at online learnability for various problems. I feel that many similar ideas are being used in these works, both in terms of the algorithms and the proofs, meaning it is not so clear how long this process should go on before we have a work that tries to unify things. This work, which aims to provide a unification (at least for bounded losses) via the Sequential Minimax (SM) dimension, is therefore welcome. I hope it can help refocus future work in online learnability and provide more focus on obtaining the best rates and on obtaining adaptive guarantees (going further than minimax results).

In terms of the novelty of the ideas in the proofs, having seen various works using these types of arguments before, I cannot say I detect a high amount of novelty. However, putting together these arguments is not easy. Also, I believe the proof of the upper bound of Theorem 9 relies on some new tricks (namely, the idea of $\varepsilon_t$-realizability) which are of interest to the learning theory community; I comment on later in my review. In any case, by far the most clear contribution in my eyes is the novel concept of Sequential Minimax dimension. The definition, while long, is intuitive.

Readers of this paper would benefit if the authors could be explicit about the assumptions on the algorithm and the assumptions on the adversary. From Definition 1, I can see that in each round, the algorithm deterministically selects its distribution (conditional on adversary's history of plays thus far). From the notion of regret formalized just before Definition 2, it seems that the adversary is oblivious. Can the authors confirm this? For upper bounds (sufficiency of your new dimension), it seems fine to me that you restrict to this type of deterministic learner and oblivious adversaries. We can apply standard arguments from Prediction, Learning, and Games (Lemma 4.1) to extend to adaptive adversaries. However, for your lower bounds (necessity), are the restrictions you impose on the learning algorithm really OK? Or do you avoid these restrictions for the lower bounds? It is worth at least some discussion in the paper.

In the proof of the upper bound in Theorem 9, the sentence ""Let $B$ denote the random variable denoting the randomized prediction of all experts (or their corresponding randomized algorithms)."" is not clear. Each expert itself is a randomized algorithm (by virtue of its playing, in each round, a draw from its selected probablity distribution). So, there is one source of randomness. Another source of randomness comes down to the use of MWA. At first, I assumed you meant the randomness due to the random draw (for each expert and for each round) from a probability distribution over the action space $\mathcal{Z}$. However, if that is the case, then there is something wrong with the bound given right after ""Then, conditioned on $B$, Theorem 21.11 ... tell us that"", since there is no conditioning on the RHS. Here, I am assuming that $E(x_t)$ is a probability distribution, as that is consistent with what MRSOA returns. If you meant that $E(x_t)$ is the random sample drawn from the distribution, then this is *not clear* from the context (especially in light of the LHS of the inequality, which does take a conditional expectation); please write the conditional expectation on the RHS explicitly (assuming the inequality is indeed still correct).

For the proof of Theorem 9's upper bound, could you split this into a two or three main pieces? The proof currently is long and notation-heavy, and those two things together make it difficult to process. To get started, think about how you might write a proof sketch. What are the main pieces for that sketch? You then might consider making a lemma for each piece.

I noted many similarities between Algorithm MRSOA and the algorithm RSOA of Raman et al. (COLT 2023). However, a key difference (which I have not seen before; I did spend some time checking) was the introduction of $\varepsilon_t$, which I view as important to handle the case of regression. In the paper, the authors should comment on the algorithmic predecessors to MRSOA (I guess RSOA is one). Also, in your response to my review, I would like to know if the previous algorithms of the SOA style have used $\varepsilon_t$ variables.


## Regarding Organization and Section 5 of the paper
I felt that Section 5 is a bit fast for a few reasons. First, the meaning of ""finite character property"" (and why the property is important) was not clear to me. I know this appears in some fundamental works, but without more motivation, it may be hard even for most learning theorists to appreciate this pursuit. Also, I do not know if it would be enough to use the finiteness to argue for computational tractability, due to negative results for computable online learnability for Littlestone classes. Finally, I really think the main interesting technical development (proof of Lemma 15) should be sketched in the main text if this result is worthwhile to include in the paper (or are the ideas involved just not interesting?) 

I have a concrete proposal for reorganizing and possibly cutting some material, saving it for more thorough coverage in future work. You could save all of Section 5 for future work if you can resolve the open question regarding necessity (the one stated shortly after Lemma 15). This could be a strong, independent work or maybe could appear in a journal version of your current work. If you cannot resolve the open question, then you could use the current material for a COLT open problem (stating some positive results, and then giving as an open problem being the resolution of necessity for classes with finite $p^*$). The space you save could be used to exhibit how SM dimension can recover previous dimensions, i.e., some of the proofs of parts of Theorem 8. It really is a shame that all of proof of Theorem 8 was left to the appendix. For example, perhaps you might sketch, in the main text, how SM dimension reduces to Sequential Fat-Shattering dimension. If you can demonstrate the ease (not sure if it is easy, actually) with which SM can capture previous dimensions, this will better allow others to leverage your SM results for other online learning problems. 



### Additional comments:
1. Page 3, first line: What does it mean to “tightly characterize”; you either characterize learnability or you do not.

2. For the list online classification and measure-shattering dimension papers, you should cite the COLT version of each paper.

3. In Section 5, you write ""in Section 3 we showed that the SMdim reduces to... and the p-Set LDim"". However, as far as I am aware, you only showed how SMdim to recover Measure Shattering dimension. So, did you actually mean to write SM dimension?

4. You write just before Theorem 8 that the theorem ""unifies all major existing results in online supervised learning."" I strongly suggest adjusting the writing here. It is true that (i) and (ii) are major; they stand the test of time. However, (iii) and (iv) are rather new and it seems premature to say that these are major results (at least without further explanation). Moreover, one of the most major losses in all of learning theory is the log loss, for which there are results for sequential prediction. Yet, Theorem 8 (nor the entire paper) does not say anything about results for log loss.


### Some minor issues:
- In Definition 4, the only equality (=) should be changed to not equals, which would then match Definition 3.
- In the proof of the upper bound in Theorem 9, first math display: your notation for what I will call an ""expert function"" also needs to have the round index as a parameter since MRSOA_gamma needs to access not only x_t but also the round index (to have access to [t-1]).",1
115,"Reviewer's Comments:

The paper introduces an innovative method for sleep event identification based on multi-modal contrastive learning, which is innovative in the field of sleep medicine. The SleepFM model performs well in retrieval, sleep stage, and apnea classification, contributing to sleep medicine research. Here are some suggestions:

Language: The overall language of the paper is fluent, but there are instances where expressions are not clear. Additionally, there are numerous abbreviations without providing the original full terms. Particularly, for ""SleepFM,"" I am curious about what ""FM"" stands for.

Methodology: The paper describes clear methods, including dataset selection, model architecture, and evaluation metrics. However, more detailed descriptions of the implementation details of the contrastive learning method may be needed for readers to understand the model training process and data processing flow.

Results and Discussion: The Results section provides detailed experimental results, but some explanations for certain results could be more in-depth. For example, why does pairwise contrastive learning perform better in retrieval? The authors could provide more explanations about the internal mechanisms of the model.

Overall, this paper is helpful for research in the field of sleep medicine, but there are still some aspects that can be further improved and refined.",1
116,"Pros:
- The paper is well-structured, presenting the methodology and results clearly. The approach achieves faster inference speed without suffering from performance drop, which is a great improvement.

Cons:
- Please add your average scores and running time in the abstract to provide a quick overview of the performance metrics.",1
117,"The authors propose using sine activation function for all hidden layers in PINNs. They use SA-PINN as their base model to showcase the proposed usage. The results show the advantage of using sine activation function. However, I have some concerns:

1. The authors should consider comparing with some more activation functions, lets say swish and mish - do they provide accuracy comparable to tanh case?

2. Is it because of the underlying harmonic problem that this fix works? or the authors consider it as widely applicable to other problems?

3. The authors can also combine adaptive activation function while using sine and see if it further improves the learning

4. The paragraphs have different spacing, kindly check that to maintain consistency.

I am happy with the results for acceptance in ICLR workshop because in a way the paper is using the known physical prior in case of a mass damper system to choose the activation function. The choice is intuitive, but is validated empirically and hence would be interesting for this workshop.",1
118,"This paper investigates three different strategies for assigning optimal initial condition in Neural Langevin-type stochastic differential equations. The investigation focuses on the classification task involving irregular time series data in astronomical studies. The three methods for optimal initial conditions include the interpolation method, imputation method, and static approach. Through extensive experiments, this study demonstrates that Neural SDEs are robust in handling irregular time series data, and the static method for initial conditions provided the best results for their problem.
1. In the imputation method, how is the mean computed? Is it a temporal mean or the mean of input features measured at that time? From Fig. 2, it appears that missing values are mostly replaced with zeros in the imputation method. It would be helpful to mention that the black dashed-dotted line corresponds to missing data in the figure caption.
2. The classification task is not clearly defined. More details should be added about the specific problem being addressed in the LSST dataset.
3. The three strategies for optimal initial conditions are tested on only a single dataset. Are these observations dataset-specific, or is the static or imputation method consistently better than the interpolation method overall?
4. How does the computational time of Neural L-SDE compare to other methods like RNN, LSTM, and Neural SDE?",1
119,"The paper “Proper Learnability and the Role of Unlabeled Data” examines the conditions under which proper learning can be optimal (as opposed to when an improper learner is needed for optimality) and also studies whether it can be simply charactarized.

The main results of the paper are as follows:
- in the distribution dependent pac model, optimal proper learners exist 
- the efficiency loss from distribution-dependent to classical PAC is at most logarithmic
- impossibility results for multiclass proper learning, going through the EMX work of Ben-David et al., are given.

These results are conceptually interesting and add to the picture of proper vs improper learnability that has been analyzed by many people including Simon, Danielly, Hanneke, etc.  Some of these results, however, are not very complicated and goes through known avenues of attack, eg via results for the transductive setting or via techniques developed by Daniely and Shalev-Shawrtz. The latter results illustrate the difficulty of characterizing proper learnability in many settings.

Despite these reservations, I think the conceptual contributions warrant acceptance. The paper is very well-written and easy to follow.",1
120,"Pros:
- The paper is well-structured and provides a comprehensive overview of the development and evaluation of Rep-MedSAM. The methodology and results are promising, showcasing significant improvements in efficiency and performance.
- It's interesting that you only use the external dataset for the CT modality in the training pipeline. It would be nice if you could comment more on why you do this.

Cons:
- In the main contribution (in the introduction), ""distill"" is misspelled.
- In the data preprocessing section, there are 11 modalities in the training set, it seems like you have missed the microscopy type.
- In Figure 2, some blocks are just noted as ""1x1"" and ""3x3."" You should specify what those blocks are.
- In the distillation phase, the teacher model was not applied with augmentation, but the student model was. How can you align these two outputs with MSE loss while their orientations do not match?
- The scores in the abstract do not match the scores in the Table 5.
- The scores of hard cases in qualitative results are still high (0.88 and 0.94 NSD scores). You should pick more challenging cases.
- Some sections are missing: qualitative results, efficiency results, limitations, and future work.",1
121,"This paper presents a new commonsense reasoning benchmark called CROW that is based on real-world tasks. The CROW is a manually curated, multi-task benchmark, and it tests the commonsense reasoning ability of a model across six real-world NLP tasks. This benchmark has around 16k examples. The authors have benchmarked the dataset with sota LLMs and empirically showcased it is very challenging.

Strengths: 
* This real-world commonsense benchmark will help judge the CS reasoning capability of an LLM.
* Evaluation results showcase the difficulty of this benchmark.
* This is human annotated benchmark.

Weaknesses: 
* No examples of curated data have been given, also hard to understand the uniqueness of the data generation approach.
* CS violation across 6 dimensions would be very helpful, however, no statistics have been shown on that.
* Also, good to see how this dataset will help an LLM to improve the CS reasoning performance. Maybe through Finetunining.",-1
122,"*** Summary ***

The paper shows convergence results for both the unadjusted Langevin and proximal samplers in arbitrary $\Phi$-divergences, under a more general class of assumptions (the $\Phi$-Sobolev inequalities).

*** Strengths/Weaknesses ***

The work shows a convincing connection between $\Phi$-divergence and a class of $\Phi$-entropy inequalities.

The analysis nicely generalizes what is known for the Langevin dynamics/proximal sampler under more “standard” functional inequalities.

In my opinion, the paper is somewhat lacking motivation. Why might the reader be interested in Phi-divergences beyond those considered in e.g., Vempala and Wibisono or Chewi et al. 2022? The R\’enyi and KL divergences already imply results for many distributions of interest. I hope the authors can point to a few cases where we can hope to either get by with weaker results under more general assumptions, or stronger results with more restrictive assumptions. I hope the authors can emphasize these aspects in a revision.

If instead the authors want to focus on their proof techniques, it would be interesting if they could extend it to broader classes of Markov chains. See my question below.

Secondly, I think the proof technique can largely be found in prior work. For instance, Lemma 14 and 15 result immediately from an application of the Phi-Sobolev inequality to the decay equations, which can be found in Chewi (2024).

*** Minor/Questions***

Can one demonstrate similar results for chains after metropolisation? What about for the underdamped dynamics?

How can the results of [1] be placed in this context? Alternatively, what about the LOI results in Chewi et al 2022? (There is some discussion about the relationship between Phi-entropy and LOI in Bakry, Gentil and Ledoux.

I am not aware of Dalalyan 2017 having results in KL divergence. Perhaps the authors just mean in W2. Secondly, Chewi et al. 2022 (a) does not contain any mixing results to $\nu$, but only $\nu^\eta$.

Pg. 2 Assume smoothness assumptions -> make smoothness assumptions

Pg. 4 based on Metropolis … -> based on the Metropolis …

Pg. 4 from stationary distribution -> from the stationary distribution

The final equation on Page 7 has a sign error in the first equality.

Page 9: obtained in -> obtained is

[1] Mousavi-Hosseini, Alireza, et al. ""Towards a complete analysis of langevin monte carlo: Beyond poincaré inequality."" The Thirty Sixth Annual Conference on Learning Theory. PMLR, 2023.",-1
123,"**Summary:** The goal of the work is to enhance the performance of LLMs in tasks requiring multi-hop reasoning through human feedback.

**Strengths:**
- Introduces a dataset of human-feedback
- Presents methods and objectives to learn from the feedback dataset

**Weaknesses:**
- The applicability of the method seems to be task-specific. It is not clear how methods will be performed in unseen datasets.
- The collection of human preferences is costly; whereas AI feedback is cheaper. The paper does not address this issue.
- The proposed objectives are variants of existing techniques. 
- RL-based objectives are not compared.
- The error-types look limited. There can be other types of errors.",1
124,"This ambitious paper fine-tuning a large SOTA LLM for structuring clinical notes capable of handling long context windows and rigorously evaluates it to other commercial/open models using a chatbot arena + LLM-as-judge setup.

The background is well set with both a survey of clinical LLM tasks from arXiv and huggingface and an empirical investigation of context windows required for clinical notes in MIMIC-IV.

They chose a TigerBot base model as it is multilingual and demonstrated superior performance to Llama 2-70b chat with accuracy of next token prediction on 8k contexts. Whilst next token prediction isn’t a particularly useful task they justify it as suitable for rapid decision making and early exploration. The poor performance of Llama 2 70b on 8k vs 4k tokens is hypothesised due to under representativeness of clinical vocabulary leading to worsened hallucination - this seems possible, but I can’t believe that the justification that TigerBot was trained on arXiv which has 1.2% biomedical content explains the difference, I’m sure this was part of Llama training too!

The training data is constructed using clinical notes from MIMIC-IV processed using GPT-4. It’s good to see (trained!) expert evaluation of the training data. The ethical provisioning for this needs to be mentioned as PhysioNet does not permit use of OpenAI APIs! This is not mentioned despite the extensive ethics appendix. 

Given the importance of training data it would be useful to have some additional details of how GPT-4 was used to restructure data for the three extraction tasks. There are some additional training datasets such as a ‘previously unseen corpus’ of general-purpose SFT data which needs clarifying. The use of ASclepius for basic clinical tasks like NER and abbreviation seems sensible but despite training for abbreviations they use a medical dictionary at both training and inference?

They structure training from general purpose to basic tasks (ner/abbreviations) to hard tasks (summarisation) but it would be nice to see some experimental results or referenced justification for why they did this. Otherwise this really follows the general LLM -> domain specific fine-tuning paradigm so I’m not sure constitutes a novel strategy in and of itself?

The technical details of training framework are clear and impressive.

Evaluation is rigorous with comparison with range of commercial and open-source (GPT3.5/4, Gemini Pro, llama2, mixtral). The use of ChatBot Arena for blind pairwise evaluation includes control groups with intentionally wrong information and swap-position executions. They use GPT-4 as a judge, supplying the evaluation prompt which is thorough, however despite using 5 domain experts to review training data I can’t see any expert review of the final evaluation data or the LLM as judge strategy? This appears to me to be the biggest weakness in an otherwise strong paper and is perhaps time related?

Overall this is a really ambitious and thorough piece of work which makes both an interesting contribution to the research literature as well as the open source community through release of trained models, datasets and evaluation code.",1
125,"The paper studies the following best-arm identification problem. There are n arms with stochastic rewards drawn from unknown distribution $F_i$ for each arm $i$. The learner wants to identify the arm with the largest quantile $F^{-1}_i(q)$ for a given $q$. When pulling an arm, instead of knowing the reward, the learner only observes a single-bit information. In this paper, the single-bit information is from a threshold query, and in each round the learner can observe whether the value of the arm is greater than the threshold proposed by the learner. The paper proposes an algorithm that has asymptotically optimal query complexity.

Evaluation:
The problem studied by the paper is definitely a generalization of the best-arm identification problem of quantile bandit with full value feedback. However, the algorithm proposed by the paper seems straightforward (i.e. run noisy binary search algorithms and maintain the confidence interval around the target quantile of each arm simultaneously), and the idea of using noisy binary search to learn the quantile of a distribution is pretty common, especially in the dynamic pricing literature that always considers pricing (i.e. threshold) queries. Overall, although the authors have made non-trivial technical effort to define the proper terms such that the query complexity is well-defined, I do not find the algorithm and analysis surprising or containing any interesting enough new intuitions.

The line of work that should be cited: learning distribution with threshold/pricing queries has received some recent attention in the learning and game theory area, dating back to “The value of knowing a demand curve: Bounds on regret for online posted-price auctions” (Kleinberg Leighton FOCS’03), with some recent follow-up papers using threshold queries to learn distributions, including: “Pricing Query Complexity of Revenue Maximization” (Paes Leme et al. SODA’23, which includes an algorithm that uses noisy binary search with confidence interval to learn a quantile of a single distribution), “Non-Stochastic CDF Estimation Using Threshold Queries” (Okoroafor et al. SODA’23), “Description Complexity of Regular Distributions” (Paes Leme et al. EC’23), and so on.",-1
126,"A) One major limitation of this work is that it only refers to physics inspired neural networks and ignores much that has been done in the last 5 years such as MGNO, Fourier neural operators or the multiwavelet neural operators. Here are some recent examples that solve similar problems:
- “Multipole graph neural operator for parametric partial differential equations” In Advances in Neural Information Processing Systems, volume 33, pages 6755–6766, 2020.
- ""Non-linear operator approximations for initial value problems."" In International Conference on Learning Representations (ICLR). 2022.
- ""Coupled Multiwavelet Operator Learning for Coupled Differential Equations."" In The Eleventh International Conference on Learning Representations. 2022.
- ""Multiwavelet-based operator learning for differential equations."" Advances in neural information processing systems 34 (2021): 24048-24062.
- ""Identifying arguments of space-time fractional diffusion: data-driven approach."" Frontiers in Applied Mathematics and Statistics (2020): 14.
- ""Fourier neural operator with learned deformations for pdes on general geometries."" arXiv preprint arXiv:2207.05209 (2022).
B) The authors stated in the article that the use of DOF will not cause a loss in precision. Can this be specifically shown in the experimental results section?
C) The authors compared the proposed strategy with the AutoDiff method based on the Hessian matrix. Can more methods be added to prove the improvement of DOF?
D) The authors need to improve the rigor of the paper’ writing. Many of the citations that appear in the article are in the wrong order. Also as highlighted above they ignored major developments in this field of many papers that collected hundreds of citations, so I see no reason for which they ignore good prior work.",1
127,"The paper, ""Automated Generation of Hospital Discharge Summaries Using Clinical Guidelines and Large Language Models,"" explores an approach to automating the creation of hospital discharge summaries. Leveraging LLMs few-shot prompted by clinical guidelines, this method does not require extensive training datasets and can handle full-length physician notes (by utilizing large LLMs), guided by clinical best practices. The system, tested with GPT-4-turbo and MIMIC-III physician notes, was evaluated by clinicians, achieving a micro accuracy of 0.81. The paper discusses methodological limitations and future improvements needed in the evaluation framework.

Pros:
1. Utilizes LLMs in conjunction with clinical guidelines to automate the creation of discharge summaries, offering a solution to reduce manual effort.
2. The methodology does not rely on extensive datasets for training, potentially making it more adaptable and easier to implement across different hospital systems.
3. Involves clinicians in the evaluation process, ensuring that the automated summaries meet practical clinical needs and standards.

Cons:
1. The reliance on a single dataset (MIMIC-III) for testing may limit the generalizability of the findings to other healthcare environments or patient demographics.
2. Accuracy and Completeness: While achieving a micro accuracy of 0.81 is promising, there may still be concerns about the accuracy and completeness of the generated summaries, especially in complex cases. A more in-depth error analysis of identifying which group of patients (which health conditions, which demographics, etc) end up with a better model performance can significantly improve the work.
3. Even though the paper acknowledges limitations in its evaluation framework, suggesting further refinement and broader testing is necessary to fully assess the system's effectiveness and reliability.",1
128,"This paper evaluates linguistic variation in speech data by age and gender using standard NLP tools: PoS using the Stanford Parser and the Penn Treebank tags adjusted for Singaporean English. The author goes on to derive a variety of linguistic features from this data, on which the analysis is performed. The results largely corroborate existing results related to the effect of age on linguistic variation -- particularly as it pertains to ""lexical concreteness."" The methodology appears to be sound, and the use of the Stanford Parser, in my opinion, constitutes foundation model usage and thus making it a relevant contribution to the workshop.",1
129,"Advantages:
1. Gene pathogenicity prediction is a significant task, which can help us understand genetics and its impact on human health.
2. A benchmark study is an urgent need of this research community.

Disadvantages:
1. This paper focuses on three models: HyenaDNA, GenaLM, and Nucleotide Transformer. However, these models are relatively small.
2. This paper is far away from ""comprehensive"", which is important for benchmark study. There are few datasets, tasks and models for evaluation.",-1
130,"The paper studies a ""batch query"" version of the classic DP-SCO problem, where the goal is to design a DP-SCO algorithm that 1) achieves the optimal learning error, 2) uses linear gradient query complexity, and 3) uses sublinear ""query depth"", i.e., the number of batches of gradient queries submitted. The main result of the paper is an algorithm using n^{1/4} batches in the realizable case (i.e., global optimizer in the constraint set), and otherwise n^{1/2} batches. To achieve this result the authors assume a fairly stringent smoothness bound of O(L/D) where L is the Lipschitz parameter and D is the diameter. Previously, it was known how to achieve goals 1 and 2 above assuming a smoothness bound of O(L * sqrt{n} / D) [FKT20]. Intuitively, O(L/D) is the ""best case smoothness"", as then the gradient norm can change by an additive L over the domain. Another side effect is that the algorithm doesn't use contractivity properties to argue about privacy as in [FKT20], instead directly controlling sensitivity, so it stays private for non-convex problems (albeit with unclear utility bounds).

The key idea is a tighter analysis of the noise sensitivity of AGD, by using smoothness to control gradient sizes, along with more careful gradient aggregation scheme (i.e., the binary tree mechanism of [DNPR10]). The authors also need to use the utility guarantees to bound the eventual sensitivity of their algorithm, which is a nice technical observation.

The paper is reasonably well-written, and studies a fairly well-motivated problem. Perhaps the biggest weakness is the fact that they have to essentially assume the strongest possible smoothness bound in their setting (stronger than prior works by a sqrt{n} factor). One thing that I was curious about is -- does the paper degrade gracefully at all if the smoothness is a bit worse than O(L/D), i.e., if it's instead LC/D, can you lose some poly(C) in either the query complexity or error but still get a parallel speedup?

Additionally, I feel like the paper does not highlight its technical connection to the existing literature on 1) parallel SCO, and 2) noise-tolerant acceleration, very clearly. For example, the ""batch query complexity"" in the paper is essentially the highly parallel model of computation introduced by Nemirovski in ""On parallel complexity of nonsmooth convex optimization"", which has a fairly extensive literature. Some relevant papers are discussed in the paper, but many such works, including e.g., ""Randomized smoothing for stochastic optimization"", ""Complexity of highly parallel non-smooth convex optimization"", and the most recent state-of-the-art ""Closing the Computational-Query Depth Gap in Parallel Stochastic Convex Optimization"" are not. The last paper has a survey of this literature that might be good to take a look at. In a similar vein, while I would believe that the exact statement of Theorem 3 has not appeared in the literature before, there are a fair number of papers that study stochastic or adversarial variants of Nesterov's acceleration. For example, ""Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization i: A generic algorithmic framework"" contains a pretty similar analysis, and another example is ""On Acceleration with Noise-Corrupted Gradients"".

Overall, I think the paper makes an interesting enough conceptual contribution to be above the bar for acceptance, as I'm not even sure if the problem of parallelizing DP-SCO has really been studied before, and is a very reasonable direction of exploration for practical reasons.

Some more minor comments:
1. The discussions of ""convexity for privacy"" are somewhat confusing when first presented, because the problem is explicitly called DP-SCO. What I think the authors mean is that a bunch of previous linear query complexity algorithms all used that smooth, convex gradient steps are contractive, and their analysis does not. I feel like clarifying this early on would make it simpler to understand.
2. Could the authors discuss whether this zero-out DP notion is necessary / how to modify it for more standard definitions?
3. The FKT20 line in Table 1 is a bit confusing, as the gradient complexity is n but the steps are O~(n). Certainly it cannot be more than n.
4. bluntly <- crudely? (Page 5)
5. stochastcic <- stochastic (Page 6)
6. The comparison to [CJJLLST23] on Page 6 was very hard for me to understand. First of all, the authors state the rate of [CJJLLST23] as min(n, n^2/p) + min(np^2/eps, n^{4/3}eps^{1/3}), but the rate in [CJJLLST23] is actually min(...) + min((np)^{2/3}/eps, ...) The authors then say their overall gradient oracle complexity is O~(sqrt{n}) -- do you mean your batch complexity? Also, for sufficiently large n >> p^2, it seems the [CJJLLST23] algorithm also achieves linear gradient query complexity. Maybe the entire paragraph was meant to compare the batch complexity? (On Page 3, p <= eps^{3/2} is quoted as a transition for [CJJLST23], which was similarly confusing.)
7. Section 1.1 felt quite out of place (and largely redundant).
8. Discussion at top of Page 11, see the previous references on stochastic / noisy acceleration.
9. I think Lemma 8 has an incomplete sentence in its statement.",1
131,"This work introduces a self-supervised learning model for EEG data analysis aimed at improving transferability and interpretability. While the approach is innovative, several critical aspects require scrutiny:

1. The concept of leveraging self-supervised learning for EEG data is not novel. The paper must delineate clearly how EEGFormer diverges from and improves upon existing models like BrainBERT or SeqCLR in terms of architecture, learning efficiency, or application to diverse tasks.

2. While the paper asserts that EEGFormer offers interpretable outcomes (which I think it is explainability rather than interpretability), it also falls short of providing a comprehensive framework or quantitative measures for interpretability. The paper should incorporate case studies or comparisons with expert analyses to substantiate these claims.

3. The work needs to show a few-shot learning performance in order to be a foundation model.",1
132,"** Summary **

This paper proposes a method to address Amodal Instance Segmentation. To mitigate the overfitting issue of relying on shape prior information from previous research, this approach uses a large-scale pretrained diffusion model. By introducing a new architecture with the Diffusion Shape Prior Estimation module, it enhances the performance of amodal instance segmentation.

** Pros **

- (Significance) The paper addresses a significant problem of amodal instance segmentation (AIS) that AIS has various applications.
- (Clarity)  The introduction of prior work and the clear presentation of methods and experiments make it easy to read.
- (Method) The authors effectively leverage the powerful ability of large-scale pretrained models for shape prior estimation, presenting a logically sound approach that is easy to follow. 
- (Effectiveness) Performance has been proven across various benchmarks, including KINS, COCOA-cls , and D2SA.
 							
** Cons **

- (Originality) While the novelty is not surprisingly remarkable, the addition of a new module based on existing work has improved performance. 
- (Effectiveness) Considering the complex added module DiffSP and Shape Prior Amodal Predictor, the performance improvement is somewhat marginal compared with the methods [14, 24] which do not require shape prior.
- (Minor correction): Line283: four AIS datasets -> three AIS datasets.",1
133,"### Contribution:

The submission introduces FIXED, a nuanced approach aiming to refine domain generalization through a modified Mixup process. The authors articulate theoretical underpinnings for their strategy and validate their claims with experiments, suggesting broader applicability in classification tasks.

### Strengths:

1. FIXED presents a thoughtful attempt to navigate the complexities of domain-invariant representation, potentially enhancing model robustness. The approach seems promising within the scope of the presented experiments.
2. The submission delves into a detailed theoretical discourse, shedding light on the intricacies of domain generalization and the proposed method's potential advantages.
3. The empirical work is commendable, with a rigorous experimental setup and a comprehensive analysis that lends credibility to the proposed method's efficacy.

### Weaknesses:

1. The narrative detailing FIXED's operational mechanism, especially its handling of domain and class information, lacks clarity. This obscurity might hinder readers' understanding and raise questions about the method's adaptability.
2. The dense theoretical exposition in Sec. 4, while insightful, poses accessibility issues. A more approachable presentation of these complex concepts would likely benefit a wider audience.
3. The submission would gain from a more nuanced discussion on FIXED's limitations, computational demands, and its behavior under varied conditions, which remains unexplored.
4. On a minor note, the formatting issues require attention to enhance the presentation quality. Specifically, elements like Figure 4, Table 2, and Table 3 are too close to the text margins, compromising readability. Additionally, the absence of error bars in the experimental results is a concern. Incorporating error bars would significantly strengthen the solidity of the findings by providing a clearer depiction of data variability. I kindly suggest these refinements to ensure a more polished and authoritative paper.

### Broader Impact Concerns:
The submission does not directly engage with the broader implications of the proposed method. It would be beneficial for the authors to speculate on both the positive and negative ramifications of their work in real-world contexts, ensuring a holistic understanding.

### Conclusion:
This paper makes a tentative step forward in the realm of domain generalization, offering a potentially valuable method with FIXED. While the theoretical and empirical aspects are generally well-executed, there are areas where the clarity of communication and depth of analysis could be enhanced. The paper somewhat meets the conference's criteria, suggesting that, with further refinement in the areas highlighted, it could resonate with the interests of a segment of the CPAL audience. Therefore, I lean towards borderline acceptance, contingent on the authors' willingness to address the identified concerns.",1
134,"**Summary:**

The paper focuses on fine-tuning the 7B and 70B Llama-2 models on a dataset compiled from several open medical datasets, evaluating the performance gap between LoRA fine-tuning and full-parameter fine-tuning. Experiments conducted on several medical benchmarks led to good performance on some of the benchmarks, outperformed only by models trained at a larger scale (GPT-4) and models pre-trained on medical corpora (MedPaLM-2). To ensure a fair evaluation, the paper also introduces a decontamination pipeline to remove potential common samples between the training and the testing splits of the benchmarks.

**Strengths:**

1. The evaluation benchmark is thorough, encompassing a wide set of medical benchmarks, thus enabling a more in-depth analysis.

2. The dataset introduced by the authors seems fairly comprehensive and suitable for the clinical domain, and the performance obtained by the Llama models trained in the paper realistically substantiates this.

3. The focus on data decontamination for a fairer analysis by the authors is appreciated and makes their results more relevant.

4. The overall work presented in this paper is very relevant to the topic of the venue.

5. The elaborate (for a short paper) description of the hyperparameters to enable reproducibility is appreciated.

**Weaknesses:**

1. The theme of the paper revolves around parameter-efficient fine-tuning vs full-parameter fine-tuning. However, the claim that parameter-efficient fine-tuning achieves results close to full-parameter fine-tuning is a well-known research artifact. The authors themselves note that the results are in line with prior work for LoRA vs full-parameter fine-tuning in other domains. I would recommend the authors adjust the paper to better describe their main contributions towards the compilation of the training dataset from open medical sources and the data decontamination pipeline, with a lesser focus on parameter-efficient fine-tuning vs full-parameter fine-tuning.

2. I recommend the authors describe the instruction tuning methodology in greater detail in the main paper, if space permits, else in the appendix.

**Other recommendations:**

There is a typo in the caption for Table 1, where GPT-3.5 is incorrectly mentioned as GPT-3.4.",1
135,"In reviewing this manuscript, it is clear the authors can intellectually articulate the focus of their study. They were able to explain the rationale of their research as well as their results. 

My constructive feedback would be as follows:

1. The abstract should be more concrete in explaining the “encouraging results.” At present, there is no concrete description of any results whatsoever in the abstract. 

2. In defining the attention function, the authors should define all terms in the model; at present, they do not describe the \\(d_k\\)
scaling term and the role it plays in the attention function. 

3.  In the section about pretraining, the authors state, ""Specifically, we detect the word “Figure” in sentences and remove the corresponding sentences."" Without having looked at the curated pre-training dataset, it would be imperative to know if all sentences analyzing images had the word ""Figure"" or words such as ""Image"" or other synonyms might have been used.

4. I would encourage the authors to explicitly define the ""cls"" subscript used in their arrays.

5. When describing the space of retrieved sets, I believe the authors may have a typesetting issue; namely, the authors state the set as \\(R^{1xh}\\), using an italic \\(x\\) as opposed to \\(\\times\\), indicating the array size of R being 1 by h. Hence, I believe the dimensionality of R should be represented as \\(R^{1 \\times h}\\).

6. Since the authors are using LaTex markups, I encourage them to express the learning rate as \\(10^{-4}\\) as opposed to 1e-4

7. The authors should define lora_alph and lora_r in the context of LoRA and display them with the appropriate LaTex markup (if applicable).

Overall, the authors have an extremely strong paper.",1
136,"Pros:
1. This paper address a meaningful and interesting research question that the existing large language models often return incorrect and inconsistent answers to input questions.
2. This paper has conducted solid experiment and the detailed experiment result.

Cons:
1. It will be better to give an concrete example for Declarative Constraints.
2. Although the experiment result is solid, only LLaMA-2-7B is used which will be good if there is more backbone models been considered.

Typo issues:
1. Related Works TODO: Reword -> Related Work",1
137,"The paper develops sample compression schemes for multiclass classification, regression, and adversarially robust learning. In particular, the paper provides novel reductions from sample compression schemes from these settings to binary classification schemes. It builds on the longstanding open problem in machine learning related to the sample compression conjecture, which proposes that any binary concept class with a finite VC dimension should have a compression scheme of size O(d_{VC}). At a high level, the authors show that : 

- if binary classification has a sample compression scheme of size f(d_VC), then multiclass classification has a compression scheme of size O(f(d_G \log(|Y|))) where Y is the set of the label and   d_G  is the graph dimension of the considered class. 

- Under further assumptions, such as the reconstruction function (in the sample compression scheme for binary classification) being stable, based on the majority vote of classifiers, or proper, this extra log(|Y|) factor can be avoided. This circumvents a recently established lower bound due to Pabbaraju et al. 2024.

-Similar reductions and separation are also provided for regression, and adversarially robust learning settings.  

- The authors introduced infinitized and inflated compression schemes to handle infinite data sequences, which I found to be novel; I was not aware of prior works discussing this. 

- The authors leave interesting open problems about whether compression schemes for regression can be improved using fat-shattering dimensions, instead of the pseudo dimension (currently considered in the paper). 

Overall the proofs seem to be straightforward. I see this paper as a collection of various small results on the same theme. Taken together they are sufficient for a good ALT paper. I recommend acceptance. This paper will serve as a useful tool when we finally resolve the VC sample compression conjecture. 

Questions / Cons: 
Can the authors discuss why is it even interesting to consider infinitized setting? It seems like an artificial construction. 
Can authors provide a discussion on the tightness of the converse direction, i.e. binary classification setting to the setting considered in the paper (multiclass, regression, adversarially robust learning, etc). Can the two directions be used to connect the seemingly unrelated problems of multiclass classification or regression to each other in a tight manner?",1
138,"## Summary
The paper addresses an important field of LLM evaluations.  Its focus on semantic understanding over pure accuracy is novel and positions it as a valuable contribution to mathematical reasoning and AI explainability. The authors use the NLP4PLP, a dataset of probability words, and evaluate three different LLMs: Qwen, DeepSeekMath, and Mathstral. 

## Strengths 

**Novel Evaluation Approach:** The evaluation approach present in the paper focuses on semantic and similar problem understanding rather than just accuracy

**Valuable Results:**  The authors show that Math tuned models still rely heavily on linguistic features rather than mathematical semantics in their internal representations

## Weaknesses 

**Limited Evaluation:** The authors only evaluate their results on a small dataset comprising probability-related problems. It would be interesting to see if these results are similar to those of other fields of mathematics, such as algebra. 

**Lack of reasoning behind the observed results:** While the authors demonstrate models' reliance on linguistic features over mathematical semantics in their representations, they lack theoretical analysis or hypotheses explaining this phenomenon in depth. Adding the same in more detail would strengthen the paper's contributions.",1
139,"Summary
The paper presents a novel method to improve fairness in machine learning models for electronic health records without using demographic data. It constructs a ""graph of gradients"" to identify underrepresented groups based on model gradient similarity. Weights are learned to increase the exposure of disadvantaged groups. Evaluated on diagnosis prediction tasks, this approach significantly enhances fairness metrics like equalized odds and disparate impact compared to prior algorithms. The paper argues for an interdisciplinary perspective spanning technical, medical, and sociological factors when examining algorithmic fairness in healthcare.

Strength
•	Proposes an innovative graph of gradients method to represent demographic groups and identify underrepresented populations for bias mitigation.
•	Theoretical analysis demonstrates gradients are more closely correlated with demographics than input features under reasonable assumptions.
•	Evaluation of two datasets shows significant improvements in fairness metrics equalized odds and disparate impact over state-of-the-art algorithms.

Weakness
1. The assumptions should be listed before the theorem, not in the appendix
2. The assumption that model accuracy and input features strongly correlate with demographic groups is quite strong and may not always hold in practice. The authors do not provide empirical evidence to support this.
3. The soft grouping method using a graph of gradients is interesting, but the authors do not provide much intuition or analysis into why this works better than prior methods.",1
140,"This paper proposes an innovative approach to predicting the dynamic knee moment using wearable sensors, AI, and ML algorithms. The author provides a detailed description of the model structure, training process, and explanatory analysis facilitated by the XAI tool. Here are some review comments:

Methodology: It is strongly recommended that the author explains the physical meanings of each symbol and letter in the formulas on the right side of the second page, as well as the distinctions and connections between the second and third lines of the formulas. Additionally, is the sample size of only 24 participants a bit small?

Results and Discussion: The paper's explanatory analysis of model predictions, particularly using the XAI tool, is very interesting. It is suggested that the author delves deeper into analyzing the model's performance, limitations, and future directions. For instance, a discussion on the model's adaptability to different types of patients or varying environmental conditions would be valuable.

Figures: Figures 3, and 4, along with their respective explanations, are crucial for readers to understand the research results. However, it is advised that the author provides more detailed explanations in the captions and legends of the figures to ensure readers accurately comprehend the information presented in the charts.

Overall, this paper presents a promising study demonstrating how the integration of wearable technology and AI/ML algorithms can predict the dynamic knee moment. Through explanatory analysis and detailed discussions on model performance, the paper has the potential to further strengthen its contributions and practical applications.",1
141,"In this paper the authors study the sample complexity of recovering low rank symmetric tensors from random symmetric rank-one measurements.

**Settings and result:**
Let the rank be $r\,$ the dimension $d\,$ and the tensor order $\ell$.
We are given samples of the form $Y_i=\langle T, X_i^{\otimes \ell}\rangle\,$ where $X_i\sim N(0, I)\.$
The main result of the paper shows that, information theoretically, $O(\ell^2\cdot r\cdot d)$ observations are enough to learn $T\.$
The authors complement this result by showing that $\Omega(d\cdot r^{1-\epsilon}/(\ell\log d))$ samples are necessary.

The problem is closely related to that of learning two-layer polynomial networks.

The result itself is not surprising,  the proof uses a combination of moment analysis for Gaussians (via the corresponding orthonormal base of Hermite polynomials), anti-concentration, and metric entropy bounds.
Given that the techniques used are well-understood, I feel the paper would have been stronger had the Gaussian assumptions been relaxed. 
More concretely, the authors do not clarify what are the limits of the technique used and do not try to investigate the distributional properties necessary to obtain a result as Theorem 2.
While there is value in this work,  I am inclined to consider this its main limitation.
 




**Comments:**
- I don't quite see the point of the section *""Comparison with ERM""*. There the authors show that the sample complexity of the least square estimator is significantly worse. I do not see how this is a meaningful comparison since this estimator is allowed to optimize over the entire $(\mathbb{R}^{d})^{\otimes \ell}$ space rather than in the lower dimensional space given by low rank symmetric tensors. Indeed, by adding such a constraint (via a regularizer or a constraint) the estimator would yield better guarantees (my guess is that these would be more in line with Theorem 2).
A more meaningful comparison could be made against larger classes of efficient estimators. 
By employing well-known (conditional) computational lower bounds, the authors could obtain a more insightful version of Theorem 5.
- The paper could be better contextualized. The literature on recovery of low-dimensional structures is vast and I believe a more accurate picture could improve the presentation of the results, as well as provide a starting point to improve Theorem 5.
A comparison with general (and efficient) M-estimators would be useful.
One additional line of work that could be worth looking at is that on oblivious adversarial models, a generalization of matrix\tensor completion. 

**Comments on the presentation:**
- The formulation of Theorem $2$ is a bit confusing. $T^*$ is first defined as a specific tensor, then the same symbol is overloaded to represent all tensors satisfying the given linear constraints. 
- In *""The Road for Proving Theorem 2""* the authors try to outline the proof structure of their results. I believe the section could be written better. As a concrete example the authors write *""We bound the covering numbers of $\zeta_S(2r)$ using a certain monotonicity property of covering numbers""*. 
However, this is quite a natural argument, that is not impossible to convey in a few lines. Hence a more effective strategy would be that of explaining what this property is, why it holds and how it is used here. 
- The presentation of the results is also a bit chaotic. For example, I did not find Proposition 3 more insightful than Theorem 2. It appears to me the importance of the proposition lies in the fact that it implies Theorem 2. In this case it might be better to just present Theorem 2 and then in *""The Road for Proving Theorem 2""* argue that the result is obtained via this proposition. 

**Questions:** 
- What can be said about the quadratic dependency of the sample complexity on $\ell$?",1
142,"The paper focuses on data-dependent regret bounds for the Online Portfolio Selection (OPS) problem with n assets and T time periods. They propose the LB-AdaCurv ONS algorithm with a worst-case regret of O(\sqrt{nT log T}) and a data-dependent regret of O(nR log T). The OUE-LB-FTRL algorithm achieves a regret of O(n log T) with accurate predictions and O(\sqrt{nT log T}) otherwise. The BoB-OPS meta-algorithm combines portfolios of an expected utility investor and a regret minimizing investor to achieve a regret of O(log T) for wrt the expected utility investor and O(n log T) for static regret. They also provide several new First-Order, Second-Order and Gradual-Variation regret bounds for OPS. 

Overall, I found the topic of the paper to be relevant, the new problem variants to be interesting (eg: integrating predicted returns), the technical advances to be nontrivial, and thus argue for the paper to be accepted. Some slightly more detailed comments are below.

The first two sections were very well written and easy to read for a non-expert (though it is dense, and one must read every line!). From this, it is clear that the results (if correct) are quite extensive and impressive, and require algorithmic as well as analytic advances to accomplish. However, the paper is extremely long and I did not have the time to check the proofs. I appreciated the tables very much, these were great summaries. 

The second half of the paper is well written enough to understand the algorithms, and the claimed theorems. But it is somewhat short of intuition. It is like a long list of algorithms and guarantees. In some sense this could be considered acceptable: the proofs are provided and one could check them, and the algorithms are variants of existing, sometimes well known, algorithms (with important tricks and alterations), so it would take too much space to describe the intuition of each algorithm. Nevertheless, it was not such an easy read.

I had a basic question. Why are some regret bounds of the form n \log T (which is minimax optimal) and others of the form \sqrt{T \log n}? What kinds of algorithmic techniques deliver regret logarithmic in n versus in T? Is there a fundamental reason that one cannot get ""a best of both worlds"" of this type?",1
143,"This paper develops generalization bounds for gradient descent methods and continuous gradient flows. Unlike the standard PAC-Bayesian bounds, the derived bounds are stated with high probability with respect to both the training dataset and the randomness of the initial model. The basic idea is that the density function of the trajectory can be expressed in terms of the Hessian matrix or Laplacian operator. In this way, there is no need to introduce a derandomisation step. The paper gives generalization bounds of order $O(1/m)$ if small empirical loss can be achieved, where $m$ is the sample size. Applications to specific models are then given, including random feature model and wide neural networks.

**Strength**
- The developed generalization bounds show advantages over existing PAC-Bayesian bounds as they are stated with high probability with the dataset and the initialization. Also, there is no need to introduce a derandomisation step.
- The paper gives comparisons with three popular approaches: PAC-Bayesian approach, stability approach and information-theoretical approach. As compared to the stability approach, the paper does not require a Lipschitzness assumption and can imply faster rates. As compared to the information-theoretical approach which implies bounds in expectation, the bounds in this paper depend directly on the optimisation trajectory.
- The developed generalization bounds are general in the sense that it considers a general $\Psi$ and $\nabla C_s$. Extensions to stochastic gradient descent and momentum dynamics are also given.

**Weakness**
- A downside of the bounds in the paper is that the derived generalization bounds look complicated. For example, in Theorem 4, the bounds involve $tr log (I-\eta\nabla^2C_s)$. It may be difficult to give a tight estimate for this term. While the paper shows that this can be bounded by the trace norm of the Hessian matrix in Lemma 5, this leads to a linear dependency on $d$. Therefore, the derived bounds may not be appealing for high-dimensional settings.
- For the applications to neural networks, the derived generalization bounds depend on $n\sum_k\eta_k \land \lambda_{min}^{-1}$. Note that $n$ can be very large, and then the term $n\sum_k\eta_k$ would be very large. Furthermore, the smallest eigenvalue is often very small, and then the term $\lambda_{min}^{-1}$ is also very large. Therefore, the generalization bound in Proposition 8 may not be quite effective due to $n\sum_k\eta_k \land \lambda_{min}^{-1}$. It is also interesting to state clearly how large $n_{\min}^\delta$ should be in Proposition 8.
- Several steps are not quite clear to me. For example, it would be beneficial to give some explanations on the equation $\partial_t\rho_t(h)=\nabla\cdot(\rho_t(h)\nabla C_s(h))$. Also, the notation $G_{\eta}$, $\widetilde{G}_k$ in the proof of Theorem 4 are not clear to me. It is also note clear to me how the equality $\tilde{G}_k(h_k)=h_{k+1}$ for $_k\in A_s$. 

**Typos**:
- Theorem 4: ""smoothwhere"" should be ""smooth, where""
- Section 6, the part with SGD: ""Id+\eta_k"" should be $Id-\eta_k$
- Proof of Corollary 3: "","" should be in the displayed equation",1
144,"# Summary

The paper proposes a physics-inspired soft constraint for training Koopman networks.
The constraint in question follows from the definition of the Koopman operator, and is given by $\mathcal{L}g = \nabla g \cdot \mathbf f$, where $\mathcal{L}$ is the Lie operator, $g$ is the observable function, and $\mathbf f$ is the ground truth ODE given by $\frac{d}{dt}\mathbf x(t) = \mathbf{f}(\mathbf{x}(t))$. 
In practice, the Lie operator is approximated by a square matrix $L$, which is learned during training and whose eigenfunctions and eigenvalues can then be estimated.
In experiments on a number of prototypical systems, the proposed method is able to recover the correct eigenfunctions and eigenvalues of the Lie operator.

# Strengths
1. (**significance**) The work has the potential to be impactful, due to apparently widespread interest in obtaining linear representations of nonlinear dynamics.
1. (**significance**) The proposed soft constraint is, to the best of my knowledge, a novel contribution.

# Weaknesses
1. (**significance**, **clarity**) It is not entirely clear what the paper is trying to achieve with the proposed method.
Unlike the data-driven methods referenced in the introduction, such as those based on dynamic mode decomposition (DMD) and variational autoencoders (VAEs), the soft constraint proposed here requires complete *a priori* knowledge of the ground truth dynamics $\mathbf f$.
In other words, the proposed method incorporates the ground truth dynamics into the training procedure.
It is then reasonable to ask: if we already know $\mathbf f$, why would we want to train a Koopman network to learn (a linear representation of) $\mathbf f$?
Despite the title of the paper, it seems that the proposed method is not very interesting in a purely time-series prediction paradigm, since we necessarily already know the ground truth dynamics.
We are therefore left to speculate about other settings in which the proposed method might be useful.
For example, and this is not discussed much in the paper, one might suppose that obtaining a linear representation of some known, nonlinear $\mathbf f$ is a worthwhile aim in and of itself.
According to Brunton and Kutz [1], “Expressing nonlinear dynamics in a linear framework is appealing because of the wealth of optimal estimation and control techniques available for linear systems.”
However, if this were the aim of the method, then this needs to be stated clearly and the present work put into the context of related methods for obtaining the Koopman modes from $\mathbf f$, including purely analytic approaches such as Laurent series expansions [1].
Indeed, while all of the systems studied in this paper have analytically tractable eigenfunctions and eigenvalues, there may exist systems where they are intractable [2], offering a potentially useful application of the proposed method.
1. (**quality**) The introduction claims that ""We demonstrate doing so reduce the need for large training data-sets and it enables the model to better predict beyond the training horizon,"" but neither of these claims is backed up clearly by the results.
The first claim would require a comparison to related methods while using varying amounts of training data.
The second claim would require a comparison to related methods using some kind of forecasting metric such as relative error (but I am still not convinced that this would be an interesting application of this method, as discussed in the previous point).
1. (**quality**, **clarity**) Further to the previous point, Section 3.2 claims that ""All physics-informed counterparts perform better than the original architectures"", yet the results in Table 1 suggest no significant difference between the proposed method and the baselines (although the exact meaning of the error quantity, i.e. the number after $\pm$, is not stated anywhere).
2. (**clarity**, **completeness**) There is no discussion in the paper about how to choose the dimension of the Koopman invariant subspace when it is not known *a priori*.
3. (**clarity**) Unfortunately, there are issues throughout the text with spelling, punctuation, formatting, and citations. 
As a result, presentation is a serious issue for the paper in its current form, which is hard to follow in places.
To give some concrete examples:
    - The citations at the beginning of the introduction are not formatted correctly.
    - Symbols and subscripts in the methods section are not well defined or consistent. 
    For example, in Section 2.2, $p$ is used to mean both the number of measurements and the number of collocation points (we have to go to the Appendix to find out that $N$ is in fact the number of collocation points).
    In the same section, $\mu_k$ appears out of nowhere, which is presumably supposed to be $\lambda_k$.
    - Table 1 is not referenced anywhere in the text, although it apparently contains the results for Section 3.2. 

# Conclusion
While the paper has serious issues in its current form, I think most of them can be addressed fairly easily.
In particular, with regard to the first weakness discussed above, I would encourage the authors to think carefully about what problem is solved by the proposed method and how it relates to existing work.

# Citations
[1] Brunton SL, Kutz JN. Data-Driven Science and Engineering: Machine Learning, Dynamical Systems, and Control. Cambridge University Press; 2019.

[2] Lusch, B., Kutz, J.N. & Brunton, S.L. Deep learning for universal linear embeddings of nonlinear dynamics. Nat Commun 9, 4950 (2018).",-1
145,"Summary:
The authors tackle the problem of solving locally checkable labeling (LCL) tasks on graphs using Multi-Agent Reinforcement Learning framework. In contrast to traditional supervised approaches that rely on ground-truth algorithms or enforce unique solutions, their framework uses verifiers to evaluate correctness. This method allows models to learn solution strategies independently, free from biases toward specific algorithms and supports the discovery of multiple valid solutions. They validate their framework on four core LCL problems, showcasing its ability to generalize effectively, surpass supervised baselines, and provide a flexible foundation for algorithmic reasoning on graphs.

Key Contributions:
* RL-based Framework: The method trains agents (representing nodes or edges) to learn decision-making policies based on local observations and verifiers.
* Flexibility: It supports problems with multiple valid solutions and avoids biases tied to specific algorithms.

The framework was tested on the four LCL problems:
* Maximal Independent Set (MIS)
* Minimal Vertex Cover (MVC)
* Maximal Matching (MM)
* Minimal Edge Cover (MEC) Results demonstrate superior performance compared to supervised baselines, particularly in generalization and solving edge-centric problems.

Strengths:
* The paper is clearly and effectively written.
* The proposed framework achieves better performance compared to supervised baseline methods.
* The RL-based approach eliminates the need for predefined labels or unique solutions, making it highly adaptable to a variety of LCL problems.
* The framework effectively handles problems with multiple valid solutions, addressing a significant limitation of many supervised methods.

Limitations:
* The RL-based framework involves tuning multiple parameters (e.g., reward functions, policy networks), which can lead to increased computational complexity.
* It is recommended to move the description of the RL framework from the appendix to the main paper, as it represents the core contribution.
* Clarification is needed regarding the dataset generation process for training, validation, and testing. Were the graphs generated randomly, and what is their distribution?
* Testing the framework on larger graphs with more than 16 vertices would have provided a more comprehensive evaluation.

Typos:
Page 2: “In GraphFSA, ach node...” change ach to each.
Page 4: “Architectures using gGCN show partial success...” change gGCN to GCN",1
146,"**Summary**:

The authors present a foundation model for chest x-ray interpretation with three novel components, they present an instruction-tuning dataset, a foundation model trained on this dataset, and a benchmarking tool to evaluate FMs across different CXR datasets. The authors showcase the performance of their FM across multiple tasks, such as Image Perception, Question Answering, and Text Generation. The authors compare their FM against other General and Medical-domain specific FMs across 8 tasks and 7 CXR datasets and indicate a general superiority of the performance of their models across the different tasks. 

**Pros**:

- *CheXagent's* performance looks impressive across the different tasks. They are able to demonstrate its utility as a Foundation Model by displaying generally superior performance across 7 tasks that are relevant to an FM in this domain.
- The authors comprehensively describe the steps they took to infuse the underlying LLM with medical and clinical knowledge. The overall architecture of *CheXagent* also appears convincing and matches intuition on their good performance across the different tasks.
- The authors have created a benchmark for evaluating FMs for Chest X-rays using their *CheXbench* benchmark. This is important for reproducibility and extending the evaluation across newer Chest X-rays datasets and Medical FMs. 

**Cons**:

- The authors mention they provided an evaluation of the disparities of the mode's performance across demographics, and important considerations for FMs when they envision their FMs being adopted into clinical practice by radiologists. 
- I would've liked the authors to provide a list of diseases they are evaluating the models on along with their distributions. It would have been interesting to provide some examples of the model's performance in the appendix. 
- I would've liked the authors to make a comment or two on interpretability, and how they think they could extend their work to incorporate measures of explainability and trustworthiness, which is fundamental to the adoption of AI models into clinical practice. Frequently, we run into the issue of developing ""black-box"" models in the field with not a lot of effort made into explaining how the model makes its decisions. 

**Quality**: 

The overall quality of the paper is good. 

**Originality**:

Even though it appears that some work has been done on building summarization models for Chest X-Rays using Multimodal LLMs like GPT, I believe the authors have done a good job highlighting the novelty of their work in compounding an extensive X-ray dataset, developing a novel FM specific to Chest X-ray and evaluating it across a variety of tasks.

**Significance**:

I believe this can be a significant model in the field of radiology if the authors are able to extend this work to take it out of its current ""black-box"" setting and integrate some form of explainability or generalization, and comprehensively evaluate how this model's performance differs across different demographics. 

**Miscellaneous Comments**:

- Have the authors considered incorporating the Noisy CXR dataset into CheXinstruct? The dataset presents the unique dimension of capturing label noise, and it would be interesting to observe how CheXagent performs under such a scenario.",1
147,"**Pros:**

- **Advancement in LLM Evaluation:** CRAFT-MD represents an advancement in Large Language Model (LLM) evaluation, moving beyond static exams to capture the complexity of real-world clinical conversations. This is particularly relevant as LLMs are increasingly being explored for healthcare applications.

- **Scalability and Ethical Considerations:** The use of AI agents for simulations offers scalability, ethical considerations, and control over conversation flow, providing a more controlled environment for evaluation.

- **Comprehensive Evaluation:** CRAFT-MD assesses various aspects, including history gathering, information synthesis, and diagnosis under different conditions, offering a comprehensive evaluation framework.

**Cons:**

- **Comparison with RAG-based Models:** Given the evolving landscape of clinical LLMs, it is suggested to explore the applicability and effectiveness of CRAFT-MD when used against models based on Retrieval-Augmented Generation (RAG). Including a comparative analysis with these models would offer valuable insights into the framework's performance relative to different approaches in the field.

- **Limited Generalizability:** The study focuses specifically on  two LLM models, potentially limiting its generalizability. Further exploration across a wider range of LLMs would strengthen the paper's applicability to broader contexts.

- **Need for Balanced Perspective:** While highlighting LLM limitations is valuable, a more balanced perspective could be achieved by also exploring potential strengths and areas for improvement.",1
148,"Summary:
The work showcases a novel and intriguing approach to Bayesian Experimental Design (BED) aimed at overcoming computational barriers in inverse problems for partial differential equations (PDEs). The key idea is to learn implicit neural representations of the parameters $a$ and the respective solutions $u$ and to use an energy-based model to learn a joint distribution over these latent encodings. This yields an efficient and resolution-independent surrogate for the joint posterior distribution, enabling more effective optimization of experiments within the BED framework. It is a highly relevant problem with many applications in complex systems.

Pros:
- The manuscript is well-written, and the authors successfully provide condensed information on the broad range of concepts they bring together in their approach without compromising completeness.
- Relevant related work is discussed sufficiently.
- They neatly showcase the capabilities of their approach in two examples.

Cons:
- A comparison to some other more recent method would be desirable.

Further comments:
- It would help the reader if in the supplement B equation (3), the reformulation were spelled out.
- It would be helpful to explain briefly how the compressed latent representations are precisely retrieved from the COIN++ framework.
- As they are discussed in the text, the t-SNE plots should be added to the appendix.",1
149,"The paper is concerned with generalisation bounds for (deep) neural networks under the assumption that the weight matrices of the individual layers are assumed to be low-rank. The paper derives upper bounds on the Gaussian complexity of these functions. A key proof ingredient is Maurer's chain rule. The results of this paper extend and go significantly beyond existing work, see Table 1. Moreover, I believe that this is indeed an interesting topic to study.

However, my major concern with this paper is that it is not yet ready to be published. This has to do with the style of how many theorems and lemmas are written up. For example, take Theorem 7, equation (4). The right-hand side depends on ||X||_F and ||W_i||_2, ||W_i||_F. These are quantities which are not really defined here since the left-hand side is a supremum over all possible X and W_i. Clearly this can be fixed by replacing the quantities on the right-hand side by uniform upper bounds (which are indeed an assumption of the theorem). However, this is not only the case in Theorem 7. Namely, the same issue appears also in Lemma 6, Lemma 5, Lemma 4,
While these issues can clearly be fixed by the authors, this is a ""major revision"" and I feel one should not give the paper a pass in the current state.

Further comments:
1.Equation (2): ""."" missing at the end
2. page 6: ||W||_2 = \prod_{I=1}^n ||W_i||_2 is not true in general (only less or equal)
3. page 6: ""Where Phi is ... linear activation function (ReLU or LeakyReLU)"" (incomplete sentence)


-----------------------------------
I have read the other reviews and the rebuttals by the authors. I do not really agree with response. In my opinion, this is not really the way to present the main theorems, regardless of how other papers are presenting the results. However, I think one can understand what is meant by statements. For this reason, if the other reviewers are fine with it, I would not ponder on this point further.

Regarding the content of the paper, I believe that the paper should is above the acceptance threshold. The result itself is novel and interesting although the proof itself is rather straightforward.",1
150,"Summary:
- This paper implemented a 3D Rubik's cube visualization and trained an agent to solve rubics cubes using DQN.
Further, it demonstrates that inverse reinforcement learning can be used to train a policy based on a dataset 10000 solving sequences of human solvers.

Strengths:
 - Implementation of an agent solving rubics cubes, using DQN
 - Collection of extensive rubics cube dataset based on many different human solvers

Weaknesses:
 - No ablations on design decisions
 - No evaluation of the main claims of interpretabilty/human-alignment/trust or anything similar
 - No comparison with baselines optimizing for shortest solving sequence (e.g. DeepCubeA)
 - Serious number of missing citations
 - The paper lacks a coherent narrative, it is not quite clear how the individual parts contribute to the overall goal

Detailed points for improvement:
- Abstract
  * Parts could be rewritten for improved clarity, for example sentences such as ""We demonstrate assisted reinforcement learning, ...""

- Related work
  * Please add an explanation of what CFOP really is
  * Please add a citation to support your statement about growing research area of intersection of AI and human problem-solving
  * Mention of prior works incorporating domain-specific heuristics into RL frameworks but no citations
  * Please add a citation to support your statement about IRL being the most common and usefool tool for inferring reward functions 
  * Please add a citation to support your statement of prior studies showing the usefulness of visualizations for human-centered AI 
  * Please add a citation to support your statement about interpretability in aligning AI systems with human cognitive processes having been underscored in many studies, but a single citation of an online article not underscoring the previous statement
  * Please add a citation to support your statement about that it has been shown that interpretability is necessary for trust and collaboration but no citations
  * Statement about breaking strategies down into human-understandable steps providing numerous benefits in AlphaZero, but citation of an online article not underscoring the previous statement
  * The following conclusion, using a 3D visualization instead of text further increasing interpretability is not supported by previous statements.

- ARL Approach
  * Please add a citation to support your statement about prior studies having shown the usefulness of visualizations in human-centered AI
  * What part of this training setup makes up the ""assisted"" in assisted RL? How does it learn from traditional human techniques/human intuition?
  * You introduce the interactive Rubik's cube model, but then you don't do anything with it. How do you use it? Can you show that it helps with interpretability or trust?
  * How long was the history in the observation you have eventually used? How did you model partial observability, and is this really necessary?
  * Given your sparse explanation of the moves, I am confused as to how invalid moves could occur. Some more details on this would be beneficial.
  * How do these actions relate to CFOP? These actions seem to be the default/obvious actions of a rubic's cube, also used in previous work (e.g. https://arxiv.org/pdf/1805.07470)
  * Please add a citation for Stable Baselines3 (see https://stable-baselines3.readthedocs.io/en/master/ at the bottom for proper citation)
  * Figure 2 is missing the axis labels
  * Your approach at hyperparameter optimization is commendable, however looking at Figure 2 and no reports of performance with respect to different random seeds, the performance difference might be dominated by randomness.
  * Using a callback and regular checkpointing is useful. I assume that you then select the best checkpoint according to mean episode length? IMO, this does not prevent overfitting, but allows you to select the best model before your policy diverges
  * Weird citation for the MLP used. Also, what MLP architecture did you use in the end?
  * How many steps of random permuations did you use for the initial state? Did your agent achieve 100% success rate regardless of the number of permutations?

- IRL Approach
  * Figure 3, do you mean ""over 50 moves"" for the right leafs?
  * How does the gym environment used here differ from the one for ARL?
  * Please cite the paper for AIRL, not only a library (https://arxiv.org/abs/1710.11248)
  * How do you initialize the generator, on what kind of synthetic environments do you pretrain?
  * What do you mean by ""The Adam optimizer was also used to stabilize learning rates""?
  * Could you provide some insights and details, ideally some quantitative analysis how you determine that the policy solves the cube in a very human like way? An option to achieve this would be to use your reward model to score the actions of your policy. You could then compare the rewards your model assign to your AIRL policy, to the ARL policy, some existing solvers such as DeepCubeA (Agostinelli, Forest, et al. ""Solving the Rubik’s cube with deep reinforcement learning and search."" Nature Machine Intelligence 1.8 (2019): 356-363.)
  * The dataset could be a nice contribution for future work. Please consider making it public.

- Conclusion
  * How was the 3D cube model crucial to the leisure of human users?
  * It remains unclear how human intuition was added to the ARL approach
  * It would be beneficial to mention that using IRL, you managed to build a reward function modelling human behaviour, based on your collected dataset of human moves.
  * Please actually provide some insights on the benefits of the learned reward function

Minor:
- Captions should be below the table for the AAAI style
- intrepretability -> interpretabilty
- more slow -> slower
- missing words ""DQNs utilize an \eps-greedy for exploration""
- Gym has been deprecated in favor of Gymnasium (https://gymnasium.farama.org/)
- Citation at the wrong place in ""Stable Baselines’ (Mnih 2013) implementation of DQN uses two neural networks""",-1
151,"Well written paper proposing a pipeline capable of predicting cardiovascular diseases. Custom models are used with a RAG layer to retrieve predictions.

The evaluation is well thought out. Overall a good contribution.",1
152,"This abstract presents an approach to building and benchmarking an AI system trained on Common Factors Theory using NLP techniques. Using labeled data, the work aims to use synthetic and generative technologies to generate and validate rare user cases. However, the model/method details are not clearly stated.

Pros:
* Applying common factors in AI development is a relatively novel idea
* Data in use is comprehensive and potentially sufficient

Cons:
* Method detail is not clearly stated (model architecture, how training is done etc.), and how Common Factors is integrated/reflected is not clear from current writing
* What is the difference between this work and the work supervised to detect different common factors? It would need more work to distinguish the contribution of this work and existing works.
* Vague connection with foundation models",-1
153,"## Overview

The authors introduce a new sparsity-focused library tailored for machine learning research. Built on the JAX platform, the library facilitates the implementation of an array of sparse algorithms, encompassing various sparsity patterns, both static and dynamic training sparsity, and multiple pruning metrics. A comprehensive set of experiments spanning diverse domains such as image recognition, natural language processing, federated learning, and deep reinforcement learning, attests to the library's adaptability.

## Comments

(+) The library has been effectively tested on an array of tasks, from image recognition to deep reinforcement learning, and incorporates numerous sparsity methodologies, from unstructured to dynamic sparsity. This demonstrates the library's comprehensive adaptability.

(+) Some features, like using int8 type for storing masks, are commendable, particularly given the growing prominence of expansive foundation models that demand extensive mask memory.

(+) The paper is well organized, delving initially into the reasons for creating a new sparsity-centered library, transitioning into its primary features, and culminating with in-depth benchmarking results.

(+) This library makes a notable contribution to the sparsity community, simplifying the process of implementing new ideas.

(-) An elaboration on its compatibility with other sparsity training models, like Mixture-of-Experts, would be beneficial.

(-) The paper lacks a comparative analysis with prevalent libraries (w. Pytorch or Tensorflow), particularly concerning training/inference velocity and memory consumption.",1
154,"This paper studies efficient learning of disentangled causal representations by approximating conditional probability differences with generalization loss.

**Quality** 
The paper is technically strong with solid theoretical analysis and extensive experiments.

**Clarity** 
The writing is clear and easy to follow. The problem is well motivated, and the proposed approach is intuitively explained. Theoretical results clearly convey the mechanisms and efficiency benefits.

**Originality** 
Approximating conditional divergence with generalization loss to identify causality is novel. This simplification enables direct leverage of standard ML workflows.

**Significance** 
The significant efficiency improvements enable wider application of causal representation learning.

## Pros
1. Intuitive approximation using generalization loss avoids the adaptation process.
2. Theoretical analysis clearly explains mechanisms and advantages.
3. Empirical results strongly demonstrate efficiency benefits.
4. Enables straightforward integration with standard ML workflows.

## Cons
1. More intuition behind the generalization loss approximation could be useful.
2. Experiments on more complex real datasets could better showcase benefits.
3. More discussion on sensitivity and failure cases would be helpful.
4. Comparison with more baselines besides the one previous method is needed.
5. A broader impact discussion could be added.",1
155,"The paper proposes a new training algorithm for neural ODEs based on a variational formulation. This effectively replaces the numerical ODE solver with numerical quadrature, with the goal of thereby accelerating the training procedure. 

Overall, the proposed method seems interesting and promising, and I think it is a valuable addition to the neural ODE literature. Unfortunately, I have concerns regarding the presentation and in particular regarding some claims made by the authors, that seem overly strong and insufficiently supported. I will elaborate on individual points in the following.
- *Numerical ODE solvers as the bottleneck for neural ODEs:* This claim is made throughout the paper, in particular in the introduction and in the abstract, but I find this statement quite unclear. 
  - ""existing training method, often based on adaptive-step-size numerical ODE solvers, are time-consuming and may introduce additional errors"": If anything, does step size adaptation not help with the efficiency by only evaluating the model when required? Also, in which sense does this introduce additional errors? Paragraph two states again that ""ODE solver-based training methods [...] are inherently time-consuming"", which again does not seem like a true statement.  
  - ""the optimize-then-discretize approach incurs additional numerical discretization error, resulting in inaccurate gradients, and potentially causng the training process to fail entirely"": To the best of my knowledge, this is due to stability issues of the adjoint ODE, and can be mitigated e.g. with checkpointing or computing and storing an interpolant; see e.g. [1].
  - Paragraph 3 again states multiple times that ODE solvers are the computational bottleneck and leads to inaccuracies, without substantial support.  
In summary, from the perspective of the initial Neural ODE paper by Chen et al, are ODE solvers not exactly the object that were added to ResNets that brought all of their nice benefits? An are adaptive steps not exactly the mechanism that saves computation? Of course, if there is a way to speed up the process that would be great! I just struggle to see the evidence for the claim that the paper tries to repeatedly make.  
- *The computational cost of the proposed method:* The introduction mentions that ""this VF loss requires one numerical integration"" (similar statement at the end of section 2.2). But does equation 4 not show that $C_j$ needs to be computed for $S$ different $g_s$ functions, implying that we need to solve $S$ integrals? In any case, with the strong claims made in the paper this statement could and should be much more rigorous: How many evaluations of the ODE vector field, i.e. the neural network, do existing methods need, and how many are needed by the proposed method? These numbers are directly comparable, as the main assumption here seems to be that exactly thos evaluations are the expensive part I believe? Or if the speed-up comes from a different aspect, e.g. the better parallelizability of numerical quadrature vs numerical ODE solvers, then this should be elaborated on. 
- *Insufficiently clear numerical evaluation:* The experiments compare many different methods, some of which are much more complicated than the simple neural ODEs that were required in the paper. I believe the evaluation would be strengthened by being much simpler. From my understanding, the main contribution of the paper is a novel loss function for training neural ODEs, as well as thereby also a novel way to compute parameter gradients. Just comparing this to existing methods would already provide helpful evidence. For example, benchmarking the cost of evaluating the loss function vs a standard loss function, and benchmarking the cost of evaluating gradients vs Opt-Dis and Dis-Opt and Seminorm; as well as also comparing the quality of both loss and gradients to some reference, e.g. computed by using an existing established ODE-solver based method with very low accuracy settings. A possible result of this would then hopefully be that all methods achieve similar quality of loss and gradients, but the proposed method presents a significant speed-up over the others. If then it was previously also discussed where exactly this comes from (number of NN evals or parallelisation?) then this would already be all the evidence that this paper needs. Of course, looking at multiple ODEs and even at ODE-RNNs etc is good additional evidence.

So overall, I do believe that the proposed method is valuable and should be presented to the neural ODE community, but in the current form the paper makes too many claims that are insufficiently supported. I would strongly recommend to the authors to revise the manuscript, soften many claims, and provide a simpler and clearer evaluation of the method, to better present this interesting method. 
  
  
[1] Ma et al, ""A Comparison of Automatic Differentiation and Continuous
Sensitivity Analysis for Derivatives of Differential Equation Solutions""",-1
156,"- Myocardial injury after non-cardiac surgery (MINS) is a postoperative complication presented in diverse profile patients and marked by varied symptoms. Thus, its early prediction is a challenge and ML approaches, even heavily utilized, present some difficulties in processing unstructured and imbalanced data.
- Authors propose a framework based on the one presented in https://arxiv.org/pdf/2306.02052.pdf (RBF), called Retrieval Based Disease (RBD) Prediction framework. Their approach transforms multifaceted pre-operative and intra-operative tabular data into coherent text-based descriptions, enabling the use of Language Models (LM) for data interpretation.
- The authors face an imbalanced dataset of MINS, with only 7.9% of the total patients experiencing MINS. They compare their framework with a RandomForest, a XGBoost, a BERT-base and a SciBERT, ClinicalBERT and BioBERT fine-tuned for binary classification. They show that their RBD framework outperformed the ML approaches and the LM ones. Even with an ablation study, RBD-t showed better performance than the others (but the original RBD).

The presented framework is a variation of a pre-existing one (RBF) and combines it with other Languange Model for Biomedical domain (PubMedBERT). However, the methods seem to be properly adapted and a good choice to the problem to be tackled, with the corresponding citation. The framework is correctly presented in Figure 2 and the results of the few experiments presented clearly in Tables 1 and 2. 

The presented results show a good improvement compared with the other baselines, which seem to be diverse and relevant enough; first, two widely used ML techniques and then 4 domain specific language models. Even the ablated version of the framework (RBD-t) overperforms the other baselines, despite performing worse than the not ablated RBD. 

Even though it uses pre-existing methods, the need of adaption of it to imbalanced datasets is essential and the significance of having early detection techniques without the need of post-operative data is valuable. 

Regarding to format and clarity, the work is well presented and clearly structured, having not found major errors in the writing. The trivial next steps are presented as future work, with the aim of making the framework more general by extending it to multi-label datasets. 

COMMENT:

- If I am not wrong, the only innovation here is the adaptation of RBF to medical data by using a specific BERT model for biomedical NLP tasks, named PubMedBERT. Right?
- What is the explanation of K=3 showing the best results?",1
157,"This paper proposes a white-box Transformer architecture for visual segmentation tasks. The model is designed to optimize the sparse rate reduction objective, which results in the property that each layer first compresses the distribution of tokens and then sparsely encodes the next representation. The visualization shows a good segmentation performance compared with ViT. Meanwhile, each layer and attention head is explainable. This paper is very well-written. However, I still have several questions or concerns.

1. What is the major contribution compared with [51]? From my understanding, the architecture seems similar to [51]. Is the contribution mainly about the tasks on segmentation? 

2. It would be better if there were more theoretical explanations of the relationship between the CRATE model architecture and segmentation tasks in Section 2. I like the proposed mechanism of each layer, but it is unclear how it helps segmentation tasks in theory. 

3. I will treat such work as an important work on the theoretical understanding of Vison Transformers. The proposed mechanism of first compressing and then sparsely encoding is very interesting to me. Some recent theoretical works [a], [b], [c] on (Vision) Transformers provide another explanation of the learning process, which could be summarized as feature matching and selection. It would be great if this paper could cover a discussion with these works. 

4. A minor point. How do you compare the training efficiency of your proposed method with existing works on segmentation tasks?


[a] S. Jelassi et al., Neurips 2022. ""Vision transformers provably learn spatial structure.""

[b] H. Li et al., ICLR 2023. ""A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity.""

[c] Y. Li et al., ICML 2023. ""How do transformers learn topic structure: Towards a mechanistic understanding.""",1
158,"The paper presents a hierarchical volumetric text to image model. The authors integrate a use of mask annotations to stabilize the generation process to improve generated results. The model is trained on a custom dataset with pseudolabeled anatomical annotations. The metric scores on the custom dataset seem rather low thus some reference values to set the methods into perspective might be helpful. Additionally, it would be great to see the individual impact of each considered mask in the process. What happens when omitting what?
Overall the idea seems nice and interesting and as such i tend towards accepting the paper.",1
159,"This paper studies the problem of Online learning of quantum states with respect to the Logarithmic loss function. In general, in online learning framework, there are two players: say the Physicist and the Reality. The game is played for $T$ rounds in a sequential manner. At every round (say at round $t$), the Physicist decides a density matrix $\rho_t$, and then Reality announces a Hermitian positive semi-definite matrix $A_t$, and the Physicist suffers a loss of $- \log tr(A_t \rho)$. The primary goal is to design efficient algorithm to minimize the cumulative loss of the Physicist over the $T$ rounds against all possible strategies of the Reality. This is commonly referred as the regret minimization problem and has been extensively studied for several decades in the classical setting.

Recently Aaronson et al. (NeurIPS 2018) initiated the study of online learning in the quantum setting, and since then there have been several works in this setting. However, this problem has been primarily studied when the loss function is convex and Lipschitz continuous. In this work, the authors studied the problem for the logarithmic loss function which they define as LL-OLQS (Online learning of Quantum states under logarithmic loss). However, since the logarithmic loss function is not Lipschitz continuous, the known techniques do not extend directly.

In this setting, the current best result is by Zimmert et al. (COLT 22) which achieves the regret of $O(d^2 \log T)$, where $d$ is the dimension. However, the algorithm of Zimmert et al. evaluates a high dimensional integral in every round. The authors in this paper design an algorithm for LL-OLQS with regret $O(d^2 \log(d+T))$ where each iteration of the game can be performed in polynomial time using semidefinite programming.

The authors follow the techniques of Jézéquel et al. (2022) who designed an algorithm VB-FTRL for the celebrated Online Portfolio Selection (OPS) problem. However, the approach of Jézéquel et al. does not immediately translate to the quantum setting. In particular, the technique of affine parametrization does not work here. Moreover, Jézéquel et al. used the convexity of the Volumetric Barrier (VB) (see Section 2, paragraph 1) for bounding the final regret, which does not directly translate to the quantum setting.

In order to bypass the second bottleneck, the authors define the notions of VB-convexity in the quantum context (see Definition 3 & Theorem 7, Section 2.1). They show that the volumetric barrier associated with any convex function remains convex (Lemma 5 & Corollary 8), which is crucially used for the regret analysis in Section 3. To bypass the first bottleneck, they used techniques from the work of Tsai et al. (NeurIPS 23) (see Lemma 13, Section 3).

The proof of the main theorem (Theorem 1) is described in Section 3, which follows the Follow the Regularized Leader (FTRL) approach from Jézéquel et al. with the new notion of the Volumetric barrier convexity and establishes the total regret of $O(d^2 \log(d+T))$. There is a gap of $d$ with the current lower bound of $d \log T$ which follows from the universal portfolio selection. The authors also mention this in the introduction.

I think the new notion of the volumetric barrier (VB) convexity in this context is novel and would be of interest to the ALT community. I support accepting the paper.

Comments:

1. I think adding a table of prior results mentioned in the introduction would be better to follow.
2. I think presenting a brief overview of the regret analysis in Section 3 would improve the readability of the paper.",1
160,"This paper presents a new IQA method that combines the data-centric IQA and model-centric IQA. Basically, this paper is more likely an active learning method in my opinion. Using existing IQA models and VGGNet to select the most valuable data.

At first, the author demonstrates the drawbacks of the previous data-centric IQA and model-centric IQA. Data-centric suffers from the easy dataset problem and model-centric suffers from the overfitting problem. Then introduce a method that uses IQA models and  VGGNet to find the difficult and diverse samples. 

The reason for the improvement of this method also seems to be intuitive. There are no obvious weaknesses in this paper to me.

I am not familiar with this field but I do buy the main idea of this paper.",1
161,"Summary:

This paper aims to propose a framework for view selection in the NeRF optimization. The key motivation is to quantify the uncertainty in NeRF training. The author uses the Fisher information during training to produce an uncertainty channel and leverage it to design a view-selection policy. The proposed framework outperforms the previous approach ActiveNeRF by a clean margin.

Strength:
1. The paper is well-motivated and the proposed solution is reasonable.

Weakness:
1. Lack of novelty. There is one paper FisherNeRF [a] shared similar motivation and designs as BavsNeRF. Both of these papers use Fisher information to quantify the uncertainty. The key formulations of these two papers are kind of similar. 
2. The acknowledgment should not appear in the submission.
3. The writing could be further improved in the format (e.g, line 333, 3.2 -> sec 3.2), and caption of section (e.g. Conclusions in Sec5)

[a] FisherRF: Active View Selection and Uncertainty Quantification for Radiance Fields using Fisher Information",-1
162,"Strength:
The method outperfomrs state-of-the-art models: the method yields significantly better performance on diagnois production and heart failture prediction for two MIMIC datasets. 


Weak points and suggestions: 
1. Missing important related work on bridging ICD code with LLM:
(1) ""DRG-LLaMA : tuning LLaMA model to predict diagnosis-related group for hospitalized patients""
(2) ""CPLLM: Clinical Prediction with Large Language Models""
2. Unclear writing:
(1) This sentence is confusing to read: “But there is still a significant gap between the primary language, i.e., natural language, with the model’s hidden represntation” 
(2) In the 'Performance of Memorization' section, what is the sample size? How many ICD-9 codes were assessed? 
3. Presentation error: 
(1) Missing citation: ""The events are normally presented in medical code format, such as ICD-9 disease codes, with a large candidate space to choose from (13,000 disease candidates in ICD-9) (?)""  
(2) Figure 1 is difficult to read and could benefit from additional labeling.",-1
163,"Authors present an approach to use language model to predict the diagnosis of the next visit of patients given as input a sequence of visits and their associated code-diagnose. They benchmark the new approach with existing approaches and standard datasets form medical settings. 

The paper is original in the use of language model technology for next visit prediction, however the reviewer and reader would appreciate more detail in how the system is built and how it learns, specific parameters. What type of model do authors use, what is the architecture, is it an encoder-decoder, only decoder architecture? How is the fine tuning performed?

 I would like to suggest that the clarity of the writing could be improved. There are some sections where the language appears a bit unclear or could benefit from a revision for smoother readability. I recommend a thorough review of the English language throughout the manuscript to enhance its overall clarity. This will undoubtedly contribute to a better understanding of the valuable research.",1
164,"This paper proposes two potentially useful metrics, CHAIR and DVH, for evaluating medical LVLMs. Overall this is a good metric proposal, although given the use of chest X-rays, some comparison to other metrics like RadGraph and CheXBert would be useful here.",1
165,"**Summary of the paper:**
The authors present an analysis of three different manners to process neural stochastic differential equation initial condition for astronomical data. The initial condition is first transformed to fill in some missing data, either through cubic interpolation, mean filling, or 0 filling. This transformed condition is then passed into a latent space where the SDE is solved.

**Strength of the paper:**
The motivation of the paper are well described (the need to properly define initial conditions), and the review of neural ODEs, SDEs, and Langevin SDEs is well written. Regardless of the choice of initial condition processing technique, the use of Neural LSDE seems to outperform other neural network based approach.

**Weakness of the paper:** The three different approaches to handle initial conditions are not well described and are particularly confusing in light of Figure 1. The authors state that the goal is to handle missing data in the initial condition, but in figure 1, the missing data is filled across time. It is not clear if figure 1 represent x or z(t), and what each color represent. The author mention that in approach #2, the mean is used in-lieu of missing data, but it is not clear which mean. In figure 1.c, it rather seems like the missing data has been replace by zeros, instead of a (undefined) mean. It is also very puzzling to me that if any value is missing from x, it is fully replaced by zeros. In this case, all the initial condition with missing data would be processed into the same initial condition, and the variance across solutions would no longer be function of the initial condition, but only the SDE inherent stochasticity. 

The dataset description is also unclear: Solving neural differential equations implies that we are looking at predictions that a continuous time series, but the dataset mentions classification. How do SDEs fit with classification tasks?",-1
166,"This paper provides a comprehensive analysis of the current state and future prospects of clinical Large Language Models (LLMs), focusing on domain adaptation strategies, performance comparisons, and the potential impact on healthcare. The following points should be considered:
1. How did the authors ensure the fairness of the results reported in Table 1, given the varying sizes, training data, and training methodologies employed by these models? Especially the differences in the evaluation settings on these two datasets, for example, BioGPT and GatorTronGPT employed prefix-tuning/prompt tuning to evaluate the pretrained LLMs, where the parameters of the LLMs are kept frozen, while PMC-LLaMA and BioMedGPT employed instruction tuning/fine tuning on the target dataset, where the parameters of the LLMs are trainable and may be better adapted to the downstream tasks.

2. The results in Table 1 are informative but could be enhanced, for example, the performance metric should be clarified, the column name ""Approach"" should be ""Training approach"", and the unit of parameter size should be clarified (e.g., 70B ->70 Billion). In the "" Training data"" column, there is some confusion about the unit (e.g., 160K data, 47B tokens). It would be beneficial to add a column to report the computational cost for each model.

3. Could the authors elaborate on the ethical and legal implications of using potentially copyrighted or sensitive patient data in training clinical LLMs?",1
167,"This paper examines the sample complexity required for recovering low-rank symmetric tensors from symmetric rank-one measurements. The authors adopt a random setting where the rank-one measurements are inner products with rank-one symmetric Gaussian random tensors. By leveraging tools such as covering number arguments and the Carbery-Wright inequality, the paper establishes both upper and lower bounds on the sample complexity. 

The nice thing about this paper is that the obtained upper and lower bounds only differs by a polynomial factor with arbitrarily small degree. Additionally, the authors also discuss the applications of their results to two-layer polynomial neural networks. However, the proposed natural rank minimization problem is NP-hard (as noted by the authors), and hence not applicable in real practice. I would be more interested to see a more in-depth analysis of sample complexity of empirical risk minimization, or some convex relaxations of the original optimization problem. Further, this paper only considers the setting where the linear measurements are exactly known. It would be better to extend the analysis to settings where measurement errors are allowed, and explore the dependence of sample complexity on the errors.",-1
168,"This is a review of the manuscript, ""Minimizing structural vibrations via guided diffusion design optimization,"" submitted to the ICLR 2024 Workshop on AI4DifferentialEquations In Science}. The paper describes a diffusion-model-based method to design a beading pattern for vibration control (damping). The authors report a modified thin-plate system that responds to external forcing, and the response is characterized via the frequency-integrated mean-square velocity. Two neural networks, $\theta$ and $\eta$, are trained to generate beading patterns and predict the frequency response for a specified plate geometry, respectively. In both cases, a U-Net architecture is chosen. A guided-diffusion algorithm utilizes $\theta$ and $\eta$ to iteratively update a plate design, starting from a random seed. Numerical experiments that demonstrate the ability of this approach to generate designs which are superior to all elements of the training dataset are reported.\par

The paper is well-written and provides a helpful overview of the physical problem, and the work is of a high quality. Moreover, the authors note the primary limitation of their technique, namely: the high-cost and parochial scope of the trained networks.",1
169,"Summary: This paper introduces an approach to PDE control problems; the goal is to learn to control the PDE behavior. The DiffConPDE model learns under the condition that the explicit form of the PDE may not be known, rather what is known is observed control sequences and trajectory data. A generative denoising diffusion model is used to generate the trajectory, and an inference algorithm estimates the optimal control signal.

My research area is in solving PDEs with ML, not PDE control. I also am not familiar with the mathematics of generative diffusion models (sorry!), so I do not understand the meaning of equations (6) (9) and (10). For those reasons, my review comes with relatively low confidence.

This paper is well-written, well-motivated, clearly of interest to the workshop, and seems to achieve good results (both in the main text and the appendix). I am quite happy with this paper.

It is possible that there are flaws with this paper that I am not aware of (better baselines, prior work with similar ideas, etc). However, I don't have any reason to suspect these flaws exist.

I believe this paper is clearly in the top 50% of accepted papers. I am not familiar enough with this research area to decide that this paper falls into the top 15% of accepted papers, but I would not disagree if someone more familiar with the research area felt that it deserved such a rating.",1
170,"In reviewing this manuscript, it is clear the authors can intellectually articulate the focus of their study. They were able to explain the rationale of their research as well as their results. 

I would encourage the authors to discuss the results of their RBD model in the abstract.” At present, the abstract states their ""LM-based approach outperforms traditional machine learning methods"" but does not state any results.

Overall, I believe this is a strong work from the authors.",1
171,"Summary:

This paper proposes a nuclear norm regularizer to facilitate domain generalization. The proposed approach is evaluated on standard domain generalization benchmarks. Theoretical analysis with a toy example is given to justify the approach.

Advantages:

1. The paper is clearly written and easy to understand. The domain generalization problem is important and relevant.

2. The proposed regularizer is well-motivated with theoretical insights, and the synthetical data experiment offers clear intuition.

3. The method is thoroughly evaluated and compared with existing domain generalization baselines. Although the method itself is not the most performant approach, it shows compatibility with other approaches thanks to its simplicity.

4. The method is ablated carefully, giving the reader more insights into the method's property.

Downsides:

1. While the approach is simple (which is a commendable property, in my opinion), it can incur significant computation burden and instability, placing constraints on the batch size and the representation dimensionality.

2. The performance seems highly sensitive to the weighting factor $\lambda$, which may compromise the practicality of this method. Clearly, there is a subtle balance between norm regularization and classification performance, where the former, if not properly tuned, can throw away valuable information in the model representation.",1
172,"This paper presents an innovative approach to address the challenges of medical image segmentation across diverse imaging modalities using limited computational resources. The authors propose incorporating a class-prompt mechanism into a lightweight TinyVIT architecture, enabling efficient and accurate segmentation tailored to specific modalities.

Contributions:
1. The introduction of class prompts, inspired by the specialized organization of hospitals, allows the model to adapt its segmentation capabilities to different imaging modalities effectively.
2. The proposed class-prompt TinyVIT model achieves superior segmentation performance, particularly for challenging modalities like PET and microscopy, while maintaining competitive results for other modalities.
3. The lightweight nature of the model, coupled with its high accuracy, makes it suitable for deployment on resource-constrained devices, such as laptops with limited computational power.

Strengths:
- The paper addresses a critical need in medical image analysis by enabling accurate segmentation on low-resource devices, facilitating widespread adoption in resource-constrained settings.
- The authors provide a comprehensive evaluation of their approach, including quantitative and qualitative results, demonstrating the efficacy of their method across various imaging modalities.
- The methodology is well-explained, and the authors provide insightful discussions and analyses of their findings.

Suggestions for Improvement:
1. While the authors mention the potential for real-time processing, it would be beneficial to provide more explicit benchmarks or comparisons with existing real-time segmentation methods to highlight the computational efficiency of their approach.
2. The paper could benefit from a more detailed discussion on the limitations and potential failure cases of the proposed method, as well as strategies to address these limitations.
3. The authors could explore the generalization of their approach to other medical imaging tasks beyond segmentation, such as detection or classification, to further demonstrate the versatility of their method.
4. Additional ablation studies or sensitivity analyses could be conducted to investigate the impact of different hyperparameters or architectural choices on the model's performance and efficiency.

Overall, this paper presents a promising solution for accurate and efficient medical image segmentation on resource-constrained devices. The authors' contributions are significant, and their work has the potential to facilitate the widespread adoption of medical image analysis in low-resource settings. By addressing the suggestions outlined above, the paper could be further strengthened and provide a more comprehensive understanding of the proposed approach's capabilities and limitations.",1
173,"This paper proposes and studies multi-sampling, which generalizes the notion of single sampling proposed in the previous papers. Essentially, given i.i.d samples from distribution D, multi-sampling asks the algorithm to output m samples, with distribution close to $D^{\otimes m}$ . 
Despite the question has been studied when m=1, running the algorithm multiple times does not yield the right sample complexity even for very simple distributions, as shown in the paper.

In the paper, they study two basic distributions, the discrete k-ary distribution and the Gaussian distribution.
For discrete k-ary distribution, under approximate differential privacy, they give improved sample complexity linear in $m/\epsilon$, which improves the trivial baseline linear in $m^2/\epsilon$, where $\epsilon$ is the privacy parameter. 
For Gaussian distribution, they give pure differential privacy algorithms, while previously only approximate DP algorithms are known. 

**Merits** The problem studied is natural and exciting, especially due to the improvement over the baseline by running single sample algorithms.

**Drawbacks** 
1. There should be a statement of (informal) main theorem at the beginning of the paper, for the most important result
2. The lower bounds and upper bounds for the sample complexity does not match for discrete distributions. 
3. The Euclidean-Laplace mechanism for the gaussian distribution(equation (3)) does not seem to run in polynomial time.",1
174,"Pros:
- The authors articulate a well-defined research question and address it with clarity and efficiency;
- There's a comprehensive evaluation conducted against various state-of-the-art large language models, both open-source and proprietary;
- The presentation of results is clear and straightforward.


Suggestion for improvement:
- It would be beneficial to explicitly indicate in Table 1 which backbone corresponds to PE-FT and FP-FT; I assume it's llama70b. Additionally, including a column for llama7b would give the complete picture.
- It would be insightful to detail the computational resources required, in terms of GPU hours and memory, for both PE and FP fine-tuning. Providing this comparison could offer a clearer understanding of the differences in resource intensity between the two methods.",1
175,"Pros:
- The authors articulate a well-defined research question and address it with clarity and efficiency;
- There's a comprehensive evaluation conducted against various state-of-the-art large language models, both open-source and proprietary;
- The presentation of results is clear and straightforward.


Suggestion for improvement:
- It would be beneficial to explicitly indicate in Table 1 which backbone corresponds to PE-FT and FP-FT; I assume it's llama70b. Additionally, including a column for llama7b would give the complete picture.
- It would be insightful to detail the computational resources required, in terms of GPU hours and memory, for both PE and FP fine-tuning. Providing this comparison could offer a clearer understanding of the differences in resource intensity between the two methods.",1
176,"### Summary

This paper proposes a foundational model for sleep-related tasks and shows its efficacy through two downstream tasks - (i) sleep apnea detection, and (ii) sleep stage detection. While it proposes a novel application of two interesting pre-training techniques, the experimentation does not truly evaluate the potential of the proposed foundational model. Overall, the paper is built on a promising idea and its presentation can be further improved through more rigorous experimentation.

### Strengths
- Novel application of pretraining tasks to align multiple modalities to create a sleep (time-series) foundational model
- Paper is written with clarity, explaining proposed methods and experiments well
- Promising results

### Weaknesses
- “Foundational Model” capabilities have not been evaluated: To claim that a new model is a foundational model, it must satisfy certain properties of foundational models (FM). It is the authors’ responsibility to then highlight the properties that have been tested and note limitations of the foundational model. For example, a common property found in foundational models is the ability to generalize reasonably well to an unseen dataset. 
- Weak baselines: Ideally, the model should be compared with other methods which have been trained for the proposed downstream tasks. Eg: [1] is a sleep apnea detection method which can be included as a baseline.

### Other Feedback (to extend this work):
- The authors should motivate whether a foundational model for sleep is in fact useful. Identifying the shortcomings of existing methods (which do not consider all modalities, for example) and clearly delineating the research questions that you would like to answer would be a good way to approach this.
- Authors considered separate encoders for the different modalities. Some recent papers on time-series foundational modeling have shown that a single time-series model can encode time-series of different #channels and frequencies [2, 3]. Consider using one of these methods as the base model for your proposed pre-training tasks. This could help better align the modalities, especially if one of the modalities is more sparse than others.
- Experiment on the effect of leaving out one modality - could motivate the need to jointly model multiple modalities.

[1] https://ieeexplore.ieee.org/abstract/document/8571271
[2] https://arxiv.org/pdf/2302.11939.pdf 
[3] https://arxiv.org/abs/2402.03885",-1
177,"1. Summary and contributions: Briefly summarize the paper and its contributions
- The paper outlines the development of billion parameter GatorTron, an encoder only, and GatorTronGPT, a decoder only, transformers. 
- They are trained from scratch on billions of text tokens, both from general text corpora as well as de-identified clinical notes. The paper then goes on to summarise the previously published performance of the models on commonly used clinical NLP benchmark tasks.

2. Strengths: Describe the strengths of the work. Typical criteria include: soundness of the claims (theoretical grounding, empirical evaluation), significance and novelty of the contribution, and relevance.
- It is a huge (maybe unique?) technical achievement for an academic institution to be able to train billion parameter LLMs on billions of tokens.
- The performance on various benchmarks is very strong.
- Highly relevant to this symposium

3. Weaknesses: Explain the limitations of this work along the same axes as above.
- The hypothesis of this work is that explicitly including clinical notes in an LLM’s training data aids performance on downstream clinical tasks. Therefore, a direct comparison to state-of-the-art general LLMs (e.g. GPT/Gemini/Llama/Mistral) in Table 1 would strengthen this argument. Especially since general LLMs have been through RLHF, unlike GatorTronGPT
- Not clear why the models were trained from scratch instead of finetuning a generally pre-trained model. Although the training corpus size is large, it is still dramatically smaller than that used in open-source models (such as Llama 2 trillion tokens)
- Does GatorTronGPT exhibit zero/few-shot learning abilities, or must it be finetuned?
- No section on ethical considerations or the ethics board approval. This is highly relevant given the large-scale use of (de-id) clinical notes and the subsequent open-sourcing of GatorTron. This is a great initiative, so it would be helpful to be explicit on how this was achieved so others could do the same in the future.
4. Correctness: Are the claims and method correct? Is the empirical methodology correct?
- “GatorTronGPT provides a solution to solve many diverse information extraction and classification tasks using unified text-to-text learning” seems like a strong statement.
- The methodology, although only briefly outlined due to page limit, is sound.
5. Clarity: Is the paper well written?
- The paper is well written. However, the last paragraph of the conclusion is oddly formatted and does not seem to follow from the previous one.
- The repetition of Peng et al b and c on seemingly the same datasets and tasks but with differing performance rankings in Table 1 is a little confusing.
- Would be useful to note the context window of the models.
6. Relation to prior work: Is it clearly discussed how this work differs from previous contributions?
- Yes, a clear explanation of general-purpose LLMs and their evaluation in biomedical/clinical NLP space. This then goes on to outline the limited specialised training of LLMs in the clinical domain. Although the motivation for this is implicit rather than explicit (training on clinical data may lead to better results on clinical tasks) 
7. Reproducibility: Are there enough details to reproduce the major results of this work?
- No, but that is out of scope, given the page limit. The author could add the compute required to train the models.
- Links to the open source model weights or training code would be helpful.",1
178,"in the introduction, the authors say ""Message Passing Neural PDE Solver (MO-PDE) ... a limitation of their approach is that it can only predict the solution ... on the same grid used as input""

The authors should better clarify:
1. why this is a problem for practical simulation applications
2. hHow the GraphDeepONet proposed approach addresses and solves this limitation.",1
179,"The paper's approach of integrating bounding box prompts into the nnUNet architecture for enhanced segmentation in resource-constrained environments is a creative application of existing technologies, suggesting moderate innovation. Employing JIT compilation and OpenVINO optimization for deployment on edge devices indicates a strong technical foundation. The methodological enhancements, including the use of channel masks and the adaptation to a 2D slice-wise approach, are well-justified and align with the goals of efficient processing. The paper presents a well-rounded approach with practical applications and notable enhancements to a well-established segmentation framework. The focus on resource efficiency and real-world applicability, particularly for clinical settings with limited computational capabilities, is commendable.",1
180,"This paper proposed a method that utilizes the potential capacity of pre-trained StyleGAN to generate temporal micromotion frame sequences. Based on the hypothesis of Low-rank Micromotion Subspace, the workflow consists of three steps including Reference Anchoring which obtains a set of latent codes corresponding to the desired action performed by the same person, Robust space decomposition that utilizes robust PCA to find the edition direction, and subspace transformation that interpolate or extrapolate along the edit direction to obtain the intermediate frames.  


The idea is clear and interesting. The results seem to be promising. The hypothesis is meaningful. I do recommend to accept this paper.

A question: Why the results of PCA could provide the edit direction \delta V? Could provide more detail about this? Moreover, what is the shape of \delta V?",1
181,"The paper proposes an excellent end-to-end pipeline from training to deployment. The accuracy and efficiency of their method is great. The source code provides comprehensive reproducibility. Here are some advices for the paper:

1. In Fig.1, the author shows that the output of the image encoder is the image embeddings. Correspondingly, the output of the prompt encoder should be pointed out as well.

2. In Fig.2, the purple masks and boxes on the right subfigure is inapparent. The author should use a brighter color.

3. The font in figures should be Times New Roman.

4. In Table.6, the reason that MedSAM gets N/A on both runtime and memory usage should be pointed out. The reader may not be one of the challenge attendee and not familiar with the threshold.

5. In section 2.2 Loss function, the author should provide further explanation as to why the Focal Loss deserves more attention.",1
182,"This paper upper bounds the sample complexity of differentially private density estimation of Gaussian mixture models (GMMs). It considers agnostic learning: the input is iid from an arbitrary distribution, but we want to compete with the best mixture of $k$ Gaussians in $d$ dimensions. The mixture weights, means, and (positive definite) covariances may be arbitrary. The main result is an $(\varepsilon,\delta)$-DP learner with sample complexity roughly $k^2 d^4 \log(1/\delta)/\varepsilon$ (ignoring accuracy parameters). This is the first result for this task; applied to the realizable setting, it improves upon Afzali et al. (2024).

The analysis constructs ""list globally stable"" (LGS) learners, which return a set of distributions containing (usually) a good estimate and also satisfy a form of stability: for any input distribution, there is an output that often appears in the list. The proof has three main parts. First, one can turn a non-private LGS learner into a private algorithm. This seems to be a careful application of existing private selection techniques. Second, we see how to construct an LGS learner for mixture models given access to an LGS learner for the single-component/base distribution. The algorithm is simple (run the base learner on every subset of samples) but the analysis seems subtle. Both of these steps apply to general distributions, not just Gaussians. Finally, we construct an LGS learner for Gaussians, using robust compression schemes and discretization.

This is a nice paper, drawing from distribution learning, robustness, and privacy. I think many people at ALT will find it interesting. The authors did a good job giving an overview of the proof, despite the messiness in the problem parameters. The submission's main weakness is that it's a little hard to identify the new technical ideas.

A few smaller points:
- The introduction jumps quickly between ""agnostic"" and ""robust."" Sometimes I couldn't follow the conclusions from related work, such as ""Therefore, there is no general recipe..."" (p2).
- Related: the paper often talks about agnostic learning as learning under corruption (e.g., p4, ""the corruption level""). Unless it's made more explicit, this view might confuse readers.
- Is there a naive upper bound using exponentially many samples? If so, I think that might be useful context. If it's not obvious, then that itself is interesting!
- Section 5.1 contains the sentence ""The formal proof is given in Section 5.1.""",1
183,"The authors utilize the EfficientViT-SAM backbone combined with dynamic quantization to improve the efficiency of the LiteMedSAM baseline. They replace the 3 duplicate channels used for grayscale images with anisotropic diffusion and histogram equalization to enhance well-pronounced edge features directly in the input image. The authors also pre-process MedSAM's provided training dataset to a fixed resolution of 256 x 256 and encode the binary masks with Run-Length-Encoding to save space on the disk.

The paper is well-written and the methodology is sound and complete. The authors explain everything in enough detail so that is possible to reproduce their results and model training. I only found one small comment: Table 1 should include a reference to each dataset. Other than that, the paper seems to be complete and reproducible. 

Hence, I would opt for an acceptance of the manuscript.",1
184,"This paper proposes a new optimization algorithm for sparse neural network training. The authors provide an intuitive explanation of the algorithm, empirical motivation by examining gradient variance and correlation as a function of sparsity, theoretical justification for their approach, and empirical results on cifar 10, cifar 100, and imagenet. 

I was slightly confused about the complexity of the approach. In algorithm 1, it appears that every m steps, we must calculate g^tilde, which requires traversing the entire dataset to calculate the gradient at the current model weights. If I am understanding the algorithm correctly, this is a pretty computationally intensive requirement. Moreover, this may make this algorithm prohibitively expensive when 1) the dataset size is effectively infinite (i.e. streaming data applications which are common in industry - https://arxiv.org/pdf/1906.00091.pdf); 2) storing and accessing an extra set of gradients is expensive from the point of view of (GPU) memory (i.e. foundation models, large language models, recommendation models https://arxiv.org/pdf/2208.06399.pdf).

On the other hand, the results in section 6 are quite convincing. Since I am not an expert in the space of sparse training algorithms, I will give the authors the benefit of the doubt that their approach is scalable when giving my rating.",1
185,"The authors present an approach to predicting the next most likely disease /outcome for a patient given a previous sequence of outcomes. They focus on using the icd10 ontology. The model is an LLM that is further fine tuned on intermediate predictive tasks such as recalling definitions of codes. The authors trial their approach on open source EHR data and show good performance. The paper is a good contribution to an important area of research.

In general I have two criticism to offer.  My criticism is on the practicality of using approach in the real world. Based on my reading it assumes codes are accurately recorded by the clinician/clinical care team following a given patient episode. In reality clinicians are not very good at recording this level of data. At what stage of the clinical workflow would this 'model' would this be useful?  

Secondly I am not sure how much is lost by discarding the actual clinical text as part of the input data. This approach seems to model the problem as a sequence of codes (or sequence of bag-of-codes). LLMs are designed to interpret free text so why not take advantage of this?

Overall I think the paper presents an interesting and somewhat original solution to the problem. I think the clarity of writing can be improved and ideally some justification for design choices needed to be provided.",1
186,"Reviewer's Comments:

The paper introduces an innovative method for sleep event identification based on multi-modal contrastive learning, which is innovative in the field of sleep medicine. The SleepFM model performs well in retrieval, sleep stage, and apnea classification, contributing to sleep medicine research. Here are some suggestions:

Language: The overall language of the paper is fluent, but there are instances where expressions are not clear. Additionally, there are numerous abbreviations without providing the original full terms. Particularly, for ""SleepFM,"" I am curious about what ""FM"" stands for.

Methodology: The paper describes clear methods, including dataset selection, model architecture, and evaluation metrics. However, more detailed descriptions of the implementation details of the contrastive learning method may be needed for readers to understand the model training process and data processing flow.

Results and Discussion: The Results section provides detailed experimental results, but some explanations for certain results could be more in-depth. For example, why does pairwise contrastive learning perform better in retrieval? The authors could provide more explanations about the internal mechanisms of the model.

Overall, this paper is helpful for research in the field of sleep medicine, but there are still some aspects that can be further improved and refined.",1
187,"The manuscript proposes a retrieval-augmented LLM approach for text-based cardiovascular disease detection. 
Overall, the proposed approach is reasonable. However, there exists a number of unclear aspects that need to be addressed before the manuscript to be published.

**Strengthese**
- cardiovascular disease detection is one of the important risk prediction scenarios for clinical foundation models.
- the proposed retrieval augmentation is a useful technical to enhance foundation models

**Weaknesses**
- Heart disease dataset
  - since it is an author-collected dataset, it is better to mention the size of training and testing set
  - in the real clinical setting, there can exist healthy patients. However, the dataset does not contain the label for the healthy condition.
- Technical part
  - how do the authors implement the re-ranker? Now there is no explanation for that.
  - how to derive ``<RAGHere>`` from ``A``? In the introduction of the case fusion layer, the authors stop after introducing their cross-attention operator. There still exists a gap between the cross-attention and ``<RAGHere>``
  - is there a particular reason to use the same $W_K$ for both $K=W_K A$ and $V=W_K A$?
- Experiment setup
  - what is the RAG model? there is no reference for it. If it is a custom baseline, it would be better to introduce it.
  - ""During training, we randomly mask $m$ cases."" $m$ is first introduced here. This introduction of a new variable without prior explanation can pose challenges for understanding the method effectively.

**Questions**
- Can the authors explain why the retrieved cases are still from the training data? Assuming the foundation model is well-trained, then it does not need 
- what do ``standard values`` refer to (Results section)? Also, there is a typo for ``w/o stanard`` in Tabl 2. Is the ``standard value`` similar to the concept of ``standardization of units`` mentioned in the Heart disease dataset section? I can guess it may refer to the standard value range of a vital, but it is better to explicitly introduce it.",-1
188,"The paper applied LLMs to automate the generation of hospital discharge summaries from physician notes, and evaluated the performance with clinicians from different clinical perspectives. Public benchmark dataset MIMIC-III was used.
- Quality: the paper is technically sound and of high quality. Data processing and filtering criteria, such as only including the first occurrence of duplicate text, is considerable to avoid potential information leakage. 
- Clarity: the paper is well-structured, precise and concise in experiment settings, results interpretation and limitation.
- Originality: the paper illustrated a novel application of existing technologies to a challenging and meaningful clinical task. Though the idea might not be the first, the implementation and thorough evaluation with clinicians make the paper sufficiently novel. 
- Significance: the clinical task of discharge summary is a challenging and important problem to address using advanced ML techniques. Moreover, the evaluation criteria of different types of mistakes in particular with LLM applications could be a good reference for other similar clinical applications using LLMs.

Questions and feedback:
1. How many clinicians reviewed the same discharge summary? If there's more than 1 reviews per summary, how you aggregate the evaluation metrics, especially how to handle conflict opinions.
2. It will be better to compare the current approach with some baselines to further improve the technical soundess, e.g. fine-tune encoder-decoder models from supervised training.",1
189,"This paper investigates the benefits of feature mapping in physics-informed neural networks. The authors show that Fourier-based feature mapping has certain limitations, and conditionally positive definite radial basis functions provide better results for solving partial differential equations using PINNs. Different PDEs are investigated in this work for both forward and inverse problems, and overall results with RBF-based feature mapping are better compared to other methods. However, the motivation behind using feature mapping in PINNs and how it exactly addresses the limitations of PINNs are missing. Addressing this would enhance the credibility of the proposed approach. There are several critical points that require attention to strengthen the paper's contribution and clarity.

1. The error for PINNs and the proposed RBF is similar for even and uneven sampling for nD Poisson equations. What is the justification for using RBF for feature mapping for this problem?
2. MLP on page 2 is not defined.
3. There is no visual comparison of solutions from PINNs in Figs 6-11.
4. The number of RBFs does not seem to have a significant impact on L2 error, and in the case of Burger’s equation, the error seems to increase as the number of RBFs is increased. Is it due to overfitting? Similar observations for the number of polynomials are also noted.
5. In the conclusion, the authors mentioned that this paper introduces a framework. However, the present paper does not discuss how to decide the feature mapping depending on the complexity of the problem. Hence, we cannot call the present study on feature mapping a framework.
6. In the conclusion section, the author mentioned that the RBF feature mapping enhances generalization across forward and inverse problems. However, the paper does not discuss anything about the errors for out-of-distribution data.
7. Detailed experimental settings, specific implementations for each numerical experiment, and hyperparameters are not provided. The code is also not made open-source, making it difficult to reproduce the results.",-1
190,"The paper discusses the development of a medical image segmentation model optimized for deployment on CPU-only devices, such as laptops in light of the ""CVPR 2024: Segment Anything In Medical Images On Laptop"" challenge . This model leverages the EfficientViT-SAM architecture integrated with dynamic quantization to balance accuracy and computational efficiency. It furthermore uses a three-channel enhancement technique for grayscale images - retaining the raw image, applying anisotropic diffusion, and performing histogram equalization. The model was trained on over a million image-mask pairs from ten different medical imaging modalities provided by the organisers and demonstrated improvements in performance metrics, such as a 4.37% increase in dice score and a 2.85% increase in normalized surface dice compared to the baseline model, with faster inference speed for nearly all modalities.


Strengths:

Efficiency and Performance: The model achieves a segmentation accuracy with a reported dice score of 88.54% and a NSD of 98.28% outperfroming the baseline. Remarkably, the use of dynamic quantization not only boosts inference speed by up to five times but also slightly improves or maintained performance.

Innovative Preprocessing: The three-channel enhancement technique for grayscale images improves the model's ability to handle diverse imaging modalities and enhances segmentation accuracy.

Weaknesses:

Ablation Study: An ablation study without the three-channel sampling and with just the dynamic quantization would clarify their individual contributions.

Preprocessing Explanation: The explanation of the three-channel preprocessing is insufficient. While citing a paper in the introduction section, more detail in the methods section would improve reproducibility and understanding, especially since this is a key contribution to the challenge.

Segmentation Ambiguities: The model sometimes struggles with bounding box prompts that contain multiple regions of interest, leading to segmentation inaccuracies. This limitation is acknowledged but not thoroughly addressed in the study.

Metrics: Based on the public validation leaderboard, the reported NSD value of 98.28% appears unusually high. The top-performing method currently achieves an NSD of 89.16%, which is significantly lower than the reported figure.


Reproducibility: 

Although the authors mention that the code will be available at a specified link, it has not been made public yet. Additionally, the method description lacks some details that could be improved for better reproducibility.",1
191,"### Summary

This submission studies the question of learning 1-hidden-layer neural networks, with ReLU activation functions, under Gaussian inputs and noise. In particular, given i.i.d. samples of the form $(x, f(x) + z)$, where $x \sim N(0,I_d)$ and $z \sim N(0,1/\mathrm{poly}(d))$, the goal is to compute in polynomial-time *any* function $\hat{f}$ achieving squared loss better than the trivial mean estimator. They show that even achieving error that is better by an additive $1/\mathrm{poly}(d)$ (called weak learning) is impossible under standard cryptographic assumptions and when promised that the size of the network is polynomial (in particular, the width is at most polynomial in $d$).

### Strengths

This question has received significant attention from the learning theory community over the past few years, yet the question whether polynomial-sized networks can be weakly learned in the setting when the additive per-sample noise is Gaussian had remained open. Previous work implies a similar hardness result in the harsher setting in which the per-sample noise is similarly bounded in magnitude but otherwise adversarial (see footnote 2 in the submission).

The techniques used by the submission are simple but elegant. The hardness reduction starts from the continuous LWE (CLWE) problem and consists of two main steps: First, the submission observes that hardness of learning 1-periodic functions with adversarial (but bounded) per-sample noise follows immediately from CLWE. It then turns the noise into (close to, in total variation distance) Gaussian by simply adding Gaussian noise to each sample, since there are not too many samples, it is possible to take a union bound over all samples. Second, since this holds for any 1-periodic function, you can choose a piece-wise linear one and approximate this by a polynomial-sized ReLU network (by setting the function to 0 for large enough inputs).

The paper is very well-written and easy to follow.


### Weaknesses

The introduction could benefit from a more quantitative discussion of previous work, in particular, what is the dependence of the state-of-the-art algorithms on the width of the network and the weights? This can also come in a later place, e.g., after Theorem 1 and similar to the discussion on the noise rate.

### Typos

The exposition is generally polished, there are several minor typos.

Top of Page 2: that -> than
Second paragraph of Section 2.4: detecting feels like a strange choice of words here
Same place: The spacing after i.i.d. is off
Theorem 5: for solves -> for solving or that solves
After Eq. (4.1): Missing ""to"" after ""we refer""
Subsequent paragraph: Missing parenthesis after ""one can create a sample""
Several places: total variance distance -> total variation distance",1
192,"The work done in the paper is mainly motivated by previous work of Daniely and Shalew-Shwartz showing that, in the multiclass setting, one can design a hypothesis class $\mathcal{H}$ which is PAC learnable, yet no learner for $\mathcal{H}$ can be *proper* (in other words, every learner for $\mathcal{H}$ is forced to output some predictor which is not an element of $\mathcal{H}$). This naturally rises the questions: *Which kind of supervised learning problems can be learned by some proper learners? And by what kinds of proper learners?* The focus of this paper is, in particular, on multiclass PAC learnability. Here, the second question is particularly important, as the seminal result of Brukhim, Carmon, Dinur, Moran and Yehudayoff, demonstrating that every hypothesis class with finite DS dimension is PAC learnable, employs a quite involved learning algorithm, which has very little in common to SRMs and other learning algorithms which are used in practice. 

The main body of the paper can then be divided into two parts. 

The first part of the paper established a positive result regarding the existence of a simple proper learner for **finite** multiclass problems (namely, for classes of hypotheses $\mathcal{H} \subseteq \mathcal{Y}^{\mathcal{X}}$, where both $\mathcal{X}$ and $\mathcal{Y}$ are finite), in the realizable setting and under the assumption that the learner has full knowledge of the probability distribution with respect to which samples are drawn. In particular, the authors show that such a proper learner can be expressed as a *distributional SRM*, a notion introduced in the paper generalizing that of classical SRM. As the authors themselves admit, the techniques used to prove such results are similar to those used in previous work by Darnstädt and Simon, although the goals of the two proofs are substantially different. I should point out that the proof currently given appears quite succinct, and I think that readability of the paper would benefit from a more detailed version: in particular, in view of the discussion of the result given on page 11, I suggest to explicitly point out where and how the distribution-fixed assumption is used, similarly to what is done in the paper by Darnstädt and Simon. This will help to make more evident which are the difficulties to extend the result to the classical setting and to better motivate their conjectures.

Notice that, in particular, the results by Darnstädt and Simon imply that, in the case of finite problems of binary classification (i.e.~hypothesis classes $\mathcal{H} \subseteq \lbrace 0, 1 \rbrace^{\mathcal{X}}$, where $\mathcal{X}$ is finite), knowledge of the distribution over the unlabeled data does not significantly help in the learning task. This same observation has been confirmed as valid in more general binary classification problems in various articles, a rather detailed list of which is provided by the authors. The authors complement their main result with a nice extension of such kind of findings to the multiclass setting. Indeed, they prove that:
- For every $\mathcal{X}, \mathcal{Y}$ and every hypothesis class $\mathcal{H} \subseteq \mathcal{Y}^{\mathcal{X}}$, $\mathcal{H}$ is PAC learnable in the *distribution-fixed model* (i.e.~when the learner is given full knowledge on the sampling distribution over $\mathcal{X}$) if and only if $\mathcal{H}$ is PAC learnable.

- Moreover, the sample complexity in the distribution-fixed model can only shrink up to a logarithmic factor with respect to that in the classical PAC model.

As the assumptions on the hypothesis class and the learning model of their main results are rather restrictive, the authors motivate the quest for milder hypotheses which still guarantee the existence of a proper learner. Indeed, a characterization of **proper** PAC learnability in the multiclass setting is an important theoretical open question (notice that, on the other hand, by the fundamental theorem of statistical learning, proper and improper PAC learnability coincide in the binary setting). The second part of the paper is then devoted to provide a series of negative results, substantiating the hardness of finding such a characterization. Using a simple yet smart reduction to the famous *EMX learning problem*, defined by Ben-David, Hrubes, Moran, Shpilka and Yahudayoff as an example of a learning framework in which learnability may be independent of ZFC, the authors prove that:

- There is a hypothesis class $\mathcal{H}$ (in which both the domain and the label set are uncountable) whose PAC learnability via some proper learner is independent of ZFC. In particular, proper learnability in the multiclass setting is not a *property of finite character*, in contrast with DS dimension (which characterizes *improper* learnability in the multiclass case) and all other known combinatorial dimension characterizing the various notions of learnability used in the literature.

- Proper PAC learnability in the multiclass setting is not a *local* property, namely there are hypothesis classes $\mathcal{H}, \mathcal{H}' \subseteq \mathcal{Y}^{\mathcal{X}}$ such that, for every finite $S \subseteq \mathcal{X}$, the restrictions of $\mathcal{H}$ and $\mathcal{H}'$ to $S$ coincide, yet $\mathcal{H}$ is properly learnable, while $\mathcal{H}'$ is not. 

- Proper PAC learnability in the multiclass setting is not a *monotone* property, namely there are hypothesis classes $\mathcal{H}_0, \mathcal{H}_1, \mathcal{H}_2$ such that $\mathcal{H}_0$ is a proper subclass of $\mathcal{H}_1$, $\mathcal{H}_1$ is a proper subclass of $\mathcal{H}_2$, and yet only $\mathcal{H}_0$ and $\mathcal{H}_2$ are properly learnable.

Notice, however, that a similar reduction (although technically more complicated) to EMX learning has been recently used in the paper *Bandit learnability can be undecidable* by Hanneke and Yang: I think that the authors should include such a reference, as it gives another natural example of a learning framework with problems whose learnability is independent of ZFC. 

In summary, this is a list of what are, in my opinion, the strong and weak aspects of this paper:

**PROS**

- The results of the paper are well-motivated, as well as their position with respect to the state of the art.

- The review of the related work concerning the first part of the paper is adequate.

- Theorem 9 significantly extends to the multiclass setting the refutation of the power of unlabeled data in absence of further assumptions, at least from the worst-case perspective, nicely complementing the state-of-the-art knowledge. 

- Although technically simple, the corollaries obtained by means of the reduction to EMX learning provide strong evidence of the hardness of finding a characterization of proper multiclass PAC learnability, showing clearly that a brand new approach, substantially different to the existing combinatorial dimensions, is needed to tackle this question. 

**CONS**

- Readability and clarity of the proof of the main theorem (Theorem 13) may be improved, as well as the one of the discussion immediately following (on page 11). 

- The applicability of Theorem 13, as it currently is, are quite limited. It would be nice to have some (even partial) extension at least to classes of finite DS dimension, similarly to the one given by Darnstädt, Simon and Szörényi (*Unlabeled Data Does Provably Help*).

- The review of related work related to the second part of the paper can be improved. Besides the missing reference already mentioned, the authors should consider to briefly mention some of the results concerning the *algorithmic* decidability of PAC learning, whose investigation arises precisely as a consequence of the seminal result by Ben-David, Hrubes, Moran, Shpilka and Yahudayoff. Indeed, although not directly related, the line of research mentioned above shares with this paper the motivation of finding **simple** learners, which, in that case, are identified with learning *algorithms* (rather then simply *functions*), in the strict sense of computability theory. A large part of the literature on such problem is briefly reviewed, for example, in the paper *From undecidability of non-triviality and finiteness to undecidability of learnability* by Caro. In particular, the paper *Find a witness or shatter: the landscape of computable PAC learning* by Delle Rose, Kozachinskiy, Rojas and Steifer, solves a problem left open in *On characterizations of learnability with computable learners* by Sterkenburg providing a characterization of those classes which are **properly** PAC learnable via some computable learner by means of a relaxation of the notion of ERM: this example seems to fit the context of the paper particularly well.

- To the best of my knowledge, the novelty of the paper from the technical point of view is quite limited (besides the introduction of distributional SRMs, which, on the other hand, are only really used in the form of Bayesian learners).",1
193,"Summary of contributions: This paper extends the framework of deriving (Bayesian-style) generalization bounds through a reduction to online learning that was first introduced by Lugosi and Neu (2023) to non-iid processes that have sufficiently weak temporal dependency with respect to how the generalization gap is evaluated (see Assumption 1; essentially a weaker version of $\beta$-mixing). To handle temporal dependency, the reduction is now carried out to online learning with $d$-delayed feedback (Proposition 5 and Theorem 6). Corollaries for geometric and algebraic mixing processes and extensions of the FTRL family with incorporated $d$-delay are then presented in Section 4. As outlined in Section 4, there is a natural and expected tradeoff in the choice of $d$: the higher the value of $d$, the lower the error arising from dependency (Assumption 1 and Proposition 5) but the higher the regret bound of the delayed online learning algorithm. In the main application of the bounds to geometric and algebraic mixing processes (Section 4.2), the mixing parameter dictates the choice of $d$. Finally, in Section 5 an extension of the framework to dynamic hypotheses that incorporate memory is presented, building on the works of Erengis et al (2022 and 2024).

Strengths of submission:
- I found the original work of Lugosi and Neu (2023) to be very novel and innovative and consider this to be a nice extension of their framework to non-iid data. Assumption 1 (indeed, even the slightly stronger $\beta$-mixing assumption) is very natural.
- Although the results are largely a careful combination of existing techniques (Assumption 1 directly implies the generalization bound in expectation, i.e. Proposition 5; Lemma 7 uses the classical blocking technique of Yu et al (1994), and the applications to explicit delayed online learning algorithms and mixing processes take the form of corollaries), the framework is simple, elegant and general which I consider to be a positive.
- The paper is overall well-written, well-structured and well-contextualized with related work. As mentioned in Section 6 it is considerably simpler and more general than some related recent approaches to generalization bounds under non-iid data.

Weaknesses of submission:
- I think the statement that Assumption 1 differs/is weaker than the usual $\beta$-mixing assumption is somewhat overblown given that the authors ultimately only present applications of their results to $\beta$-mixing processes in Section 4.2. I could not think of any natural example of a process that does not satisfy $\beta$-mixing but would satisfy Assumption 1. It would be great if the authors could provide such an example, if it exists, or try to think of one, and it would make me even more enthusiastic about this submission if so.
- As mentioned above, given that the results mostly combine existing techniques, I would say that the technical novelty is somewhat limited (I consider this to be a minor weakness, though). 
- While the paper is well written overall, there were a couple of aspects where I thought the presentation could be enhanced. First, while I appreciate the way in which Sections 3.1 and 3.2 are structured such that the reader can make direct comparisons between them, I think Theorem 2 could be expanded to include both the in-expectation and high-probability bound, so that a reader who may not have been familiar with Lugosi and Neu (2023) already could easily compare the in-expectation iid bound with Proposition 5 and Theorem 6 respectively. (I understand this easily follows from text that is already in the paper, but still think this could be presented slightly more cleanly). Second, I think Section 4.2 could benefit from mentioning implications to common examples such as Markov chains and hidden Markov models -- both of these fall under $\beta$-mixing processes but I think it would be helpful for the reader to see them explicitly written out.

Questions for authors:
- This is just out of curiosity, but you mention in Section 6 the concurrent work of Chatterjee and Sethi (2024) that reduces to standard online learning algorithms (without delay) but does need to make strong assumptions about the loss function/online learning algorithm. I was curious about whether you believe there is any scope to make a similar reduction instead making stronger assumptions on the process. I was also curious about whether there are non-mixing, e.g. periodic processes that could be handled given that there do exist results in the literature concerning learning, or concentration without mixing in these cases (albeit for simpler settings/special cases; see https://projecteuclid.org/journals/annals-of-applied-probability/volume-14/issue-2/Optimal-Hoeffding-bounds-for-discrete-reversible-Markov-chains/10.1214/105051604000000170.full and https://proceedings.mlr.press/v75/simchowitz18a.html). 
- Relatedly, one other shortcoming of Corollary 10 and 11 (and its further applications to Corollaries 12 and 13) is that it does require knowledge of the mixing parameters $\tau$ or $r$. I wondered if there is any scope to design online learning algorithms that adapt the delay parameter to data in a ""model selection"" style. This seems like it could be possible using online model selection routines as a black box.

***UPDATE AFTER REBUTTAL***
I am happy with the authors' response and I have slightly increased my score. Please see my follow-up comment for details on suggestions to include in camera-ready version.",1
194,"The paper emphasizes the potential of LLMs in extracting insights from unstructured medical data for survival analysis and risk estimation, proposing a comprehensive approach that incorporates embedding, fine-tuning, and prompting strategies. It also highlights the importance of cross-validation techniques in assessing the generalizability of these methods across different medical institutions.
The graphs seems not well orgnized, could you please double theck the graphs. Besides, the recommendation section seems fragmented, could it be reorganized to summarize it in the conclusion?",1
195,"In the present paper, based on the authors’ claim, an approach based on CNNs accompanied by finite element discretization has been constructed to solve the Darcy flow problem. Besides, a multi-level discretization of the solutions is incorporated into the derived CNN architecture, leading to a more efficient approach in the number of required samples, the training process, and the overall size of the network. Finally, Numerical tests are provided for discretization on fixed locally refined grids.
This paper provides adaptive multilayer neural networks for parametric
PDEs, and may appear to have much interest in the ICLR 2024 Workshop AI4DiffEqtnsInSci readership. 
However, the authors did not mention some critical and intriguing features of the CNN architecture, the number of parameters, and the specific benefits of the proposed method in comparison with existing methods. Moreover, more explanation about Table 1 can help interested readers to understand better the outcome of the method.
In addition, talking about the limitation of the proposed method is not available in the paper.",1
196,"*Summary:* This paper studied the improving multi-armed bandit problem (IMAB), where the reward function for each arm is a concave and increasing function with respect to the number of times the arm has been pulled. The goal of the learner is to maximize the cumulative reward given a total number of rounds. This paper provides the first nearly-tight approximation bound for IMAB with randomized algorithm.

*Strength*

1. This paper provides new $\Omega(\sqrt{k})$ lower bound upper bound for an existing problem IMAB, which is an important contribution to this setting.

2. The proposed algorithm matches the bound with mild assumptions. The authors further show how to remove the assumptions at the cost of an $O(\log k)$ factor. This result is significant and achieves better approximation rate compared to the previous work.

*Weakness*

It would be better if the authors could provide more motivation of the problem studied in this paper. Also, the paper could be more comprehensive if the stochastic-reward setting is discussed.",1
197,"The paper explores the impact of training parameters on latent time-scales within a neural ODE-based surrogate model of the Kuramoto-Sivashinsky equation. It also investigates the significance of the trajectory length and relates it to the largest eigenvalues of the system. 

Pros 
- The paper is well-structured, the plots are well-documented and good to understand. 
- The focus on trajectory lengths makes it easy to follow along. The results show the sensitivity of the accuracy of results to trajectory length. 

Quality: The quality of the paper is good. \
Clarity: The paper is well-structured. \
Originality: good. \
Significance of this work: The results presented are promising. However, to determine the significance and expected generalizability--given the title and abstract--a more elaborate benchmark would be needed. 


Major issues 
- Generalizability: As only one ODE is investigated, the generalizability of results is unclear. 
- One of the main results of the authors is the correlation between training length and the largest eigenvalue of the system dynamics/t_lim. This is also visualized and described in Figure 1c/d. However, it is not clear how exactly they are correlated. For example: t_lim is very similar for decoupled approach with trajectory length 1000, 100 and 200 but higher for 500, i.e. there is neither a clear positive nor negative correlation. An investigation of average t_lim values over time (x-axis) and more training trajectory lengths could help investigate this correlation better. 


Minor issues 
- The paper title might be misleading. The authors only investigate the KS equation. In the abstract (+introduction) the authors specify that the subject of the paper are ""surrogate models for advection-dominated dynamical systems"". Generalizability is unclear. 
- Why did the authors choose n_t= 500 and n_t=4000 for Figure 1g? 
- Is it n_t=7 oder n_t=8 in Figure 2 (right)? 
- Acceleration is not mentioned in the discussion.",1
198,"The level of detail of the methods implemented in this work is excellent. It is relatively straightforward to understand what the authors did. Also, they state very clearly the motivation and the novelty of their study, and it helps to capture the importance of their contribution. I consider that this work is worth accepting it.

Pros:
* The topic of their work (physics-informed machine learning models) is very relevant in the scientific community currently.
* They provide all relevant information of the data, model architecture, baselines, training procedure and objective. The paper is very informative.
* The results reached are quite impressive, specially for the reaction equations, with regards to the tested baselines. 
* With their proposed model they are tackling two weaknesses of the CDF equations, so it is more efficient that all other methods that tackle each weakness separately.

Cons:
* I appreciate that the authors explained the meaning of the equations and most of their parameters. However, since this is a Physics-informed machine learning model, I feel they should have explained also the physical meaning of the tested values of the parameters. In most of the cases they only say which numbers they used, but not actual physical explanation of most of them.
* The bibliography is quite old. There is not any mention of related work from 2023 nor 2024, (the most updated one is only one work from 2022), which makes me think that they are not comparing their method to a more state-of-the-art model.",1
199,"This paper studies the problem of minimizing swap regret over a convex $d$-dimensional action set $\mathcal{K}$. With discretization arguments, the authors prove $\tilde{O}(T^{\frac{d+1}{d+2}})$ swap-regret bound under the full-information feedback assumption. The authors further establish several stronger regret bounds for loss functions with (strong) convex and smooth properties. Then the authors use these regret bounds to develop efficient algorithms for online forecasting problem with $O(T^{1/3})$ $L_{2}$-calibration error. 

Overall this work is on my borderline. 

On the positive side, the authors develop a new method to resolve the online forecasting problem based on minimizing the swap regret. This might provide evidence to apply bandit algorithms to other online calibration problems. The authors also provide complete discussion for smooth, concave, and strong-convex loss functions, where the algebra computations might be useful in related problems.

  On the negative side,  the proposed algorithm is a simple discretized version of classical algorithm for swap regret minimization, which is inefficient in computation.   The final regret bound $\tilde{O}(T^{\frac{d+1}{d+2}})$ is relatively weak. Another minor point is that, it would be better to present Algorithm 1 in the main text for a better reading experience.

Questions:
1. Could the swap regret result be applied to other calibration losses, e.g., $\ell_1$ loss? If not, what is the difficulty and why $\ell_2$ loss is suitable for the application.",1
200,"The paper presents ""SleepFM,"" a multi-modal foundation model for sleep analysis using large-scale polysomnography (PSG) data, including EEG, ECG, and respiratory signals. The model is trained via contrastive learning and demonstrates superior performance in tasks like sleep stage classification and apnea detection compared to traditional CNN methods. The innovative aspect of using a leave-one-out approach in contrastive learning for multi-modal data integration is highlighted, showing significant improvements in model performance.

As author stated in the limitation section, more external datasets are needed to prove the work as a foundation model. Also, it would be great to see the performance of using only one kind of signal as downstream task, e.g. ECG-only for sleep staging.",1
201,"Contributions and Novelty:

This paper provide a unified general framework for analyzing the online learnability of online learning problems. At the core is the introduce of the definition a new combinatorial dimension, named sequence minimax dimension, which is defined with respect to **a specific loss function**. By specifying the loss function and parameter space, the notation reduces to the correct combinatorial dimension for the specic problems, such as Littlestone dimension. 

The unified framework is very interesting, which not only covers existing online learnability notations (providing a unified proof) but also has the potential to motivate new ways of characterizing online learnability for other online learning problems. I checked the proof for proving the reduction to other dimensions, which involves bounding those notations from above and below, seems not obvious and non-trival. 

Weaknesses/questions: 

The authors showed that the proposed dimension notation reduces to existing hardness notations for several problems. While it is nice, it is unclear to me if the new framework can provide any meaningful new results.  

Based on the proof of Lemma 19, it seems that the SMdim and MSdim has a very direct connection. I wonder if the authors could add more discussion on this point. Is the definition of SMdim coming from the observation that MSdim can be written in a more general way?

Presentation: 

This paper is very well-written and easy to follow. I appritate that the authors explain all of the existing ideas is a very clear way. 

Minor comments:

Definition 7 (last line): it seems that $z\sim\mu$ should be $z\sim\mu_t$.",1
202,"Summary
------------------
This paper proposes a hybrid modeling approach that allows learning parameters and parametrizations in Earth system models, with the additional advantage of delivering uncertainty estimates. The approach is showcased in a toy example but seems promising and advancing in the right direction.  Authors consider a hybrid model that contains poorly known physical parameters and a neural network for sub-grid scale parameterization. They approach the joint estimation of physical and ML model parameters with quantified uncertainty, framed as a Bayesian inverse problem. The work, even if in its early stages, shows promise, and if thoroughly advanced, it could have a strong impact on the Earth and climate science community. It goes without saying that the approach, in a similar vein to NeuralGCM, would not only learn parametrizations but scale up from surrogate models like the Lorenz systems to larger-scale, more realistic scenarios.

Evaluation 
------------------

**Quality:**
The paper demonstrates a robust research methodology, technical depth, and experimental rigor. It addresses a significant challenge in weather and climate modeling and proposes a novel framework for joint estimation and uncertainty quantification of physical parameters and machine learning parameterizations. The experiments are well-designed, using appropriate simulations and evaluation metrics, and the results are thoroughly analyzed. Overall, a high-quality piece of work.

**Clarity:**
The paper effectively communicates complex concepts in a clear and understandable manner. The introduction provides necessary background information, and the methodology section is logically organized with illustrative equations and figures. The experimental setup and results are presented in a structured format, making it easy to follow the research workflow and understand the findings.

**Originality:**
The paper demonstrates originality by proposing a novel framework for addressing a pressing challenge in weather and climate modeling. Integrating differentiable programming with Bayesian inference represents a unique approach to enhancing hybrid physics-ML modeling, with potential implications for advancing key problems in Earth system science.

**Significance:**
The paper's findings are highly significant for weather and climate modeling, offering potential improvements in prediction accuracy and reliability. The experimental results demonstrate promising performance over traditional parameterization schemes, highlighting practical implications for environmental science and artificial intelligence in scientific modeling.

Clarifications
------------------
- clarify what you mean by ""The superscript in M n denotes function composition""

- some comments on computational complexity, a bit of ablation study on all parts (integration, HMC, model runs), and some words about future schemes

- comments about calibration of uncertainties would be welcome.

- what are ""Smagorinsky schemes""?

- unlike variational approaches, MC schemes have shown great advantages in dealing with multimodal distributions but are more costly (see Svendsen 2023, https://doi.org/10.1007/s10994-021-05999-4). some discussion about this in the context of learning dynamics?

- when learning params and NN params, which are unevenly distributed and dimensional, some words of caution should be expected, both because I presume the optimization may become quite unstable and also because of the risk of running into identifiability problems, right?

- Why MSE, especially in such a dimensional uneven setting? 

Typos and grammar issues
------------------

- Fix notation around (1); \theta_1 --> \theta_NN (also take the opportunity to harmonize dimensionality notation, e.g. d_phys and d_nn, and eventually give rough numbers of those beyond the d_nn>>d_phys for scientists that are not in the field)

- several typos: ""Hamiltonian Monte Calro (HMC)"", ""which approximate_S_ the gradient"", ""Peter Jan Van Leeuwen,"" double author?, ""maximum a posteriori_(MAP)"", etc. Please give a grammar pass to the text and clean your bib (this is a nice tool, btw: https://flamingtempura.github.io/bibtex-tidy/).",1
203,"This paper proposes TDE-GNNs for learning high order temporal dynamics using GNNs. TDE-GNNs model the temporal dynamics via neural ODEs, with maximal order >= 1 for modeling longer and more complex dependencies.

Pros
1. This paper is well written and easy to follow.
2. Extensive empirical studies on various datasets and comparisons to baselines demonstrate the effectivenss of proposed TDE-GNN.
3. The ablation on order $o$ shows that the performance consistently improve as $o$ increase, which well supports the motivation of TDE-GNN.
4. Implementation details are provided.

Cons
1. It seems that with such discretization in Eq(6), it is hard for TDE-GNN to incorporate advantages from neural ODEs, i.e., getting a continuous solution trajectory can be difficult.",1
204,"The main claim is that a quantization aware training pipeline followed by deployment on OpenVINO significantly enhances inference,
while keeping a sufficient level of accuracy. The authors did quantization aware training for the image encoder, followed by a seperate QAT run for the mask decoder.
They used the Xilinx Brevitas framework and deployed their final quantized model using OpenVINO. Additionally, they decided to sample equally sized subsets of all modalities during each training epoch and adjusted their training code to work on compressed files. Lastly the inference code for 3D images was adjusted to avoid computing the same image embedding multiple times.
The authors demonstrated a significant speed improvement over the baseline.

The paper seems to be accepable, it proposes a QAT pipeline followed by deployment on OpenVINO, the authors demonstrate a signifcant speedup over the baseline.
The authors could be a bit more objective and detailed in the presentation of their results.

## Presentation/Clarity
In section 4.2 I would recommend to refrain from calling the improvement on NSD ""superior performance"" while at the same time calling the decrease of the DSC ""marginal"",
since DSC got significantly more worse (1.88%) than NSD got better (0.54%).
The baseline scores seem to be different than the ones I've seen so far, why is that? Your baseline scores are slightly worse on all modalities except PET, compared to ours. I understand differences in the scores for 3D modalities, since there have been related bugfixes to the baseline during competition, but I don't know why the 2D scores would be different. I would recommend you to link to a specific commit of the baseline code here.
In Section 4.2 you write ""The results highlight a notable acceleration achieved by the quantization method."", your results in table 5 would indicate that the speedup is due to using OpenVINO as a runtime and using an improved inference code for 3D datapoints and not due to quantization.

## Reproducibility
The paper and accompanying code seem to provide sufficient information to reproduce the results. 
The authors provided information about the training environment and protocoll in the paper, they also provide a requirements.txt as well as a README in the GitHub Repository.

## Typo/Grammar
+ Section 3.2 ""Normalized Surface Dice"" => ""Normalized Surface Distance"" 
+ Section 4.1 ""because that""
+ Section 1 ""Notably, ... notably""
+ In Section 1 you mention that MedSAM was trained on 15 modalities, according to the abstract of the MedSAM paper it was 10.",1
205,"Quality and clarity:
- The writing is generally clear and easy to understand

Originality and significance:
- Gatertron Foundational Model trained on clinical data, highly relevant for this workshop

Weaknesses
- Performance ranking makes it more difficult to visualize the actual performance of the model, more fine-grained evaluation metrics would be appreciated, like accuracy for QA, precision and recall for the extraction tasks, etc
- Where are the GatertronGPT evaluation results?",1
206,"Perhaps the more useful contribution of this paper is in leveraging GPT-4 to create synthetic data in niche domains that can be tailored for specific purposes (in this case, benchmarking models that have poor keyword overlap between the document and query).
However, the points regarding shortcoming of keyword based models is already very well known, but also in this case quite expected since the dataset is explicitly constructed to fool keyword matching. It would make more sense to not cast the retrieval model's performance as proof for a move towards embedding-similarity based retrieval (as that has been the case for many years now) but as proof that the dataset is interesting. If that is the intention, it is more beneficial to provide principles and details of the prompt used in the ChatGPT API that enabled the curation of this dataset, so that a practitioner can then apply such principles to their own use case. That would be a simple two page report detailing the challenges and innovations required and the iteration cycles that one may have to go through, along with simple strategies for checking the quality of the generated dataset.",-1
207,"The work ""Benchmarking Common Factors in Psychotheraphy Using AI Systems to Enhance Provider-to-Patient Dynamics to Improve Patient Outcomes"" is a really interesting paper that comprises a kind of a foundation model for neuro-symbolic AI connected with physchotherapy. However, there are several points that need to be clearly addressed before the work can be accepted for publication. To be clear enough, the general reviewer remarks are given in the form of numbered list provided below.

1. The Authors in the section ""Method"" wrote ""(...) We built our initial models using labeled data derived from (...)"". This statement is not really clear. The Authors need to address what was the structure of the data and how much of them were taken into account when it comes to the training/testing dataset. Right now, the overview of the data is missing.
2. In section ""Method"" one can also read that the Authors used methodologies for generation of the synthetic samples. However, once again, the description of the used algorithms and methods is missed. It is unclear what was the approach to generate these samples. The Authors must specify what kind of AI models or methodologies were consumed to generate the synthetic data. On the other hand it is also unclear how much samples were generated in that manner. This information is also needed to appropriately validate the worked-out models.
3. Section ""Preliminary work"" - there is information that Machine Learning models were used to create NLP algorithms. However, once again the details are missing. The Authors have to provide information about the algorithms that were used in their approach. Right now, it is impossible to understand the approach.
4. ""Findings to be Reported"" - one can read information about the levels of accuracy in detection of Appreciation and Toxicity/Confrontation - however, once again there is no sufficient details. How the algorithms were evaluated? What kind of approach was used for this aim? How the database was split and how much samples were consumed. All these questions need to be addressed.

To sum up, I would like to recommend the work for publication but only after major revision that will address all the statements given above.",-1
208,"The authors performed LoRA finetuning on top of Mistral 7B model to do TNM staging classification tasks on breast cancer pathology reports. The authors carefully curated a dataset of anoymized reports with labels from subject matter experts. The results look very promising. Only one foundational model was used in the finetuning and evaluation, so it is unclear whether there could be significant result difference among different foundation models with different sizes. It is also unclear how well the model is generalized, e.g. whether the quality and the format of the original reports may affect the final results,  though the authors mentioned it in the future work section.",1
209,"Summary: The paper is dealing with unsupervised deep metric learning, which aims to learn a metric, such that under this representation, point that are semantically closed together are closed together under the learnt metric space. In the work, the author fits a piece-wise linear embedding model on the data, and then propose the metric should follows several criterion based on this piece-wise linear embedding model. Lastly, the author train a neural network to transform the data, under the transformation, the L2 distance should satisfied the proposed criterion. The author assumes there exists a metric in the raw signal space that behaves locally consistent with the metric we want to learn. This allows us to find a neighborhood such that points in this neighborhood is semantically closed to each other. [I believe the author first use a pretrained neural network to extract feature from each image, then perform unsupervised deep metric learning on these features.] The author also assumes the neighborhood is locally low rank which can be approximated with a linear embedding.

Comments:
My background is in signal processing and unsupervised learning. I am not entirely update to date with the work on deep metric learning. My comments will be based on my summary. If anything is incorrect, please let me know, especially the part the bracket.

I think the proposed method seems to work well as it performs bette than existing benchmark. The resulting clustering from each piecewise linear manifold seems to perform better than other clustering algorithm. But I personally would like to see more qualitative and exploratory analysis than just the benchmark result. For example:
1. If the method is called piecewise-linear manifolds, can I visualize the piecewise-linear manifold structure? If the manifold of natural image is still very high dimensional to visualize, can the author to make a toy example for understanding and sanity check that the model indeed works as epected?
2. I wish I have a better understanding on what $o_{i,j}$ and $p_{i,j}$ is because they seems to be crucial. For my understanding, one is the distance between $x_j$ to $x_i$, the other one is the distance between $x_j$ to the manifold $x_i$ belongs to. Seem like these two distances needs to be balanced for the model to have good performance. But I don't get the intuition. The explanation in 4.4.3 still seem to obscure to me. 
3. Is the local neighborhood indeed low-rank? The author seems to construct the neighbor by expanding if until it cannot be approximated by a linear subspace. I would like to see a more analysis on this. Like how much can you expand the neighborhood and how the eigenvalue of PCA fall off.
4. I think it would be nice if the author can compare their methods with other manifold learning method. The general assumption and goal is that the metric in the signal space works well locally but not globally. This seems to fit ""think globally, fit locally"" manifold learning very well.
5. In fact, I think the model can be consider a manifold learning model.  The definition of the ""Point-Point,"" ""Proxy-Point"" and ""Proxy-Neighborhood"" similarity together defined a similarity kernel, which is being approximated by the trained neural network. Does the author consider of not using the neural network? Since the signal space is already the feature of a pretrained neural network, maybe the similarity kernel can just be just approximated by a linear transformation. In this case, the model is a specific case of laplacian eigenmap. Or maybe the author should do some ablation study to see if a light weighted neural network will do a similar job, as this will fit the premise of the conference ""Parsimony"" better.

Saul, L and Roweis, S. Think globally, fit locally: unsupervised learning of low dimensional manifolds. 
Tenenbaum, J. et al. A global geometric framework for nonlinear dimensionality reduction.",-1
210,"The paper studies the sample complexities of agnostic PAC and transductive learning. These two settings are closely related in the realizable setting where the labels obtained from the data generating distribution, $D$, are consistent with some hypothesis from a function class $H$: optimal predictors for the transductive setting also achieve optimal in-expectation guarantees for the PAC setting, with recent results establishing that these guarantees can be adapted to yield optimal high-probability PAC learners. Hence, the sample complexities of the PAC and transductive settings are equivalent for the realizable setting. On the other hand, the agnostic setting, where the distribution may be arbitrary and the goal is to compete with the best predictor from $H$, is far less clear: 1) It is clear that in terms of in-expectation guarantees, a predictor with $\epsilon$ excess error in the transductive setting implies one with $\epsilon$ excess error in the PAC setting, and 2) however, going in the other direction, the best-known result shows that a predictor with excess error $\epsilon$ can only yield a predictor with polynomially worse (in $1 / \epsilon$) excess error in the transductive setting. This paper aims to address that gap with two contributions: 1) Firstly, they extend recent work which establishes that transductive predictors can yield high-probability PAC predictors with the same error (plus a term dependent on the failure probability) in the realizable setting to the agnostic setting and 2) in the specific setting of binary classification, they precisely characterize the best possible achievable excess error in the transductive setting and show that this implies that the sample complexities of PAC and transductive learning are equivalent for agnostic binary classification.

Technically, the first result follows from a modification of a similar technique used in the realizable setting. The prior approach, when naively adapted in this setting, suffers from a multiplicatively worse dependence on the error of the best hypothesis from the class. In this paper, they show that maintaining a small hold-out set is sufficient to avoid this dependence. The main technical contribution of the paper is the second result: they show that the excess transductive risk is upper bounded by the Rademacher complexity (scaled by $\sqrt{n}$) of the function class. This is a surprising finding and relies on a clever symmetrization argument. It establishes that the optimal transductive and PAC sample complexities essentially coincide for agnostic binary classification.

Overall, the findings of the paper are interesting and non-trivial and suggest exciting directions for future research. Hence, I recommend acceptance. I do have two comments for the authors: 1) It appears that Algorithm 1 requires $\delta$ to be known in advance? Is this strictly necessary since the prior approach does not require this? and 2) There are recent results that show that the sample complexity of agnostic PAC learning may be improved when the error of the best hypothesis is small (https://arxiv.org/pdf/2407.19777). Perhaps the authors could comment on whether such a result is possible for their approach as well?",1
211,"The paper proposes the use of a PINN to model calcium dynamics in (biological neurons). This is motivated by the high computational costs of simulating this using conventional methods which prevents long-term simulations. However, since the proposed PINN has 4 x 50 = 200 parameters, I am quite surprised that this is infeasible to simulate conventionally (also, it's a 1D PDE and it's not clear why/when it is stiff). The numerical results show very good agreement between conventional simulation and PINN, but I again wondering why a (artificial) neural network is needed when high accuracy can be achieved with such a simple neural network.",1
212,"Summary of the paper:
This paper introduces an online gradient-boosting algorithm (Algorithm 1) and regret guarantees (Theorem 1) that do not require prior knowledge of $L$ and $\alpha$. This result is achieved via a chaining tree and is minimax optimal. Section 3.3. extends these results in an adaptive-boosting style. Algorithm 2 is able to adapt to local curvature using a 'sleeping expert' approach. 
Detailed proofs and experiments are provided in the appendix. 


Questions:
(Q1): Theorem 1 guarantees a regret bound of $T^{1-\frac{\alpha}{d}}$ and at the beginning of Section 3.3, it is claimed that the regret is in the order of $T^{\frac{d-1}{d}}$. I can not see how a regret bound of $T^{\frac{d-1}{d}}$ follows from Theorem 1 if $\alpha$ is small compared to $d$. E.g., if $d = 4\alpha$. What am I missing? 

Strengths: 

(S1): mostly clearly written.

(S2): the paper provides a nice insight that parameter-free weak learners imply parameter-free strong learners. 

(S3):  it provides a nice result by combining several existing results (regret bounds on parameter-free online learning) and techniques (chaining trees, sleeping experts). 

(S4): The proofs are clearly written and, to the best of my understanding, correct. 

Weaknesses: 

(W1): It would be helpful to state Theorem 2 and Corollary 1 in a more formal way and state the constants explicitly. Specifically, the 'rough inequalities' are confusing to me. 

(W2):  To the best of my understanding, the results are primarily achieved by an interesting combination of existing results and techniques and not by new technical tools and approaches.
 


I am a bit undecided about this paper. On the one hand, I can see its merits (S1- S4), on the other hand, to the best of my understanding the main contribution is that 'parameter-free' can be preserved through boosting. This result seems to the best of my understanding not too surprising. I am happy to revise my review if I am missing something.


%%%%%%%%%%%%% after rebuttal %%%%%%%%%%%

I thank the authors for their feedback and clarifications. Apologies for the slow reply from my side!

Answer to Answer on (W1): I think the authors should find a way to state Thm. 2 in a more formal way and avoid the 'rough inequalities'. While I can see the motivation for streamlining the discussion, these informal statements are confusing to me. (only a suggestion: maybe state the Thm. wrt a constant C>0 and define C in the appendix?)

Answer to Answer on (W2): I see your point. 

Due to the answers and clarifications, I decided to raise my score.",1
213,"The paper studies a variant of multiclass online learning with two properties: a) only bandit feedback is available to the learner b) the learner is supposed to make only finite number of mistakes but without requiring an uniform bound on mistakes. The authors call this universal learning, after Bousquet et al 2021, although it would be perhaps more appropriate to just call it the non-uniform setting, per analogy to non-uniform PAC learning. There are two related contributions here: a) they show that in non-uniform multiclass online learning, learnability with full feedback already implies learnability with bandit feedback in the realizable case and b) the same holds for agnostic learning, in the sense of sublinear regret. This in turn allows the authors to present new equivalences between combinatorial characterization of a class (ordinal Littlestone dimension) and nonuniform bandit learnability. 

The paper is clearly relevant to ALT community, while the results and contributions are stated clearly. I have some reservations about the significance or novelty of the contribution. While the results seems to be new (in the sense that they were not claimed by anyone before), they are not very surprising and the proofs are simple applications of some existing techniques with very little of new mathematical insights. Especially the part about realizable case seems rather obvious and it feels to me like something on the level of textbook exercise rather than a main contribution of a research paper. If H has does not shatter an infinite Littlestone tree, then the learner has effectively only countably many hypotheses to consider. Then the simplest nonuniform learning algorithm can be used: enumerate this countable set of possible hypotheses and try them one by one. Obviously, for this to work we do not need the full feedback, the information that a given hypothesis is wrong is enough to reject it. This kind of ideas has been around for a long time, probably already in the work of Gold and Putnam.

On the other hand, the presentation of the proofs in the agnostic part could be improved, given that the main idea there is also simple, if Lemma 11 is taken as black-box. I believe that the result claimed for agnostic setting is correct and I see how to prove it but this is mostly because I can reconstruct the idea, somehow despite the way its written. To summarize, the main weaknesses I see are: a) the contribution is small, the results are quite straightforward b) the presentation of some proofs could be improved. At the same time, I would like to encourage the authors to continue working on this setting. In my opinion, the current submission forms a nice start for something that could be expanded to a very good paper.

Some minor comments:
Page 12, Section 4, second par. 'For each J \subset \mathbb{N}, satisfied that |J| is finite' -> For each finite J \subset \mathbb{N}
further in that sentence: what is f^{bf} here? I assume that the authors explain how to define experts starting from some arbitrary f^{bf} but maybe there is something more going on here

Page 12, proof of Lemma 10. How are f and h related? Are they the same learner?",-1
214,"The paper proposes two automatic metrics for evaluating LVLMs hallucination degree in the medical domain.

## Pros
- hallucination evaluation in the medical domain is an important research question. And the authors motivate it well.
- the proposed object hallucination and ""domain knowledge hallucination"" are relevant to the medical domain

## Cons
- The proposed ""domain knowledge hallucination"" indeed only focuses on the diagnosis. Other medical concepts such as procedures, medications, medical conditions are not included. To my understanding, it is more appropriate to use the term ""diagnosis hallucination"".
- The automatic evaluation is great for scaling. Meanwhile, it would be interesting to know whether these model-based metrics are really reliable (i.e. the model-derived evaluations themselves do not contain hallucination). I suggest adding some human evaluation to see (1) whether LLM-based NER is reliable; (2) whether cosine-similarity and threshold are reasonable.
- Only LLaVA-Med is evaluated, which weakens the argument presented.
- Clarification needed:
  - how to combine cosine similarity and the ICD-10-based distance?
  - On the second round inference, would the ground truth diagnosis be leaked to the LVLM in the enhanced prompt? 

## Misc.
- Figure 2 is presented, but never mentioned in the text.

Overall, the proposed metrics are variants of existing metrics, with a focus on the medical domain. 
The clarity can be improved to make the manuscript stronger. Certain human evaluations and LVLM evaluations are needed to thoroughly validate the technical designs.",-1
215,"The author introduces channel-wise l1/l2 group sparsity into the shared convolutional layer parameters (or weights) of multi-task learning models. However, lack of comparative analysis with other relevant sparse multitask learning methods limits its persuasiveness.

Pros:
+ Extensive experiments.

Cons:
+ Some paragraphs present unclear logic, such as: "" .. Therefore, Sparsity aids in achieving parsimony ..."" does not have a clear causal relationship with its preceding context.
+ Lacks comparative analysis with any other methods, such as [1]

[1] Sun T, Shao Y, Li X, et al. Learning sparse sharing architectures for multiple tasks[C]//Proceedings of the AAAI conference on artificial intelligence. 2020, 34(05): 8936-8943.",1
216,"This paper introduces a learning model in which an apprentice aims to learn an optimal strategy having access to an oracle/expert which (perhaps approximately) gives examples of the optimal policy. As a major constraint, the apprentice must be reliable, that is always either follow the recommendation of the expert, or follow an action that is optimal. The goal is to ensure reliability while making as few calls to the expert as possible, knowing that the optimal policy lies in a policy class.

When the oracle is noiseless (always outputs the optimal action for the current state), they show that the optimal query complexity is exactly characterized by the eluder dimension of the policy class. In the presence of noise, they consider two settings: a Massart noise condition (probability gap between optimal action and other actions) and a Tsybakov noise condition. In both noise models, they provide query complexities depending on the eluder dimension of the policy class, and noise parameters. The upper and lower query complexity bounds do not perfectly match but share very similar form (in terms of dependencies in all parameters)


The paper is well written, introduces a clean model for reliable active learning and provides relatively sharp query complexities under the noise model considered (exactly sharp for noiseless). My main comment is that the model does not seem significantly richer/bring significantly novel insights compared to previous models in active/imitation learning both in terms of the results and the analysis. The result in the noiseless case (Thm 3) is almost a tautology: because the apprentice cannot afford to make mistakes, acting on its own only when all potential optimal policies agree is the only reasonable strategy and unsurprisingly gives the optimal (worst-case) query complexity, which is exactly the definition of the eluder dimension. The analysis for the other noise conditions does not seem particularly specific to the apprenticeship model either (although the noise definition needs to be modified for the Tsybakov noise to account for all possible reliable trajectories).


Some specific comments:

- p7 First sentence, ""As the"" -> ""The""?

- p18 proof of Lemma 16. The assupmtion from Definition 10 holds for a fixed value of $\tau$ but in the rest of the proof, it is applied for a value that depends on $A$ which is itself random. There seems to be a mistake here.",1
217,"The authors propose an interesting result in regards to neural ODEs. The authors claim that training and testing of neural ODEs should be performed by the same ODE solver to obtain best results for in and out-of-distribution tasks.

I cannot check the validity of the theoretical proof. In case, the  proof holds perfectly - the paper must be accepted for the workshop. In case there are nuances in the theoretical proof, they must be mentioned in the paper for clarity. Overall the idea of the paper is relevant in the context of the workshop. For authors future work, the following points could be interesting.

In the first place, why would anyone try different ODE solvers for training and testing. Is it not intuitive to use the same ODE solver?
There are several neural ODE based methods, how can the results of the proposed work be generalized?",1
218,"The fundamental theorem of PAC learning states that the learnability of some class H depends on the uniform convergence, in the sense that the empirical mean of a sufficiently large sample estimates the error of every hypothesis $h \in H$. However, this is a general distribution-free notion and works for all adversarial settings. Moreover, this is equivalent to the problem of density estimation and the problem of uniform convergence. Since the result is so general, the sample complexity can often be improved in practice with additional information This paper studied this problem in a restricted adversarial setting.

The paper defines two notions of density estimation: (i) Intermediate Density estimation (IDE) (Definition 2) and (ii) Weak Density Estimation (WDE) (Definition 4). In the problem of IDE, instead of learning all hypotheses in H, the goal is to have the guarantee for a subset $G \subset H $ which is known to the learner. For the problem of WDE, the learner does not need to know G.

The main result of the paper (see Theorem 6, Section 1) shows that the three notions of WDE, PAC learning and IDE are not same akin to the fundamental theorem of PAC learning (see Theorem 1). Instead, PAC learning is sandwiched between WDE and IDE. Additionally, the authors proved that IDE is equivalent to intermediate uniform estimator (Proposition 7) under the assumption of Uniformly Bounded Metric Entropy (see Definition 12, Section 2).    

To prove the second part of Theorem 6 (PAC learning is contained in IDE, Section 4), the authors first show that if a hypothesis class H has bounded metric entropy and has an intermediate density estimator that requires a bounded number of samples, then H has an efficient PAC learner (Proposition 29, Section 4). Additionally, they prove that the converse does not hold. In particular, there exists a concept class that can be PAC learned efficiently, however, no efficient intermediate density estimation of H is possible (Theorem 30). The lower bound follows via Yao's minimax method, and the upper bound follows from the assumption of bounded metric entropy.

To prove the first part of Theorem 6 (WDE is contained in PAC learning, Section 5), similar to the previous case, the authors first prove that if a hypothesis class H is PAC learnable, then it also has a Weak density Estimator (Proposition 34, Section 5).  Additionally, they prove that there exists a class for which efficient WDE exists, which is not PAC learnable (Theorem 35). The upper bound uses approaches from the work of Hopkins et al. (TheoretiCS 24).

Finally, in Section 6, the authors show an equivalence between uniform estimation (Definition 26, Section 3.3) and density estimation when H has bounded metric entropy (Theorem 39, Section 6). In Section 6.2, the authors prove that uniform convergence is strictly contained in Density estimation with bounded metric entropy (Proposition 42) and every class with bounded metric entropy has a weak density estimator (Proposition 43). The authors also present an overview of the technical results in Section 3.

Overall, I like the set of results and believe they are interesting for the ALT community. I support accepting the paper.",1
219,"This paper introduces MedSyn, a new hierarchical diffusion model approach for generating CTs. While this is a valuable contribution, more motivation behind design decisions are needed. For example, why isn't latent diffusion needed? What differs from medical diffusion and why does that lead to better performance? Evaluation on more standard public datasets would also be ideal for this paper for more systematic comparison (Medical Diffusion uses LIDC-IDRI for example).",1
220,"This work talks about using kernels in physics-informed ML setting. The problem setup is interesting as it incorporates IC and BC together with the PDE. However, the reviewer has the following issues:
1. Lack of proper evaluation. It seems like only 0 Dirichlet BC is studied in the paper. The other cases such as non-zero Dirichlet, periodic, Neumann etc. should also be addressed, or at least mentioned.
2. It is not clear why robustness to optimizer is valid here. An intuitive reasoning would strengthen the work. Apart from Fig-A6c, there is no other mention that reviewer could find.",-1
221,"The authors introduced a novel method that parameterizes a high-dimensional parameter of interest ($X$) via a low-dimensional variable ($Z$). Specifically, they propose to use slow-mode projection and GNN for this reparameterization. Then they introduce the Hessian backbone. My comments are below:

- The current manuscript does not flow well. A lot of sections seem disjunct. For example, it should be mentioned in section 1.1 how slow mode projection method compares to GNN. One is linear and the other is nonlinear? Which one should I choose? Why are two of these methods listed here all of a sudden? Then the authors introduced Hessian backbone in section 1.2. I do not see any connection between section 1.1 and 1.2 and I sincerely could not follow from the Hessian section to the end.
- I found the idea of $X=GNN(Z)$ very similar to deep image priors (https://arxiv.org/abs/1711.10925) and their applications on high-dimensional Bayesian inference (e.g. MCMC (https://library.seg.org/doi/10.1190/geo2021-0666.1) or gradient-based optimization (https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2022JB025964)). I suggest authors briefly mention these prior arts in their introduction, and see how their methods compare to those.
- On that note, is the dimension of GNN weights smaller than the dimension of $X$?
- I also found the slow mode projection method introduced in section 1.1 very close to model order reduction and proper orthogonal decomposition.
- In traditional approaches, is $\mathcal{L}$ usually assumed to be expensive while $\mathcal{L}_{\mathrm{CG}}$ is not? Suggest clarification.
- However, for the CG methods introduced in this manuscript (either slow mode projection or GNN), the cost of the coarse-scale and fine-scale simulators (loss functions) are almost the same --- because $\mathcal{L}_{\mathrm{CG}}=\mathcal{L} \circ \rho$. Then, it is hard to justify the benefit of using CG one.",-1
222,"The paper doesn’t fit the scope of the symposium as it is not a foundation model but rather a supervised learned model.
Clarity: The introduction of the paper is written in clear concise language. When explaining the methods of the paper, however, the language is unclear. 
Significance: the work does not appear to be significant within the field of clinical foundation models as it has been trained in what appears to be a supervised manner. 
Quality: the quality of the study is subpar with bad figured and poor explanation of methods. 
Major points 
1.	Figure 1 is basically unreadable; the figure should be bigger.
2.	Figures 3 and 4 are also way too small especially the text. Without a better explanation of time steps they are not very informative.   
3.	The sampling frequency specified, but the idea of a timestep is not. 
4.	The method is not clearly described.
a.	Explain training objective.
b.	Explain network structure.
5.	Present results 
Minor points 
6.	In section 2.1 replace 12 with twelwe.
7.	Remove Average self selected walking speed equation 1 to explanation of equation below. Use m (meters) for meters an s (seconds) for time.
Pros 
•	New data was aquired for this study. 
Cons 
•	The study does not include the creation of a foundation model to solve any task. Instead, a supervised model has been developed for assessing the 
•	RNN-LSTM seems like a somewhat outdated deep learning model architecture to implement as state of the art. 
•	Only 24 subjects were used to train and evaluate a deep learning model, although that is fine for a preliminary study.
•	There are no results presented regarding the performance of the model.
•	It appears that there was no validation dataset, leading me to question how the model was deemed to have trained for long enough.
•	Figures are very bad.",-1
223,"Thank you for this interesting paper which proposes a method for evaluating conversational reasoning, history taking, and diagnostic accuracy for dermatological conditions, using AI to simulate patients in the conversation.

I find it curious that they chose such a vision-centric specialty to evaluate a text-based model, as this is simply not realistic - no doctor would diagnose a skin condition without looking at it! Nevertheless the authors should be commended for going beyond the ‘simple’ MQA approaches of other works as they describe in the background and I think their agent based solution is promising, despite the performance demonstrated here.

Whilst the focus of this paper is on the evaluation framework the following key details are missing:
The test set vignettes are constructed from an unspecified mixture of dermnet and bespoke cases. The proportion of these should be reported, and performance stratified by case origin, as the dermnet cases will have formed part of the training data for GPT3.5/4
MCQs are used for evaluation but there is no detail on how these were constructed. This is important to confirm whether they were part of model training and to gauge how realistic the questions are - e.g. were the other answers blatantly wrong or plausible differentials. It’s for this latter reason that single best answer (SBA) questions are more commonly used in medical exams nowadays. It’s also unusual for MCQs to have only 4 options, which makes me wonder how they were generated!

I appreciate the word limit but to me the most interesting element of this work is the patient conversation agent and there is little detail on how they did this. For example 10 simulations are mentioned, presumably to capture variation in how patients may present histories for the same disease, but no explanation is given of how this variation is modelled - different prompts, temperature settings etc?

The authors include an appropriate benchmark (the whole ‘vignette’) against both multi-turn conversation, single conversation (unclear why this is useful?) and a summarised version of the vignette. Interestingly the the highest performance is observed when prompting the model with the complete case vignette. Whilst the authors suggest this indicates limitations in medical history gathering skills, however without knowing the case mix I think it is more likely that the model is simply remembering the dermnet vignettes from it’s training. I would imagine that then the summarisation, single and multi-turn conversations are then adding progressively increasing noise/corruption of the original vignette and this is what is hurting performance.

The authors include qualitative ‘expert’ evaluation in their methods but do not show any of the results of these, including whether the grader-AI agent reliably evaluated equivalent diagnoses (a central requirement for their evaluation framework).

Despite these critiques and the results shown, I believe this study is an important demonstrator of an agent-based conversational evaluation framework and is worthy of acceptance.",1
224,"This paper proposes two local operations using convolutions with a differential kernel and a local integral kernel that can capture local features of the problem while preserving the grid resolution invariance property of neural operators. The performance of FNO is enhanced by adding differential and integral layers to FNO blocks. The paper is well-written, and the authors provide sufficient empirical evidence for the proposed improvements.
1. Does Proposition 2.1 hold for a non-uniform grid with variable grid spacing? How will the scaling factor change for non-uniform grid? How is the grid spacing determined for the spherical shallow water equation? Is the grid spacing constant for all PDEs investigated in this work?
2. The authors only compare the L2 error for different problems. For the Navier-Stokes equation at high Reynolds numbers, an energy spectra comparison should be added. It would provide insight into how the proposed differential and integral layers capture high-frequency content that is not captured by FNO due to oversmoothing.
3. The authors provide a clear justification for not performing zero-shot super resolution for the Navier-Stokes equation. How important is it to have data at different grid resolutions when training FNO? If FNO is trained on single-resolution data, can it generalize well to different grid resolutions? Or does FNO only generalize well when the training dataset includes different grid resolutions?
4. Do the 5 steps in Fig. 3 correspond to prediction after 5 hours or 5 explicit Euler steps? In the problem description for the spherical shallow water equation, it is noted that 1 hour equals 150 explicit Euler steps.
5. The implementation code is not provided, making it difficult to reproduce the results in this paper.",1
225,"The paper implements Physics-Informed Neural Networks using a JAX framework and show that this implementation is more efficient than Pytorch and Tensorflow for simple problems. The authors support this finding with several experiments. This paper is well written and clear, and there are no notable weaknesses.",1
226,"# Summary

By conducting thorough quantitative and qualitative analyses, the paper effectively highlights the prowess of CRATE models in semantic segmentation, achieved through simple supervised training of classification. The research strongly underscores the merits of White-Box Transformers.

# Strengths

1. **Well-Written**: The paper is structured lucidly, with detailed experimental settings, making it accessible and easy to follow.
2. **Robust Experiments**: This paper undertakes comprehensive quantitative and qualitative evaluations, attesting to CRATE's superiority.
3. **Interesting Findings**: The study underscores the importance of a more interpretable architecture design for the academic community.

# Questions

1. In Figure 6 (left), VIT-B displays optimal performance in the last block, whereas CRATE-B peaks in the penultimate layer. Paper [1] suggests that the penultimate-layer features in ViTs trained with DINO strongly correlate with visual input saliency. Considering both models in Figure 6 are supervised-trained, why do they peak in different layers? Is there a more cogent explanation?
2. CRATE advances semantic segmentation via its white-box design. How does it stack up against other black-box architectural designs, such as PVT [2]? Can black-box designs also enhance the emergence?

# References

[1] Emerging properties in self-supervised vision transformers

[2] Pyramid vision transformer: A versatile backbone for dense prediction without convolutions",1
227,"This uses data driven methods to help with shaping the beam envelopes in the IFMIF-DONES linear accelerator. The authors do this in two steps. They first train a neural operator to predict the beam envelope given the tuning parameters. They then show that this low-cost map between tuning choice and outcome can be used to cost effectively train a control agent to choose tuning parameters given the desired envelope. The authors also show that the neural operator map can also be directly optimized over to produce the desired tuning parameters. Outside of the contribution to the IMFIF-DONES workflow, the paper introduces a novel workflow for reinforcement learning by first training a low-cost model to replace a numerical integrator and then using it to perform the large number of iterations necessary for reinforcement learning. 

My knowledge on the problem domain of nuclear fusion is minimal, but the paper is well written and demonstrates clear success with the implementation proposed. Additionally, the pipeline used to train the model may be useful in other applications where low-cost replacements for numerical integrators may allow reinforcement learning techniques to be more easily applied. My only hesitation is my lack of familiarity with the challenge and scope of the physical system being studied or existing best practices in the field.

Minor Comments:
1)	In section 2 you reference figure 6 where I think you intend to reference figure 1.
2)	In the second paragraph of section 3.3 “both constant an variable” should be “both constant and variable”
3)	As someone outside of the field, understanding the structure of the data being explored is a bit of a challenge. It may be helpful to provide additional visualizations of the range of envelopes in the appendix. 
4)	There is no baseline method provided, it would be helpful to discuss how the tuning parameters are selected in the current state-of-the-art.",1
228,"The paper proposes an efficient AL framework based on off-the-shelf self-supervised learning models, and a label-irrelevant patch augmentation scheme is introduced to reduce redundancy in the learned features and mitigate overfitting in the progress of Active Learning. Some key positives and weaknesses are listed as:

Strength:
1. Their formulation of a label-irrelevant patch augmentation scheme that preserves semantic information is interesting.
2. The proposed parameter-efficient AL framework can boost the overall performance of Few-shot AL by 5% − 7%.
3. The paper is very well written and it includes many interesting ablation studies + experimental details (eg. aug analysis in the appendix).

Weakness:
1. I am concerned about the expense of training an adapter on top of a pre-trained and fixed ViT in every AL round. In what way, this additional training cost can compensate for the performance gain?
2. Performance benefits of the proposed approach seem very marginal and sometimes less than RandAug. Can authors provide some explanation?
3. Additional results on non-medical images on conventional CV datasets can provide more evidence of benefits. I am not sure why authors limited their evaluation to medical images. Some widely popular medical datasets like ChestX-rays etc. are missing.",-1
229,"This paper considers the setting of learning in the presence of strategic agents who are in charge of labelling datapoints, while making using of ""advice"" in the form of a given fixed hypothesis. The layout of interests are as follows: each agent wants the final hypothesis to produce the smallest loss on its own subpopulation, while the designer would like to minimize loss on the total population. For the task of learning constant functions against absolute loss, the work provides an algorithm that trades off consistency (following advice when it is good) and robustness (being within a certain factor of optimal); at the extreme matching Dekel et al. The algorithmic idea does not defy expectations, i.e., interpolate these considerations when selecting the final hypothesis; but since the obtained trade-off is tight the result itself is interesting. Another main result is that in the 0/1 classification setting (if agents share datapoints), advice to the learner can't be used to mediate robustness-consistency tradeoffs any better than ignoring the advice altogether.

I found the mathematical parts to be cleanly written and linearly readable. This is a positive.

One worry I have is that (only) for upper bounds given the definition of consistency, we might not be asking enough from the algorithm. For example a natural notion would be $Cost(\mathcal{A}) \leq \min\\{\alpha Cost(\widetilde{f}), \beta Cost(f^*)\\}$. Here, the consistency bounds would come into play even if the advice is imperfect, but good. The current definition on page 5 implies consistency is only up for consideration when the advice is exactly correct. 

Comments on writing:
I should note that I had to read Dekel et al to understand why this particular arrangements of interest is well motivated, and the incentive-compatible ML literature has evolved quite a bit in the past 10 years to settings involving stronger conflicts of interests. In any case, I hope that the authors can include a paragraph (e.g., mirroring examples in Dekel et al) to motivate the setting. Similarly, briefly defining consistency and robustness in words before the theorem statement on page 2 would help, although this I feel less strongly about, because these definitions (almost; see above) match what an uninitiated reader (like me!) would imagine them to be.

The other bit that would help in making a stronger case for this paper is to expose tools and directions that the follow-up works could build on independently of the end results. For example, is there a ""core"" that although central to the lower bound construction when assumed away could result in nice algorithms?

Finally, I'm divided between assigning a 6 or a 7; so I'm open to persuasion both by the authors and by what the other reviewers have to say.

Edits: fixed typos.

---
I think post rebuttal I would like to maintain my evaluation. The authors did not present any evidence to assuage my concern that the consistency requirements imposed on the learner are very weak (only come into effect when the advice is near? perfect); I see that another reviewer shares this concern. Neither did the authors expose a reasonable way forward in the classification setting, using insights gathered from their lower bounds. So I'm still between a 6 and a 7, leaning 6.",1
230,"This paper proposes a meta-learning approach for learning parametrised PDEs, wherein the PDE is hardly encoded, as opposed to soft-constraint approaches where it is used in the loss. The proposed methodology allows for quicker adaptation to unseen contexts. 

How do you compute $g_{p}$, i.e. the incomplete PDE part?

Also, references are missing for the CODA and CAVIA methods.",1
231,"This is an interesting demonstration of an application of foundation language models cost-effectively fine-tuned to a clinical task and performing impressively, especially compared to language models without fine-tuning.

However, it is hard to follow for someone like myself with machine learning but not medical expertise. For instance, I don't know what TNM or triple-negative mean, and my lack of familiarity with medical reports make the problem and the description of data preparation, which are important to understand the implications of the results, hard to understand. In the results, it is unclear what the difference is between the sample count indicated in the model column vs the samples column. If the former is the number of samples used for training, then the claim that low sample count is sufficient for training seems unsupported, as the accuracy is substantially higher with greater sample count. Also, if possible, it would be helpful if the results included some model trained only on the cancer data so we can tell how much is gained by starting with a foundation model. Further, what are the practical implications of these results? What would be the impact of deploying this model in particular?

A small discussion of prior work in fine-tuning foundation models for clinical tasks and the gap that this work fills could help contextualize this work and understand its contribution. Much of the last page is speculative, which is, I think, less valuable than further supporting the experimental study - the main contribution of this paper - with more details as mentioned above.",-1
232,"Quality: The quality of this work is satisfactory.

Clarity: Very well-written and easy to follow regarding their aim.

Originality: This framework is somewhat novel, although not entirely unprecedented.

Significance: The findings of this work are promising for one case, but I am uncertain about the effectiveness of your method for canonical PDE problems",1
233,"The authors proposed an innovative approach to enhance the subitizing generalization of Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). They considered adapting Holographic Reduced Representations (HRRs) to develop an alternative loss function that improves the subitizing capabilities of these neural networks.

I found the integration of HRRs into deep learning loss functions to be novel, bridging the gap between cognitive science and neural network research. The paper also demonstrates that the proposed HRR loss improves generalization in subitizing tasks, particularly for CNNs. The experiment section is extensive, and the saliency map analyses provide empirical support for the effectiveness of the approach. The experiment section also includes a discussion of the comparison between CNNs and ViTs under various conditions, which provides a comprehensive understanding of the models' capabilities. While the authors have clearly mentioned that the HRR loss shows improvement, it does not completely solve the problem of subitizing generalization. Nevertheless, the authors' discussion of the approach's capacity in offering valuable insights and directions for future research in combining symbolic and neural approaches is fair.

The experiments are conducted on a specialized dataset (Numerosity database), which may limit the generalizability of the findings to other datasets or real-world scenarios. I suggest that the authors, as their next step, consider incorporating more benchmarks and datasets to improve the formulation of the approach's generalization.

In summary, the paper presents a significant contribution to the field by introducing a neuro-symbolic approach to enhance the generalization ability of neural networks in cognitive tasks, and I believe it is qualified to be accepted and presented at the NuCLeaR workshop.",1
234,"### Summary
This work studies the relation between the (fastest/slowest) time-scales of a dynamical system and the time scales of an autoencoder-based neural ODE surrogate in its latent space. The authors show empirically for the Kuramoto-Sivashinsky equation that the autoencoder architecture (number of layers and latent dimension) does not impact significantly the time scales of the latent space, while the length of the training trajectories significantly correlates with the slowest/fastest time.

### Comments
* The subject is interesting and well suited to the workshop.
* The goal of the paper is clearly presented and well introduced, although a bit verbose.
* The results are interesting but very limited and mainly empirical. In particular a single dynamical system is used for the experiments. It is hard to know if the results carry for other systems. The architecture (and training) of the neural ODE could also have an impact, which is not considered.",-1
235,"## Summary

The paper studies the Improving Multi-Armed Bandits Problem where there are $k$ arms, and each arm's reward is a function of how many times it has been pulled. The authors study this problem when the reward of every arm is increasing and concave in the number of times it has been pulled.

The first result of the paper is that no randomized algorithm can get a competitive ratio better than $\sqrt k /3$. The next result is an algorithm that, given some (approximate) information about the optimal arm, achieves competitive ratio $O(\sqrt k)$. The final main result is another algorithm that runs without the aforementioned information and achieves competitive ratio $O(\sqrt k \log k)$. All of these guarantees are in expectation.


## Class with previous work

The authors claim that Patil et al. (2023) have $\Theta(k)$ upper and lower bounds for the competitive ratio of deterministic algorithms. However, looking at Patil et al. (2023), specifically the proof of Theorem 2 in Appendix C.1 in page 16 (in the arxiv version at least), they seem to be claiming that their $\Omega(k)$ lower bound holds even for randomized algorithms. As far as I can tell, both from skimming the proof of Patil et al. (2023) and the proofs of this paper, Patil et al. (2023) are either wrong or they are considering an adaptive adversary that can respond to the algorithm's actions (which is quite unrealistic). I don't know if the authors of this paper were aware of this technicality (I think they might have been because their lower bound proof is very similar to the one in Patil et al. (2023)), but I'd like to see some discussion about this in the rebuttal.


## Pros

Aside from the above problem, I like the paper. The results are natural since they study the IMAB problem when the algorithms are randomized, which is usually the approach in online algorithms, and especially MAB where Randomization is necessary in some cases to achieve non-trivial bounds. The algorithms are simple and concise and the proofs are simple to understand but not trivial. I found the idea of the $V()$ function quite smart.


## Cons

I was a little puzzled by the final form of Theorem 8. In the last part of the section, the authors change the definition of $m$ so that it holds $m = \Theta(f^*(T-k))$ and $m \le f^*(T-k)$. While this feels similar to the original definition if $k$ is a constant wrt $T$, if $k$ is proportional to $T$, this might lead to quite a big disparity.
Finally, while the authors always made sure to include text that explains both the statements and the proof, in Theorem 8, there is no such text whatsoever. Maybe some explanation for the change in $m$ would have helped with my previous comment.


## Summary

Overall, I liked the paper. I am in favor of accepting, bar the class with previous work which I would like to see discussed in the rebuttal.


## Minor Suggestions

I have the following minor suggestions to the authors:
* The way $m$ is defined initially is confusing. Initially (at the start of Section 4) the authors define $m = \Theta(f^*(T))$ but eventually they require that $m \le f^*(T)$. While this is a small disparity in the text, I think it should have been specified.
* Claim 5: I would suggest rewording to emphasize that the reward comes from that arm: e.g., ""the algorithm receives total reward *from that arm* at least...""
* I found the calculations of the minimum in equation (4) a bit tedious. It would have been better if the authors mentioned that it is a second-degree polynomial and that its minimum is attained at point X with value Y.
* The authors seem to be using repeatedly a property of the reward functions (the one mentioned after Equation (12)). If I am right and this property is being used multiple times, it might be useful to make that a claim.",1
236,"This work lays the groundwork for the creation of a Foundation Model (FD) on the domain of Chest X-Ray (CXR) images. It proposes a set of datasets (CheXinstruct) containing 5 task categories related to CXR, a FD trained on these datasets (CheXagent) and an evaluation benchmark (CheXbench), in which the model achieves outstanding results. This work is well presented, clearly expressed and is especially relevant with regards to the topic of Foundational Models for medicine. Although it builds on the contributions of many other works (which is properly cited in the text), it is an important contribution nonetheless and will allow further research and advances in the topic. For these reasons, I consider to accept this paper for the symposium.

I would like to include some comments for further clarification or correction of the work.

- When listing the tasks in the construction of the dataset, some tasks might not be familiar for all readers and a short description would be beneficial, e.g., view classification.
- In the model section, “To infuse the model […], we utilize **five** distinct text sources for training”, but then only three are mentioned. Either a clarification or a correction is needed here.
- For training stage 2, training a vision-language bridger, a reference is needed to clarify how this process takes place.
- Regarding the evaluation table, no confidence intervals are given, which makes it harder to compare between models with similar metrics, particularly for single- and multi- disease identification.
- No results are given for any other method in the Findings Summarization task; if it is in the author’s power to do so, it would be beneficial to have results for these methods.
- Regarding the outstanding results in terms of View Classification, a comment on the reasons for this dramatic increase are missing.",1
237,"## Summary:
The paper introduces HRBP, a block-wise pruning method for CNNs. HRBP maintains block-wise sparsity in both the forward and backward passes of CNN training, leading to improved efficiency.

## Strengths:

The idea of preserving block-wise sparsity in the backward pass is well-motivated.
Empirical results consistently demonstrate HRBP's performance improvements in static and dynamic training.

## Weaknesses & questions from the reviewer:

- To me, the technical exposition in the paper is quite challenging to follow. To clarify the core idea of HRBP, would it be possible to include a simple walk-through example, such as applying HRBP to a 1D convolution? This would demonstrate how HRBP maintains sparsity in both forward and backward passes in circulant matrices.

-  In comparison to traditional block-pruning methods like [21], HRBP preserves sparsity in the backward pass. This is expected to enhance gradient computation efficiency, resulting in shorter run times. However, the experimental results also indicate that HRBP improves training accuracy compared to baseline methods. It would be insightful if the authors could provide some intuition behind this observation.",1
238,"The paper introduces Integral Physics-Informed Neural Networks (IPINNs) as an innovative approach to overcoming the limitations of traditional Physics-Informed Neural Networks (PINNs) in handling shock discontinuities in weak solutions of hyperbolic partial differential equations (PDEs). The novelty of IPINNs lies in their training methodology, which is based on the integral form of conservation laws. This method is advantageous because it remains valid across both continuous and discontinuous solution points, thereby facilitating more accurate modeling of shocks in hyperbolic conservation law systems. 
The critique centers on the perceived lack of novelty in the proposed Integral Physics-Informed Neural Networks (IPINNs), noting their similarity to previous methods developed by authors Patel and Jagtap. To constructively address this concern, it is crucial to highlight any distinct features, improvements, or specific applications of IPINNs that differentiate them from the earlier approaches. This includes detailing any methodological enhancements, computational efficiencies, or broader applicability to a range of hyperbolic PDEs. Direct comparison in terms of performance metrics, accuracy in shock capturing, and computational resources required could further elucidate the advancements IPINNs offer over the previous methods. Without clear differentiation or demonstrated superiority, the contribution of the paper to the field may indeed appear limited.",1
239,"The paper introduces PINA (Physics Informed Neural network for Advanced modeling) which is a PyTorch-based open-source package for solving PDEs and operator learning via neural networks. As argued in the paper, the main advantage of PINA compared to existing packages is that it streamlines the training process by adding interfaces for logging or developing new loss functions. 

I would like to congratulate the authors for their efforts in building an open-source package. However, in my professional opinion, the technical contributions of this work are marginal. Specifically, while having a streamlined pipeline is useful, the already available libraries make it very easy to implement any of the models that the authors have exemplified in Sec. 4. The performance of this package (and many of its claimed benefits) are also not compared to existing open-source packages so it is difficult to evaluate the authors’ claims.",-1
240,"The paper presents the first benchmarking study of three different Genomic Foundation Models in predicting gene pathogenicity. The interpretive capacity of each model is significantly affected by factors such as preliminary training, context length, and resolution. Conventional approaches have limitations in enhancing model interpretation and heavily rely on specific features. The study underscores the potential of Foundation Models to address the complex challenges associated with genomic data analysis.

Quality and clarity:
- The quality is clear, and the tables and figures are generally understandable. Small notes: Figure one axis should either be made larger or removed, Tables could have standard errors
- The paper is generally well-written and free of grammatical errors
 
Originality and significance:
- Nucleotide Transformer exhibits better generalizability and accuracy performance compared to other models.
- The excellent performance of Nucleotide Transformer can be attributed to its extensive pretraining on over 3200 diverse human genomes, which sets it apart from other models on various genome benchmark datasets.
- Nucleotide Transformer solely utilizes genomic sequences for gene pathogenicity prediction, whereas other approaches rely on different features.

Weaknesses
- Limited Explanation of Embeddings, as they fail to properly distinguish between pathogenic and benign variants. How can this be addressed?
- Lack of Comparison with Non-LLM Models: The study primarily focuses on comparing different Genomic Foundation Models and LLMs. However, a comprehensive evaluation should also include comparisons with non-LLM-based approaches to assess the relative advantages and disadvantages of using LLMs for gene pathogenicity prediction.
- Computational limitations could be addressed by LORA or other efficient NLP techniques",1
241,"The manuscript introduces ExpertsMedSAM, a novel framework employing the Mixture-of-Experts methodology to augment the segmentation efficacy of fundus images. The primary expert, based on the original baseline decoder, is supplemented by a secondary expert. Notably, the encoder and the initial expert's parameters remain fixed, while the secondary expert is trained on fresh data.

The experimental outcomes demonstrate the efficacy of this straightforward technique, showcasing improved performance in fundus image segmentation. Nonetheless, the observed enhancement in fundus image processing appears to come at the cost of diminished performance in other modalities, a common challenge in multimodal training paradigms. Consequently, the singular focus on designing an expert solely for fundus images is insufficient. It remains uncertain whether this approach is equally beneficial for other modalities. To address this gap, it is imperative to develop additional experts tailored to diverse modalities and conduct comprehensive validation experiments.

In addition, some key details are not fully described. 
1) In the training phase, what are the weights of the basic outputs and the weights of the new outputs in the fusion method proposed by the author? Does this weight change with the increase of training epoch?
2) Apart from the four new fundus image datasets introduced by the author, did the new training involve any other data originally provided by the competition?
3) ""only made small changes on this basis to improve the model’s performance in some areas where LitedMedSAM performed poorly."" Please describe specifically which areas, and which other areas may be affected resulting in degradation.
4) ""Due to the addition of an additional Decoder, the inference time increases."" Please provide specific statistics on inference time, how much did it increase compared to the baseline?
5) ""The loss function is the unweighted sum between dice loss and cross-entropy loss, which has been proven to be robust in various segmentation tasks."" However, in Table 3. (training protocols) the author claims to use the additional MSE loss function. Please correct these two contradictory statements.",1
242,"Strengths:

1. Authors propose a novel concept of reasoning with deictic prompting that is very relevant for reasoning-based image segmentation, a known drawback of captioning models. 
2. Embedding based unification allows for use of individual entity information.
3. The result indicates that the technique works.

Weakness:
1. Lack of comparison with existing datasets.

Formatting:
1. Some of the appendix details (eg. deictic prompt sample) should be moved to the main paper.

Questions:
1. Did the authors try to directly rewrite the query using an LLM to extract the relevant components from natural language intent (eg. InstructBLIP, LLaVaInstruct)",1
243,"In this work the authors bundle a pre-training dataset consisting of several open source cohorts, a vision-language model trained on said dataset, and a suite of benchmarking tasks to compare performance of foundation models in the space of chest X-rays interpretation.

The work is impressive and might have benefited from a longer write-up as with the 2 page constraint it is challenging to thoroughly describe all aspects of the work. I would have liked to see a less succinct explanation of the model and the datasets, in particular how the splitting between training and testing was done. Additionally, a section regarding limitations of the current work and ways into clinical application would have been appreciated.",1
244,"#Summary

This paper studies the generalization error of statistical learning algorithms in a non i.i.d. setting, where the training data is sampled from a stationary mixing process. Specifically, the authors propose a novel analytic framework, which formulates an online generalization game with delayed feedback and can achieve a reduction from the regret of online learning with delayed feedback into the generalization error bound. Based on this framework, two concrete examples of mixing processes (i.e., the geometric mixing and the algebraically mixing) are considered, yielding the corresponding generalization error bounds. Moreover, the authors also extend their framework into the case that loss functions rely not only on the last data, but on all historical data.

#Strength
1) The non i.i.d setting studied in this paper may be more practical than the classical i.i.d setting. Although this paper is not the first to investigate the generalization error in the non i.i.d setting, the assumption made in this paper seems to be weaker than that in previous studies.
2) The analytic framework is proposed by establishing the connection between the regret of online learning with delayed feedback and the generalization error, which is new and interesting (at least for me).
3) Based on the analytic framework, the authors have recovered near-optimal rates in a number of well-studied settings by tuning the delay appropriately.

#Weakness or Questions
1) It seems that the main results of the analytic framework (i.e., Proposition 5 and Theorem 6) can be simply proved by combining the Theorem 1 in Lugosi and Neu (2023) with Assumption 1 in this paper.
2) According to the online generalization game with delayed feedback formulated in this paper, the learner needs to know the cost function $c_t$, which depends on the distribution $\mu$ of the data point $Z_t$. However, it seems that this information maybe unknown in practice, which has also been partially discussed in page 3 of this paper.
3) It is a bit confusing why the same (even better) rate can be achieved in the non i.i.d. setting, because it seems that this setting should be more challenging than the i.i.d setting.
4) For online learning with delayed feedback, the authors follow the framework in Weinberger and Ordentlich (2002), which actually is known to be inefficient in the sense that $d$ instances of a non-delayed online algorithm are maintained. According to the most recent studies on online learning with delayed feedback, I suggest that the authors may develop a specific variant of EWA and FTRL for handling delayed feedback. For example, one possible attempt is to replace $\sum_{s=1}^t c_s$ in FTRL with $\sum_{s=1}^{t-d} c_s$. Moreover, a more detailed literature review on delayed online learning maybe helpful.",1
245,"## Summary
This manuscript explores the application of traditional machine learning models (Random Forest, Logistic Regression, and kNN) to the prediction of Chronic Kidney Disease (CKD) on the MIMIC-IV dataset using CKD-related ICD codes as labels and non-CKD-related ICD codes and demographic variables as features.  This is an important healthcare problem and establishes a baseline on MIMIC-IV dataset.  In general, the methodology for data sampling, splits, evaluation metrics are well done.  This manuscript would be stronger with the inclusion of more advanced models such as gradient boosted trees which often achieve stronger performance in many healthcare prediction tasks with tabular data. 

 The authors are somewhat vague in the real-world application of this model--Is the goal to create a clinical decision support/forecasting model while the patient is still in the hospital? Is the goal to create a model that can detect if we forgot to mark the presence of CKD in an encounter for billing after the ICU stay?  This is not clearly stated and these are different questions that require different modeling approaches. The design of the presented models are mainly useful for the second line of questioning.  However, in an ICU population where creatinine and eGFR values are very frequently measured, why not compute a clinical baseline using traditional diagnostic definitions for comparison? This is currently absent from the manuscript and inclusion would make the research much stronger. More on this below.

## Pros
* Important healthcare problem. Research establishes baseline for CKD prediction task from ICD + demographic data on MIMIC-IV dataset.
* Well designed experiments, train/test split
* Large sample size & statistically robust
* Good choice of evaluation metrics (AUROC, AUPRC) and threshold selection rationale with MCC

## Cons
* I consider Random Forest to be a simple model. The findings would be more interesting if a more advanced model such as Gradient Boosted Trees was also compared, especially since Gradient Boosted Trees often achieve state-of-the-art performance on many healthcare prediction tasks using tabular features.
* Poor word choice in second paragraph of ""Predicting Undiagnosed CKD Patients"" section.  The authors write ""The lower sensitivity is a benefit in this case..."", but lower sensitivity is never a benefit because we always desire higher sensitivity and specificity.  I think the authors mean that it is an optimal trade-off.
* This analysis pools all CKD classes together rather than predicting individual CKD I, II, etc.  It would be more interesting/valuable if authors designed experiments to predict individual CKD classes in addition to predicting presence/absence of CKD.  This is because management and healthcare cost of CKD I/II patient (often no dialysis, medication management) is very different than CKD IV/V (patients usually more ill, more comorbidities, and/or require dialysis).  The utility of this prediction model would be significantly improved if models were able to predict CKD classes.
* MIMIC IV dataset is derived from real electronic health records of ICU patients where there is a temporal nature to the data. Some diagnoses & ICD codes may be present in certain days/encounters earlier than others. The authors' methods indicate that ICD codes extracted correspond to all ICD codes for a given stay--that is at time of discharge. Choosing this time point limits the utility of this predictive model as many diagnoses (ICD codes) will be accumulated during the ICU stay and may not be present on admission.  The value of this model thus becomes post-encounter detection (e.g. CKD billing code is missing), not for prospective clinical decision support. A more clinically useful time point for prediction for diagnostic/clinical decision support would be earlier in the hospital stay (e.g. day 1 or day 2 of admission).  The target use case of the proposed model should be more clearly stated; currently it is vague. The chosen use case for this model would then inform different choices for data selection and model development.
- Since the study population are ICU patients, I expect almost all to have multiple creatinine value or eGFR determined in their laboratory studies. The creatinine and eGFR values are how CKD is diagnosed using diagnostic criteria such as KDIGO.  The authors tangentially acknowledge these traditional diagnostic criteria in ""Previous Work and Study Scope"" section, but do not actually compute these values as a clinical baseline.  The proposed line of research would be much stronger and clinically useful if authors determined CKD from traditional diagnostic criteria (which is still widely used in clinical medicine) as a baseline for comparison, or used the computed values as ground truth instead of ICD codes. This should be possible for most patients in the MIMIC dataset because of the high availability of creatinine and eGFR data in ICU patients. Currently authors compare against presence of ICD codes that are related to CKD, but this ground truth may be inaccurate given that ICD codes are primarily used for billing purposes.  In theory ICD codes should reflect the patient's clinical reality but in reality it may not necessarily be reflective since it requires billing staff or healthcare staff to denote the presence of the diagnosis in the patient's EHR. Thus relying on ICD codes as ground truth may actually lead to your model to under-diagnose CKD.",1
246,"Quality and clarity:
- The writing is generally clear and easy to understand
- Methods seem to be clear and well-described for reproducibility

Originality and significance:
- Physician-guided LLM prompting seems original and highly relevant for this workshop
- Prompt examples in the appendix are quite interesting, as well as the performance breakdown per discharge summary field

Weaknesses:
- Figure 1: There is a black box around the cartoon doctor, please remove
- It would be interesting to see what the standard deviation would be under multiple generations of the same discharge summary, as the performance of chatgpt may change over time, but I understand the expensive nature of human-labeling
- 53 summaries were evaluated by 11 clinicians seems small. Also, do clinicians agree with each other in their analysis?",1
247,"The paper doesn’t fit the scope of the symposium as it is not a foundation model but rather a supervised learned model.
Clarity: The introduction of the paper is written in clear concise language. When explaining the methods of the paper, however, the language is unclear. 
Significance: the work does not appear to be significant within the field of clinical foundation models as it has been trained in what appears to be a supervised manner. 
Quality: the quality of the study is subpar with bad figured and poor explanation of methods. 
Major points 
1.	Figure 1 is basically unreadable; the figure should be bigger.
2.	Figures 3 and 4 are also way too small especially the text. Without a better explanation of time steps they are not very informative.   
3.	The sampling frequency specified, but the idea of a timestep is not. 
4.	The method is not clearly described.
a.	Explain training objective.
b.	Explain network structure.
5.	Present results 
Minor points 
6.	In section 2.1 replace 12 with twelwe.
7.	Remove Average self selected walking speed equation 1 to explanation of equation below. Use m (meters) for meters an s (seconds) for time.
Pros 
•	New data was aquired for this study. 
Cons 
•	The study does not include the creation of a foundation model to solve any task. Instead, a supervised model has been developed for assessing the 
•	RNN-LSTM seems like a somewhat outdated deep learning model architecture to implement as state of the art. 
•	Only 24 subjects were used to train and evaluate a deep learning model, although that is fine for a preliminary study.
•	There are no results presented regarding the performance of the model.
•	It appears that there was no validation dataset, leading me to question how the model was deemed to have trained for long enough.
•	Figures are very bad.",-1
248,"### Summary
This paper proposes a new evaluation strategy for models specialized in mathematical reasoning. Rather than simply evaluating the accuracy of these models when solving these tasks, the authors propose to complementarily test their ability to identify similar problems. The rationale behind this is that a true understanding of a mathematical problem implies the construction of a proper abstract model for it, which should come with the ability to evaluate similarities between these constructed models. To test this, the authors use NLP4PLP, a dataset of probability word problems where each problem is annotated with its solution and a formal representation based on a declarative programming language. Three different Math-LLMs are evaluated: Qwen, DeepSeekMath, and Mathstral. In the experiments, the authors report three different metrics: accuracy (% of problems solved), inconsistency (% of pairs of problems that share the same archetype but who are not solved in the same way), and recall@10 (% of problems where the correct matching problem is retrieved from the KB). The experimental results show that, while math-LLMs can solve NLP4PLP problems with good accuracy, their internal representations predominantly encode linguistic rather than mathematical similarity. 

### Review
I liked the idea proposed in this paper: simple, clear, and well-documented. To the best of my knowledge, probing the mathematical semantic similarity between internal representations of different models is a novel idea. The closest work is probably [1], where the authors tested the ability of general (and not math-tuned) models to generate (linguistically and not mathematically) similar problems.

I have, however, a few concerns/observations regarding the experiments:

- For the inconsistency metric, it is not clear how the pairs are defined. Do you group all the problems sharing the same archetypes in pairs of two, or do you create a full cartesian product of the problem instances? It would be helpful to clarify this in the manuscript. 

- Always on inconsistency, I think it would be good to evaluate the impact of pairs where both examples could not be solved. 

- It is not clear how the problem embeddings are extracted. This could have a great impact on the evaluation: intuitively, earlier layers might contain more linguistic information, while final layers could contain more mathematical information. Having some ablation on this, then, could also be interesting.

On a more general note, I think these results are not surprising. Math-LLMs, despite being fine-tuned for mathematical reasoning, are still language models. Hence, the fact that substantial linguistic information is still contained in their “problem models” is expected. I think that, in future work, it would be interesting to understand to what extent it is possible to separate mathematical and linguistic information in the embeddings.

[1] Solving Math Word Problems concerning Systems of Equations with GPT-3, Zong, and Krishnamachari",1
249,"Strength:
- This work develops PPG foundation models using a decoder-only transformer
- loss function, embedding, and linear head are specifically designed to fit PPG applications.
- Results in Table 1 show promising results

Weakness:
- Table 1 is a bit hard to read. Different performance metrics (MAE, F1, false alarm rates) are included. Please consider separating them. 
- BP-SBP is not introduced. Also, why is 9.56 highlighted?
- In the conclusion section, it is claimed that the foundation model can be used for downstream tasks without further fine-tuning. I am not sure which experiments can support this claim.",1
250,"## Overview: 

In this paper, the authors extend self-expressive learning, which can be used to identify separate *linear*, low-dimensional manifolds that data lies in the union of, to the setting where the manifolds are non-linear. This captures a much wider class of data-sets, and through numerical experiments the authors show how their deep self-expressive approach can cluster with state-of-the-art accuracy on real world data like faces (EYaleB) and handwritten symbols (MNIST). Additionally, they show how their approach can handle corruption and can be further modified for other possible settings. 

## Strengths:

1. This paper presents a novel approach to self-expressive learning that yields strong numerical results. 
2. This paper is well aligned to the overarching goals of CPAL. 
3. This paper is well written and easy to follow. I was unfamiliar with self-expressive learning, but the authors enabled me to easily follow along. 
4. The illustrations of the approach (Figs. 1 and 2) were very helpful in understanding the method and made it easy to follow along. 
5. The authors discuss several ways in which to use in their approach in other settings, such as by modifying the regularizer and penalty term.  I believe this will make it easy for others to implement, in an *intelligent* manner. 
6. The authors present a comparison of their approach to self-attention and graph convolution networks, which I found to be interesting, informative, and topical. 

## Weaknesses: 

I found no major weaknesses of the paper. 

However, I do think there are a few points that, if addressed. would make this paper stronger: 

1. In Fig. 2, DELVE is compared to an autoencoder. While the representations learned by DELVE look much nicer (and support the authors' claims), the comparison to the autoencoder is complicated by the fact that only 4 layers of the autoencoder are shown, as compared to 40 DELVE layers. I assume the reason there aren't more layers of the autoencoder is because it is difficult to train one with 40 layers? Commenting on this rationale, as well as showing perhaps the DELVE representations after 2 or 4 layers (so as to at least match the autoencoder depth once in the figure), would be helpful in making a more clear comparison. 
2. It would be helpful for the reader to know more about the data sets used in Sec. 4 (what is COIL100?), as well as the other methods that DELVE is compared to (what is NMCE, and is it known that ``The better performance of NMCE relies critically on its use of data augmentation'' [lines 241-242]? If so, is there a citation that could be referenced?). It would additionally be helpful to reference, in the main text, that there are Tables and extra details presented in the Appendices, so that the reader can know that more details of the experiments are reported elsewhere. 
3. The paper ends rather abruptly, as there is no conclusion. I think it is reasonable to move some of Table 2 to the supplement and then have a paragraph or two re-iterating why this work is important and what future directions the authors foresee. 

## Questions: 

1. The choice of penalty term (Eq. 5) appears to be motivated by the elastic net regularizer (Eq. 4), but is never explicitly stated. Is that the correct motivation, or is there a separate reason for choosing that form?

## Summary: 

This is a great paper that introduces a novel idea, that fits well within the CPAL CfP and yields strong experimental results. I believe would be a strong addition to the first annual CPAL.",1
251,"Authors present a boosting technique to train PINNs. They focus on PDE problems where vanilla PINNs show bad accuracies and show that their method provides order of magnitude performance improvement at the cost of 3x training time and 2x memory time.

Strengths:
1. Paper is clear and well-written
2. GB-PINNs show highest accuracy for all systems considered making it a competitive method. 

Weaknesses:
Probably the biggest weakness of this paper is the poor baselines and the ablations w.r.t fourier features.

1. Comparison to vanilla PINNs may be unfair at this point. Vanilla PINNs are known to have many issues and there have been many papers trying to address them. Can the authors comment on their methodology compared to the many variants of PINNs currently present?
2. Similar to 1., the accuracy comparisons should probably also include vanilla PINNs of similar training and mem costs. So, maybe more collocation points/bigger models for the vanilla PINN. This would help the reader understand that given x resources, what is the accuracy gain. Is it still O(10) times or does it become O(1).
   - this ties back to 1: would sequence-to-sequence in 3.4 (which also introduces more cost by making the training sequential) or parameter continuation (for other systems, could start with some larger \eps and slowly decay it) be competitive alternatives as well? It's more useful to the reader to show these baselines rather than vanilla PINN.
3. In many real scientific systems, physics-based losses are only a part of the process. Supervision from observational data and/or simulations typically guide the neural network to better solutions. I'm wondering how much of the vanilla PINN failure modes can simply be fixed by a few data points (supervised loss) at minimal cost?
4. The PINN errors seem really large. Does the training fail/plateau? This again ties back to 2. and 1. It seems that the authors are primarily trying to fix the optimization difficulties. Other baselines here would be more beneficial than vanilla PINN which is known to be a poor baseline for many PDEs today. 
5. In 3.4 seems like the vanilla PINN (Krishnapriyan et al. reference) doesnt use fourier features. Is that right? In which case, the vanilla PINN baseline should include it since the inputs are 0,2\pi which are bad input ranges for NNs in general.
6. Not sure if I'm misunderstanding the ablations: but it seems like the fourier embeddings substantially improve the accuracy on their own. For each system vanilla PINN + fourier features gives the following accuracies: 0.6%, 4%, 16% and 1%. If that is true, this weakens the contributions of GB-PINNs for all systems except system 3. This needs to be emphasized in the main text, because (similar to 2.) the reader needs to be clear on what the best method is given a computational/memory envelope and fourier features add no cost. Please comment.

For reasons highlighted in the weaknesses, I lean towards 5. but open to raising my score based on author's comments/other reviewers or if I misunderstood some ablations.",-1
252,"## Summary
This paper attempts to address the important problem of training fair and unbiased Machine Learning (ML) models in clinical settings, when some demographic information about individuals or groups is not available due to privacy or other reasons. To mitigate this, the authors propose to use the model gradients as a method for grouping samples together, based on the intuition that the gradients may carry information about the unknown demographic features. They construct a graph where samples with similar gradients are grouped together, and use it to learn their weights, within the context of an adversarial weighting algorithm. They run experiments on two different medical datasets, and show that their method can improve fairness significantly without much loss in accuracy.

## Strengths
- The idea of using the gradients as a (soft) grouping mechanism, and the intuition that they may be correlated with the unknown demographic features is interesting. The authors also attempt to justify this intuition theoretically, using concepts from information theory.
- The empirical results of their resented adversarial weighting algorithm seem promising, and are competitive against the baselines tested.   

## Weaknesses
- In my personal view, the biggest weakness of the paper is clarity: some descriptions are dense, and some parts are hard to follow. The paper would benefit a lot from addressing this. For example, in section 3, notations such as U(h) are suddenly introduced in the text, without explanation. Similarly, in section 4, the method description is not easy to follow. Moreover, it would also benefit the paper to briefly explain the related background material, such as e.g. the Rawlsian Max-Min fairness objective, or some prior methods.
- The experiments presented are on small Neural Networks, although the emphasis of the symposium is on Foundational Models.

 ## Overall Assessment
Overall, I believe the ideas introduced in the paper are valuable, and the empirical results promising. My greatest concern is the clarity of the presentation, and I'm willing to increase my assessment if that is mitigated.",-1
253,"This paper delves into the limitations of rotation-invariant algorithms, especially for learning sparse linear problems, highlighting that these algorithms struggle to generalize well when noise is added to sparse targets. It establishes theoretical lower bounds on generalization error for rotation-invariant algorithms, contrasting them with more adaptable algorithms like those using multiplicative updates or certain regularization techniques (e.g., Lasso). Through analysis of gradient flow trajectories, the authors illustrate how rotation-invariant algorithms cannot prioritize sparse features effectively and tend to treat noise and signal equally. Experimental observations suggest that non-rotation-invariant structures (like the spindly network) better learn sparse noisy targets, hinting at the importance of symmetry-breaking mechanisms in neural network design.

For the remarks of this paper, I would like to say:

1. The paper provides rigorous lower bounds for rotation-invariant algorithms in sparse linear settings, extending the discussion to noisy contexts where these algorithms continue to underperform. This fills a crucial gap in theoretical machine learning literature by offering both upper and lower bounds, which makes this paper novel and the contribution solid. The proof method is particularly robust for analyzing algorithm performance across various problem rotations

2. The paper is well written, and the reference list is complete. The analysis of the sparse linear model and the rotational invariant model contributes to the theoretical machine learning community. I would give this paper an accept.

3. I would like to say, in order to make it easier for the audience to understand, the authors can write more intuitive ideas and explanations for the theorems and lemmas, so that we can understand the full picture of the proofs at the first hand.",1
254,"The authors show the application of PINNs to soil temperature modeling in a biodiversity experiment. The study explores the feasibility of  PINNs in estimating the thermal diffusivity of soils under different diversity treatments and 4 different meteorological conditions. Thermal diffusivity is individually estimated per treatment and meteorological condition and subsequently analyzed with mixed-effect modeling. Methodologically, the paper is not too novel, as inverse PINNs have been applied in other domains before. From a domain science standpoint, the paper clearly shows that diversity has an effect on thermal conductivity but does not elucidate how diversity affects thermal conductivity.

Pros:
- application of inverse PINNs to a novel domain that can provide insights into whether PINNs are feasible for noisy ecological data

Cons:
- while the authors clearly state that they are in an exploratory state of their analysis, it falls short in including diversity treatment, soil moisture, or soil organic carbon directly as covariates in their PINNs to disentangle the diversity effect from, for example, an indirect diversity effect via higher evapotranspiration in diverse plots",1
255,"The paper showed the application of a physics-based deep learning approach in the pore-scale simulation of single-phase flow in porous media, as a replacement for the Lattice-Boltzmann (LBM) approach. It seems the improvements applied in the training algorithm could bring some advantages compared to the basis model (previous work). I do believe the applied changes are very useful in improving the results, however, the importance is not shown very clearly. Also, 

	I understand the importance of developing reliable deep-learning methods for the simulation of pore-scale flow processes. I also understand the novelty of the work in using physics-based algorithms (PINNs). However, I believe the positive impact of using PINNs compared to the previous work (basis) is not shown properly. I think there could be cases that PINNs could bring much better responses compared to the basis model, to demonstrate the novelty of the work. It is important since adding a physics-based loss term adds significant time in the training of the model.  
	As far as I understood, there were two changes in the model compared to the basis model: using circular padding, and physics-based loss function. The relative advantage of each is not clear by looking at the results. However, I understand the limitations in the extended abstract, maybe it can be applied to the full paper later. 
	Equation 8 seems to be unclear to me. Did you use the residuals (PDE errors) from the LBM simulations? Why it needs to be applied if it is really an error? 
	should you add parentheses in eqs. 7 and 8 to apply the impact of sigma two both terms? 
	The paper starts with the importance of the measurement of permeability, … while in the results there is no information about the permeability predictions. It would be even better if there were a report about the improvements in the permeability prediction compared to the basis method. 

	There are a variety of writings and referencing issues, such as 4th line in the introduction section.
	Unclear sentence: “With recent advances in data-driven methods, promising new approaches, have been introduced, significantly reducing the computational cost of the numerical simulations while preserving the fluid-fluid and fluid-solid physical interactions.”
	The authors mention the term ‘pixel-level’, while it is not really representative of the author's meaning, I guess. At least at some point in the abstract, I prefer to clarify it by a more understandable term such as ‘pore-level’ or ‘pore-scale’ …
	Figure 2 does not seem to show what has been mentioned in the caption.
	Figure 5: it is not clear if it is showing testing data or training data.
	The size of the dataset used for the training is not clear enough.",1
256,"The authors present an intuitive clustering method that appears to be efficient and generalizable. The authors describe existing shortcomings and the motivation clearly. Although there are several grammatical errors, they are insignificant enough to not affect the clarity.

Pros
+ Thorough comparisons with various baselines and explored different data modalities
+ Nontrivial theoretical analysis

Cons
- Although the number of datasets tested is sufficient, the scale of the data is quite limited
- Included theoretical algorithm complexities but lacks empirical verification of speed-ups/memory requirements compared to other methods

Questions
1) Based on Figure 2, it is interesting that your method preserves diversity within each cluster in contrast to IDEC's embedding space where points in a cluster collapse on each other. Why is this happening, and what are the implications of this property?

2) Is there an interpretation of what the fully-connected layer does in the fusion step? Does it learn a specific way to mix information?",1
257,"**Paper summary**   
VARL is a reinforcement learning-based framework designed to solve Locally Checkable Labeling (LCL) problems. Compared to traditional supervised learning methods, this approach eliminates the reliance on ground truth solutions and avoids bias toward specific algorithms. By leveraging local validators to evaluate solutions, it is not constrained to unique solutions and can effectively handle tasks with multiple valid solutions. It has demonstrated effective generalization capabilities across multiple tasks, outperforming supervised learning baselines.   
**Originality**  
- **Strengths**: VARL follows the framework of the supervised method GraphFSA but relaxes the constraints on the transition function, making it more generalized. Each node and edge is treated as an agent that independently selects its next state, while all nodes or edges share the same policy, effectively reducing the number of parameters. The rewards are from the results of local validators and guide the model to find valid solutions.   
- **Weaknesses**: While the idea of allowing the model to freely explore all possible solutions through the reinforcement learning process is interesting, its time complexity needs further consideration. The approach of exploring all valid solutions without relying on specific algorithms could be seen as a heuristic. However, the exploration process in reinforcement learning, how to avoid redundant computations, and how to ensure all solutions are effectively discovered require deeper investigation.    

**Quality**    
- **Strengths**:   The technical derivations are sound. The model employs a multi-agent reinforcement learning framework, graph convolution layers for aggregating neighbor states, and MLPs for encoding and decoding. The performance improvements demonstrated in the experiments support this approach.  
- **Weaknesses**: This reinforcement learning-based approach does not rely on ground truth or specific algorithms, which might necessitate a complete exploration of the entire graph. The paper lacks a theoretical analysis of the time complexity, and the experiments are conducted solely on small graphs of size 16, without extending to larger graphs. Furthermore, the paper does not provide detailed descriptions of the design and computational cost of the local validator. In theory, the validator would need to be manually designed for different tasks.   

**Significance**     
- **Strengths**:   This method differs from traditional supervised methods as it does not rely on ground truth or specific algorithms, yet achieves better performance across various tasks, demonstrating strong generalization capabilities. It provides a universal foundation for learning algorithmic reasoning on graphs. The experimental results indicate that the combination of reinforcement learning and local validators offers a promising direction for addressing algorithmic problems on graphs, with broader implications for learning and reasoning in discrete domains.  
- **Weaknesses**:   Although the results are promising, the time complexity is not analyzed, making it difficult to assess the practical applicability of the approach. The broader applicability of this method has not been thoroughly discussed. Incorporating more comprehensive baselines or complexity comparisons would further enhance its significance.    

**Questions and suggestions for the authors**  
- In addition to supervised learning baselines, could the authors consider introducing other reinforcement learning methods for comparison to more comprehensively evaluate the performance advantages of the proposed approach. Furthermore, incorporating traditional heuristic-based algorithms as additional baselines, particularly well-known classical algorithms in LCL problems, could provide valuable insights.

- Testing on larger-scale graph structures (e.g., with 100+ nodes or more) would help analyze changes in training efficiency and validator performance. Additionally, evaluating the scalability of the proposed method in real-world large-scale network datasets would strengthen its practical applicability.

- Could the authors provide detailed descriptions of the local validators, such as pseudocode or process flows for each task, and analyze their time complexity to give a clearer understanding of their computational requirements.

**Limitations**     
The authors repeatedly emphasize that the local validator is a core component, but they do not provide detailed descriptions of its design or computational cost. For different tasks, this module may require manual design, which could limit its general applicability. Another limitation is that, although the model demonstrates strong performance and generalization capabilities, its complexity and training time costs cannot be adequately evaluated. Additionally, the correctness of the solutions relies entirely on the validator, without robust theoretical guarantees to support its reliability.    

**Ethics**    
There are no obvious direct ethical concerns related to the method as it stands. The paper does not deal with sensitive data or produce sensitive content. The approach is a method improvement and not directly involved in human-facing decision-making applications at the evaluation stage. No unethical dataset or methodology usage is apparent. Thus, no ethical issues need to be flagged for special ethics review.",1
258,"The strengths of the paper include its emphasis on high quality and clarity, showcasing SoftTiger's superior performance compared to established models like GPT-3.5. The clear articulation of objectives and addressing challenges in healthcare workflows adds to the paper's credibility.
The originality and significance of SoftTiger's approach in tackling critical subtasks within healthcare are commendable, contributing to its innovative standing. The acknowledgment of both the advanced capabilities and scalability of SoftTiger, with two configurations catering to different research needs, adds to its appeal.

However, the potential challenges or cons associated with SoftTiger, such as the risk of hallucination due to the statistical nature of language models and the dependency on the volume and quality of training data. Recognizing these limitations is essential for a comprehensive evaluation.",1
259,"## Summary
This manuscript explores the application of traditional machine learning models (Random Forest, Logistic Regression, and kNN) to the prediction of Chronic Kidney Disease (CKD) on the MIMIC-IV dataset using CKD-related ICD codes as labels and non-CKD-related ICD codes and demographic variables as features.  This is an important healthcare problem and establishes a baseline on MIMIC-IV dataset.  In general, the methodology for data sampling, splits, evaluation metrics are well done.  This manuscript would be stronger with the inclusion of more advanced models such as gradient boosted trees which often achieve stronger performance in many healthcare prediction tasks with tabular data. 

 The authors are somewhat vague in the real-world application of this model--Is the goal to create a clinical decision support/forecasting model while the patient is still in the hospital? Is the goal to create a model that can detect if we forgot to mark the presence of CKD in an encounter for billing after the ICU stay?  This is not clearly stated and these are different questions that require different modeling approaches. The design of the presented models are mainly useful for the second line of questioning.  However, in an ICU population where creatinine and eGFR values are very frequently measured, why not compute a clinical baseline using traditional diagnostic definitions for comparison? This is currently absent from the manuscript and inclusion would make the research much stronger. More on this below.

## Pros
* Important healthcare problem. Research establishes baseline for CKD prediction task from ICD + demographic data on MIMIC-IV dataset.
* Well designed experiments, train/test split
* Large sample size & statistically robust
* Good choice of evaluation metrics (AUROC, AUPRC) and threshold selection rationale with MCC

## Cons
* I consider Random Forest to be a simple model. The findings would be more interesting if a more advanced model such as Gradient Boosted Trees was also compared, especially since Gradient Boosted Trees often achieve state-of-the-art performance on many healthcare prediction tasks using tabular features.
* Poor word choice in second paragraph of ""Predicting Undiagnosed CKD Patients"" section.  The authors write ""The lower sensitivity is a benefit in this case..."", but lower sensitivity is never a benefit because we always desire higher sensitivity and specificity.  I think the authors mean that it is an optimal trade-off.
* This analysis pools all CKD classes together rather than predicting individual CKD I, II, etc.  It would be more interesting/valuable if authors designed experiments to predict individual CKD classes in addition to predicting presence/absence of CKD.  This is because management and healthcare cost of CKD I/II patient (often no dialysis, medication management) is very different than CKD IV/V (patients usually more ill, more comorbidities, and/or require dialysis).  The utility of this prediction model would be significantly improved if models were able to predict CKD classes.
* MIMIC IV dataset is derived from real electronic health records of ICU patients where there is a temporal nature to the data. Some diagnoses & ICD codes may be present in certain days/encounters earlier than others. The authors' methods indicate that ICD codes extracted correspond to all ICD codes for a given stay--that is at time of discharge. Choosing this time point limits the utility of this predictive model as many diagnoses (ICD codes) will be accumulated during the ICU stay and may not be present on admission.  The value of this model thus becomes post-encounter detection (e.g. CKD billing code is missing), not for prospective clinical decision support. A more clinically useful time point for prediction for diagnostic/clinical decision support would be earlier in the hospital stay (e.g. day 1 or day 2 of admission).  The target use case of the proposed model should be more clearly stated; currently it is vague. The chosen use case for this model would then inform different choices for data selection and model development.
- Since the study population are ICU patients, I expect almost all to have multiple creatinine value or eGFR determined in their laboratory studies. The creatinine and eGFR values are how CKD is diagnosed using diagnostic criteria such as KDIGO.  The authors tangentially acknowledge these traditional diagnostic criteria in ""Previous Work and Study Scope"" section, but do not actually compute these values as a clinical baseline.  The proposed line of research would be much stronger and clinically useful if authors determined CKD from traditional diagnostic criteria (which is still widely used in clinical medicine) as a baseline for comparison, or used the computed values as ground truth instead of ICD codes. This should be possible for most patients in the MIMIC dataset because of the high availability of creatinine and eGFR data in ICU patients. Currently authors compare against presence of ICD codes that are related to CKD, but this ground truth may be inaccurate given that ICD codes are primarily used for billing purposes.  In theory ICD codes should reflect the patient's clinical reality but in reality it may not necessarily be reflective since it requires billing staff or healthcare staff to denote the presence of the diagnosis in the patient's EHR. Thus relying on ICD codes as ground truth may actually lead to your model to under-diagnose CKD.",1
260,Authors propose FASTVPINN framework using tensor-based computation of variational loss and bilinear transformations for quadrilateral cell.,1
261,"The paper showcases an innovative approach for symbolic equation discovery, a topic that has gained a lot of relevance. The authors show improved results in benchmarking of their method compared to the original BMS method but lack comparisons to other well established methods for symbolic discovery. The paper is well written and has a focus in earth sciences with results shown for the models of the domain.",1
262,"Summary: The authors propose using implicit neural representations with energy-based coupling to provide an efficient surrogate for Bayesian experimental design. 

Strengths and Weaknesses:

* It was slightly confusing to have Figure 2 come before Figure 1

[+] The paper is well-motivated and well-written. The application of neural operators to Bayesian experimental design (BED) is novel, and the authors make it clear why existing approaches would be inefficient compared to the proposed approach. 

[-] Given the author's claim to prior inefficiencies for BED, i.e., having to solve the PDE for each MCMC step, it would be nice to see some baseline comparison highlighting how the author's approach is much faster and more efficient than prior approaches. I see no reporting of training or inference times. 

[-] Does the author's INR model differ at all from CORAL (Serrano et. al., 2023)? It's stated the workflow is based on it, so I think the authors should state it by name, i.e., CORAL, like they do FNOs and DeepONets. This clarifies that the contribution is not CORAL itself, which has already been published. In the author's INR section, this is not referred to at all, while it is mentioned in the appendix, so it's a bit confusing what the authors are claiming as their contribution. This could be a misunderstanding of the author's modification to CORAL if that is the case, but I still think it should be named and clarified in any case. 

[-] I fail to see a strong contribution with the problem solved in section 3.1. It appears the authors are just using the CORAL or, alternatively, FNO/DeepONet architectures, which they propose as future work, to perform inference. It seems to me the main contribution of the paper is the application of these function to function map neural architectures to BED. In the case of the problem in 3.2, this contribution is clearer, and the application to BED is shown to be better than Sobol points. The abstract is about this application to BED, so I fail to see how section 3.1 adds to that beyond standard operator learning results, albeit with energy-based coupling. Even in that case, the results of the learned coupling (using EBMs) have more spread and include high-frequency oscillations compared to the numerical simulations. 

Conclusion: While the application of neural operators to BED is novel, the exact contributions and benefits of the author's approach are not clear and concise.",-1
263,"This paper proposes to solve math problems by automatically selecting between chain-of-thought (CT) and program-of-though (PT) prompting. The selection is implemented with a categorization model using a 3-layer neural network based on word frequency features.

Despite some interesting insights, the paper has some major weaknesses: 

* Weak categorization model. The categorization model is based on word frequency features. As mentioned in the paper, one of the main challenges encountered in categorization is ‘answer extraction,’ which is hard to address with word frequency features. Hence, a stronger sequence model (such as a Transformer) should be taken into account for solving the categorization. 
* Why not compute the posterior probability? The current approach takes the argmax of the output distribution of the categorization model, and based on the selected category samples from the P_s(. | c), where s in {CT, PT} and c in {algebra, geometry, number theory, combinatorics}. However, one could also incorporate the output distribution of the categorization model into the computation of the posterior sampling distribution.  
Moreover, the definition of the prior sampling distribution {CT, PT} is somewhat arbitrary and not justified. 
* It is not clear how the approach is helping to reduce hallucinations in LLMs. If the approach would indeed reduce hallucinations, it should be demonstrated empirically. 
* The methodology is not clear: the paper is missing important details about network architecture for the categorization model, example prompts, etc. In its current form, the experimental results of this paper are not reproducible. 

Minor weaknesses/corrections
* References of AlphaProof and Alphageometry link to news articles instead of the original papers. 
* The section references are broken.",-1
264,"1. Summary and contributions: Briefly summarize the paper and its contributions
Introduces a new automated evaluation framework for assessing the conversational ability of LLMs to diagnose medical conditions. The framework uses a patient AI agent (also an LLM) to simulate a doctor-patient interaction. The conclusion of the interaction (the diagnosis) is then evaluated by both a grader LLM and a medical expert. 4 conversational setups are tested using 140 skin disease vignettes. The author claims this shows the shortcomings of LLMs in gathering patient histories, synthesize information over dialogues, and clinical reasoning for diagnosis without answer choices

2. Strengths: Describe the strengths of the work. Typical criteria include: soundness of the claims (theoretical grounding, empirical evaluation), significance and novelty of the contribution, and relevance to the community.
- The development of robust automated evaluation of LLMs is vital for the safe adoption of this technology.
- Increasing work is being done on conversational agents and as is correctly stated in the paper this strategy significantly enhances the scalability of evaluations and allows for broader and quicker testing. Another strength not mentioned over human evaluation is the ease of reproduction.

3. Weaknesses: Explain the limitations of this work along the same axes as above.
- No human baseline is provided and so it is difficult to gauge the level of performance shown in Table 1. It is fair to assume that the drop-off in model performance seen with increasing task complexity, e.g. mcq -> frq, clinical vignette -> multi-turn, would also happen for humans. - The extent of this is unclear though.
- The evaluation dataset is currently limited to 140 cases only focused on skin diseases. Furthermore, an unknown proportion are sourced from the internet. As LLM are trained on large-scale internet crawls, there is a high possibility of test set leakage. 

4. Correctness: Are the claims and method correct? Is the empirical methodology correct?
- As an initial paper establishing the framework, this paper needs to first establish the method as valid before making claims establishing the undoubted shortcomings of LLMs. For example, an underlying assumption is that the grader AI agent is accurate and unbiased. Previous LLM evaluation work has shown this not to be true, for example GPT-4 models favouring GPT-4 outputs. A similar assumption holds that the patient AI agent answers accurately and, for example, never hallucinates. 
- The validity of the method could be shown by running the same framework swapping out the AI agents for real human and showing the metrics are unchanged. This is suggested by the medical expert box in Fig 1, but no mention of these results is made in the main text.

5. Clarity: Is the paper well written?
Text is clear and well-written
- The icons in Fig 1 make it unclear which parts of the framework are automated, and which are human. For example, the clinical LLM has a human icon, and the grader-AI and patient-AI have different icons.
- It is not clear to me if the patient-ai and grader-ai agents are fixed models (and if so, which models) or change with the clinical LLM model being tested. Both could lead to differing methodological issues. By fixing the models, the framework may favour models of the same “type” but by changing the evaluating models metric is fundamentally changed. 

6. Relation to prior work: Is it clearly discussed how this work differs from previous contributions?
- A thorough, succinct review of the need for medical innovation, LLM development and shortcomings in automated medical evaluation is given. The introduction could be explicit about the pros and cons between human and automated evaluation.
- The recent work “Towards Conversational Diagnostic AI” would be highly relevant to mention. But an acceptable miss as it was published very close to the submission deadline.

7. Reproducibility: Are there enough details to reproduce the major results of this work?
- The link to framework’s code is provided for reproducibility. 
- It is mentioned that 10 simulations are run. I assume this is done via sampling (e.g. through temperature) but not mentioned what these hyperparameter settings are",1
265,"The paper introduces innovative prompting techniques and demonstrates their effectiveness in improving the performance of the general language model Yi-34B over a clinically fine-tuned LLM, Meditron 70B, across three out of four medical Q&A benchmarks: MedQA (4 Options), MedMCQA, PubMedQA, and MMLU - Medical.

**Pros**

1) **Clarity of paper**: The paper is well-written and easy to follow. Figure 1. showing LLM performance with time is good. 

2) **Good improvements and ablations**: The results with different prompting techniques are well demonstrated in Figure 2 and Table A1.


**Cons**

1) **Unavailability of training dataset for KNN FS CoT (minor)**: Since this requires access to train set samples, it is a costly process, and training data won't always be available for many models. I do understand the point of open source LLMs which the paper advocates. But consider medical domain datasets that are sensitive to release. Hence the authors are not able to show results of Meditron 70B on kNN FS CoT. This is to be discussed in limitations.

2) **Experiment baselines**: The exclusive focus on Meditron 70B as a baseline leaves the comparison somewhat narrow. Including at least one additional medical LLM baseline would offer a broader perspective on the presented techniques' relative performance.

3) **Missing Proper References**: The paper lacks references for the various prompting methods (CoT, KNN prompting, etc.) utilized in the study. These missing references raises following two questions:

4) **Novelty**: : It is unclear whether the use of KNN with training samples is a novel contribution of this paper or if it has been previously used.

5) **How are similar questions selected for kNN FS CoT?**
I didn't find how similar questions to test examples are chosen via KNN in the paper. It is done in which space (embedding space of model/input space). Please explain it properly.

6) **Limitations of kNN FS CoT and other prompting strategies:**  The potential for prompting strategies, such as kNN FS CoT, to overemphasize reasoning patterns from similar training samples needs further discussion. Highlighting this and other limitations of the proposed methods would provide a more balanced and comprehensive view of their applicability.

7) The clarity of Figure 2. can be improved with the usage of other shades of colors than green for more clarity.

The paper presents evidence that innovative prompting strategies can enhance the performance of open LLMs compared to fine-tuned counterparts in the medical domain. However, addressing the aforementioned concerns would strengthen the paper.",1
266,"This paper introduces the learning framework of *list regression* and introduces two combinatorial dimensions, generalizing, respectively, the fat-shattering dimension by Alon, Ben-David, Cesa-Bianchi and Haussler and the OIG dimension by Attias, Hanneke, Kalavasisi, Karbasi and Velegkas, to characterize, respectively, the agnostic case and the realizable one. 

List regression can be seen as a particular instance of a *list learning task*. For such kind of tasks, the learning algorithm, on input a given test point, is allowed to output a short list of values for that point and it is declared successful whenever at least one of them is correct. The study of list learning frameworks for **classification** has recently received some attention: here, the learner outputs a list of possible labels for the given test point, and succeeds in case its true label belongs to that list. List classification is, indeed, a very natural framework to study, with wide applicability (just think of recommendation systems). In the case of regression, on the other hand, we deal with objective functions $h \colon \mathcal{X} \to [0,1]$. Thus, in the list regression framework, the learner, when receiving a test point $x$, must output a list $(y_1, \dots, y_k)$ of values and its prediction is consider successful whenever some of the $y_i$'s is sufficiently close to $h(x)$. Although this may be theoretically interesting, such framework doesn't seem as much natural to consider, and the authors do not really provide clear motivations for their work. 

As mentioned in the beginning, the work done in the paper can be summarized as follows: 

- The authors propose a generalization of fat-shattering dimension, which they call $k$-fat-shattering dimension: usual fat-shattering dimension is recovered in case we set $k=1$ in their definition. Furthermore, they prove that finiteness (at every scale) of such dimension characterizes learnability in the agnostic list regression framework, by some learner which outputs a list of $k$ values.

- Similarly, they generalize OIG dimension to the so-called $k$-OIG dimension: again, the standard definition corresponds to the latter in case $k=1$. They hence show that a class can be learned in the realizable list regression framework by some learner which outputs a list of $k$ values if and only if its $k$-OIG dimension is finite at every scale. 

- Both in the agnostic and the realizable settings, list regression is strictly easier that standard regression: this is shown by analyzing examples inspired, respectively, by the work of Charikar and Pabbaraju and that of Bartlett, Long and Williamson.

**PROS**

Although I was not able to check the details of their argument, the authors develop a seemingly interesting theoretical machinery, reworking techniques from different areas of learning theory. Therefore, they seem to have an accurate knowledge of the state of the art. 

**CONS**

- I honestly found the paper very hard to follow. It is also very hard to review it, as, in particular, the first 12 pages of the paper do not really contain any outline of the main arguments. I strongly suggest to the authors to modify the setup of the paper in such a way that the first 12 pages contain both the definitions of $k$-fat-shattering and $k$-OIG dimension an informative (yet, possibly, intuitive) general outline of both the main results.

- The whole framework of list regression does not seem very natural to consider: indeed, the motivating example given in the introduction appears quite artificial and uninteresting. Is there a more natural or interesting example which can better motivate this learning setting? 

- It is not really clear to me how this paper relates with the framework of list-decodable regression. I hope that the authors are willing to elaborate further on this point.",-1
267,"The paper proposes a deep learning framework that integrates a cycle transformer inspired by CycleGAN and a DDI loss inspired by 4SDrug to predict the drug combination prescription. The experiment carries out with MIMIC-III dataset, indicating that the proposed model outperforms previous models by large in terms of Precision, DDI rate, and Average number of drugs in the set. 

### Strength: 
1. The experimental results are promising.
2. The model design seems reasonable.
3. The problem of predicting drug combination is important.

### Opportunity to improve:
1. The reference number of Baseline in Table 1 does not align with other citation styles.  
2. The definition of Precision needs clarification. If multiple drugs suit the patient, does hit with any of them count as 1? If it is not the case, it would be very unusual to see the Precision outperforming baselines by this far while maintaining such a small Avg #. It is extremely crucial to clarify this.
3. How is the DDI adjacent matrix defined? Without clarification, it can be very confusing. There may raise concerns if the definition of DDI is actually making sense in terms of medicine and for clinicians. 
4. I do not see why L_{EMD} can be jointly added to the loss function, even though WGAN uses it. What are set A and set B, and why is there a need to transfer A to B? 
5. Hyperparameters tuning will be very important since there are multiple loss functions. I assume adding appendices to explain how to reproduce the results and/or code would be helpful.
6. I do not think it is a good idea to call it a “foundation model”, since it has so few downstream tasks. It is not necessary to name it a foundation model just to fit in the symposium topic.",1
268,"The manuscript titled ""Learn to adapt parametric solvers under incomplete physics"" outlines an approach to predict the time dynamics of a dynamical system by incorporating known components of the physical characteristics and modeling only the unknown components. The paper is well written and clearly outlines the challenges, the approach used and the rationale for all decisions made towards the final proposed solution. The key idea is to decompose the RHS of a PDE into known and unknown components with an assumption on the functional form of this split and only train a model to learn the unknown dynamics. These unknown dynamics are further split into environment-agnostic and environment-dependent portions and a meta learning approach is described to be able to compute the environment-dependent portion of the model parameters using a linear model and learned low dimensional context vectors. This low dimensional context vector enables cost efficient adaptation to new environments. The experiments are conducted are described well and the results and ablations show the appeal of the proposed approach. With the exception of a couple of small details, all the conclusions drawn from the experiment results are well substantiated. Overall, I would recommend accepting this paper. Some specific comments:
- Section 1: ""incorporating physical constraints within a loss function"" Should cite Raissi et. al. 2019 here since they were the first to do this.
- Section 2.2: ""Since the closure model operates on the low resolution dynamics model, a better decomposition is:"" Why is composition a better approach for closure models? Typically closure terms are added as an additional source term, so wouldn't the residual approach be appropriate here as well?
- Eq 7: Is there any specific reasoning or intuition to choosing the sum of \theta^e and \theta^a vs. some other architectural mechanism to produce g_c(\theta^e, \theta^a)?
- Section 3: Citations for CoDA and CAVIA are needed here.
- Section 3: ""We also extend CoDA into a hybrid version by adding to the original data-driven loss a physics-informed loss similar to the ones in PINNs"" Should clarify if the physics-informed loss is applied on the whole model based on incomplete physics or a residual type approach with one part having the incomplete physics loss and the other one being purely data driven. The latter would be more comparable to the approach here and allow direct comparison of soft vs hard constraints, but the discussion makes it sound like the former was used.",1
269,"This paper considers a repeatedly played generalized Nash equilibrium game. This induces a multi-agent online learning problem with joint constraints. An important challenge in this setting is that the feasible set for each agent depends on the simultaneous moves of the other agents and, therefore, varies over time. As a consequence, the agents face time-varying constraints, which are not adversarial but rather endogenous to the system. Prior work in this setting focused on convergence to a feasible solution in the limit via integrating the constraints in the objective as a penalty function. However, no existing work can guarantee that the constraints are satisfied for all iterations while simultaneously guaranteeing convergence to a generalized Nash equilibrium. This is a problem of fundamental theoretical interest and practical relevance. The authors introduced a new online feasible point method. Under the assumption that limited communication between the agents is allowed, this method guarantees feasibility. They also identify the class of benign generalized Nash equi- librium problems, for which the convergence of our method to the equilibrium is guaranteed. They set this class of benign generalized Nash equilibrium games in context with existing definitions and illustrate our method with examples.

Pros: This paper gives an algorithm for the updates of the desired sets and the iterates. The contributions are summarized as follows: 1. The authors introduce the online feasible point method (online FPM) and show that feasibility is guaranteed for each iteration if each player uses the online FPM in a repeated generalized game. This method follows a fundamentally different approach from existing methods which are based on Lagrangian splitting schemes or penalty methods. 2. The authors identify a subclass of GNEP, which are called strongly benign GNEP, for which convergence of the iterates to an equilibrium is guaranteed. Furthermore, they illustrate the class of strongly benign GNEP with examples and set it into context with common assumptions such as strong monotonicity for games. 3. The authors derive regret bounds for each player and set these results in context with existing results on online learning with varying constraints. For online problems with varying constraints, strong guarantees are possible if the constraints are not adversarial but endogenous to the system. 4. The authors illustrate the behavior of the proposed method with various examples of strongly benign GNEP. They also demonstrate the convergence to the GNEP without constraint violation for GNEP beyond strongly benign GNEP.

Cons: First of all, the authors did not explain why it is important to study generalized Nash equilibrium problems in online setting. I agree that the multi-agent online learning with joint constraints would be a natural extension but some justification from practical sides is necessary. Second, the proposed method is simple and easily understood. However, when the constraint set is complicated, I do not know if we can implement some steps in pratice. For example, it would be not easy to compute (1) the minimal distance with respect to the gradient direction $g_t^{(i)}$ of the set $S_t^{\times [n]}$ to the boundary of feasible action set $\mathcal{C}$ and (2) the maximal step into the gradient direction $g_t^{(i)}$ while staying within $S_t^{(i))}$. In my humble opinion, it is computationally expensive to maintain the feasibility of the iterates for solving generalized Nash equilibrium problems mostly because the constraint sets are complicated. This is why the previous works integrate the constraints in the objective as a penalty function. While I definitely agree that the feasibility would be practically relevant, it would be better if the authors clarify why the proposed methods are implementable for solving practical problems. Finally, your results in Theorem 7 demonstrate the last-iterate convergence rate in the $\ell_2$-norm which only holds under the strongly monotonicity property and its variants. Thus, I am not sure if a class of strongly benign GNEPs are a unnecessary relaxation of strongly monotone GNEPs. I encourage the authors to provide some nontrivial examples which are strongly benign GNEPs but not strongly monotone GNEPs.",1
270,"The authors present a novel approach to operator learning with the application of learing solution operators for PDEs in mind. The proposed method applies the concept of Hypernetworks to the realm of Scientific Machine Learning and operator learning in particular.

The idea is simple and presented in a straight-forwards fashion. The idea is tested on two different PDE problems (Burgers equation and Heat equation) and hyperparameters are disclosed to make the setup reproducible. My main criticism is the limited evaluation of the method - as these two problems are fairly simple toy problems. As the self-supervised nature of physics-informed losses do not require extensive generation of training datasets, i would have welcomed more experiments, particularly in 2 spatial dimensions. Moreover, only DeepONets are considered as a baseline here. I understand that this is due to the problem setting. However, I would have welcomed a comparison to  other baselines such as Physics Informed Neural Operators (PINO).

Given that this is a workshop, I propose to accept the submission and encourage the authors to address my concern above, should they consider a full submission somewhere else.",1
271,"This is a nice paper discussing about uncertainty quantification in physics informed machine learning, by using a Bayesian perspective for the uncertainty quantification of DGM. Here are afew questions:
1. What is the advantage of the propsoed method compared to ""Yang, Yibo, and Paris Perdikaris. ""Adversarial uncertainty quantification in physics-informed neural networks."" Journal of Computational Physics 394 (2019): 136-152.""? Why not use the same approach there?
2. Where does the uncertainty comes from? Please be more specific. The authors claimed that ""To this end, we first interpret the data D to be the fictious dataset"", where does the uncertainty of the collocation points comes from in reality? 

Thank you!",-1
272,"Summary: 

This paper studies the problem of learning objects from randomly generated images.




Strengths:

- This problem seems well-motivated.



Weaknesses:

- The paper focuses on one-dimensional, quantized data, which limits applicability to real-world, multi-dimensional scenarios.

- In terms of presentation, it would be helpful to define the terms more rigorously in mathematical terms.
For example, in the notation section, it would be clearer if it were self-contained. 
If I am not mistaken, a canvas is a vector or sequence, yet I do not think it is formally defined.",1
273,"Summary of Contributions:

The work proposes a Foundation model for (as the title suggests) “assessing diverse physiological functions, using only photoplethysmography signals”. The authors encode vast numbers of 30s of PPG samples @40Hz and train a GPT like foundation model with the next sample prediction pre-training objective. Then they fine-tune this model for solving downstream tasks such as heart rate estimation, atrial fibrillation detection, blood pressure estimation, and detecting false arrhythmia alarms.

Strengths:
1. The paper is well written and easy to follow. The block diagram is representative of the method presented in the paper.
2. The proposed method is sound and it stands to reason that with the increase in the model parameters and the training set, more emergent behaviour should be witnessed.
3. The qualitative results in the appendix are quite impressive.

Weaknesses:
1. Details such as number of model parameters, training time, GPUs used, etc. are missing from the paper. They often provide some indication on how scaling up might improve the results, and also about the feasibility of using the model.
2. The fine-tuning time requirements when compared to the training time (from scratch) of SOTA specialist models are also missing in the paper.
3. Some ablation studies are missing. For instance, it was mentioned that (in the decoder) the  RMSNorm was preferred over LayerNorm, then PoPE was used instead of Positional Encoding from the original transformers paper. Some indicator on how these choices would have affected the foundation model training might have been good. (Although the feasibility of these ablations will depend on the pre-training computational requirements, which again cannot be inferred unless disclosed in the paper)",1
274,"The paper is on ""learnability"" applied to ""structured"" stochastic bandits. Here, the algorithm is given a function class $F$: a class of possible functions from arms to expected rewards; arbitrary reward distributions are allowed. $F$ is called ""learnable"" if, essentially, one can PAC-learn the best arm with bounded query complexity: i.e., if one can learn an alpha-optimal arm with probability at least 1-delta in some bounded time, for any given alpha, delta>0. 

The main result is a simple ""if and only if"" characterization of learnability (via some sup-inf expression). The basic version applies to bounded rewards (and in fact holds when restricted to binary rewards). This is extended to unbounded rewards with reward distributions of fixed variance, and also holds when restricted to Gaussian rewards. 

Interestingly, prior work (Hanneke and Yang (2023)) finds that learnability plays out very differently when rewards are deterministic: it is undecidable (within ZFC), let alone lacks a simple characterization. 

Extension #1: the optimal query complexity $Q^*$ is crudely characterized: placed into an interval $[T, exp(T)]$, for some known T. 

Extension #2: an alternative characterization is derived when the function class admits a regression oracle. This condition involves a variant of DEC ""Decision-Estimation Coefficient from prior work of Foster et al (2021, 2022)).  

MAJOR COMMENTS

[+] Learnability is arguably a fundamental question in structured bandits. A simple characterization is a very ""cool"" conceptual contribution, and should be published. 

[-] Practical significance is limited because learnability is already well-understood for any specific function class anyone cared to study earlier.

[-] The significance of the extensions is unclear: #1 is extremely crude, and the expression in #2 seems quite a bit more complex, even if DEC-like. 

The characterization's significance could be really enhanced via examples: how learnability plays out for some specific (interesting) function classes.  Ideally, also how resolving these examples via the characterization is much simpler than resolving them ""from first principles"". Absent such examples, the significance is less clear.  

The proofs are not complicated (which is both a ""pro"" and a ""con""). The main ""lower bound"" proof does something clever (even though the proof itself is short), whereas the main ""upper bound"" seems quite ""easy"". The other results are more technical, but do not seem to involve new ideas. 

""Non-learnability"" is not the end of the story, as one can usually address it via ""smoothing"", as per [KLSZ20]. That is: consider ""smoothed arms"" (i.e., perturbed an arm by a small noise), and compete with ""best smoothed arm"" rather than ""best arm"". This is arguably a reasonable benchmark when needle-in-haystack functions are allowed. So, this should be mentioned. 

In a revision, one should consider the minor comments below, and also address some issues with related work. 

MINOR COMMENTS

Does the characterization extend to some particular families of reward distributions, other than binary and gaussian? Perhaps an arbitrary family of reward distributions, under some mild conditions? Some such extension seems feasible, and would be worthwhile to add, in my opinion. (BTW, do mention somewhere that the characterization does hold for binary rewards!)

Discuss the main ""learnability condition"" (in Thm 1). In particular, note that it doesn't really work for finite #arms (i.e., it always holds), but it does work for countably many arms. Also, non-learnability can be interpreted in terms of ""needle-in-haystack"" (NIH) intuition: namely, the function $f$ that approaches the inf in (1) up to some eps>0 can be interpreted as an eps-approximate NIH w.r.t. distribution $p$ over arms. Thus, for any $p$ there must exist an eps-approximate NIH. 

Does a similar characterization holds for linear vs sublinear regret? This is another standard variant of ""learnabiity"" in stochastic bandits, hence a natural question to ask and comment on. 

In the DEC-like characterization (Sec5), spell out the resemblance to DEC very explicitly (since it seems like a primary motivator for this section), and note that the characterization assumes the existence of a regression oracle (I mean, otherwise the positive and negative results do not quite match). 

RELATED WORK

Cite the original papers for the three lines of work discussed in the Intro (note that they considerably predate the papers that you do cite). Specifically, linear bandits trace back to [AK04, MB04], Lipschitz bandits trace back to [KSU08], Bubeck et al (2011) and Slivkins (2011), and structured bandits trace back to [AK11]. For Lipschitz bandits, one should also cite the earlier work on ""continuum-armed"" bandits [A95, K04]. Likewise, contextual bandits (mentioned in Conclusions) trace back to [LZ07], if not earlier. 

Mention that learnability has been well-understood for most/all function classes studied in prior work. E.g., linear bandits are learnable iff the dimension is finite (I think). And Lipschitz bandits are learnable iff the Lipschitz constant is bounded. Further, for a fixed Lipschitz constant, Lipschitz bandits on a given metric space are learnable iff some notion of dimensionality is finite [KSU08]. 

Mention that there are different ""perspectives"" one could take when studying structured bandits and/or particular function classes. Aside from learnability, one could optimize the worst-case regret bound: specifically, constant in front of the $\sqrt{T}$, like in linear bandits, or the $\epsilon$ in $T^{\epsilon}$, like in Lipschitz bandits. Also, one could optimize the per-instance regret bound, specifically the constant in front of the $\log(T)$ term, like in Combes et al (2017). 

I assume that the prior work on DEC does not imply a similar ""learnability characterization"". So, this should be stated/explained explicitly. 


[A95] Rajeev Agrawal. The continuum-armed bandit problem. SIAM J. Control and Optimization, 1995.

[AKS11] Kareem Amin, Michael Kearns, and Umar Syed. Bandits, query learning, and the haystack dimension. COLT 2011.

[AK04] Baruch Awerbuch and Robert Kleinberg. Online linear optimization and adaptive routing. STOC 2004, JCSS 2008. 

[MB04] H. Brendan McMahan and Avrim Blum. Online Geometric Optimization in the Bandit Setting Against an Adaptive Adversary. COLT 2004. 

[K04] Robert Kleinberg. Nearly tight bounds for the continuum-armed bandit problem. NIPS 2004.

[KLSZ19] Akshay Krishnamurthy, John Langford, Aleksandrs Slivkins, Chicheng Zhang:
Contextual Bandits with Continuous Actions: Smoothing, Zooming, and Adapting. COLT 2019, JMLR 2020.

[KSU08] Robert Kleinberg, Aleksandrs Slivkins, Eli Upfal:
Multi-armed bandits in metric spaces. STOC 2008, JACM 2019.

[LZ07] John Langford, Tong Zhang: The Epoch-Greedy Algorithm for Multi-armed Bandits with Side Information. NIPS 2007.

POST-REBUTTAL COMMENTS

I appreciate the authors' responses and clarifications. 

- I understand that this is the first non-trivial combination of upper/lower bounds that applies generically.

- Good that the results extend to general families of reward distributions and to linear vs sublinear regret.

- Re DEC-like characterization: I see, both upper and lower bounds are stated for a particular regression oracle (in terms of its performance function $\bar{\epsilon}(T)$). So, this should be clarified somewhere. 

Re examples: it is interesting to work out both ""learnable"" and ""non-learnable"" examples, particularly so for the same ""domain"". For non-learnability: e.g., infinite $K$ for $K$-armed bandits; infinite $d$ for Lipschitz (resp., linear) bandits on $R^d$; infinite covering dimension (?) for Lipschitz bandits on general metric spaces. I wonder if there are less ""obvious"" examples of non-learnability that you might be able to work out, especially ones that were not known previously. I think it would improve the paper.

I strongly encourage the authors to revise as per the review / discussion: add examples, extensions, and related work; give more intuition for the main characterization; clarify the the DEC-like result; and point out that ""learnability for arbitrary bounded-variance reward distributions"" is equivalent to ""learnability for binary (resp., Gaussian) reward distributions"".",1
275,"This paper introduces a novel application of ODE-LSTM with an attention mechanism to the multi-touch attribution (MTA) problem, where the goal is to estimate the contribution of each touchpoint in a customer’s journey to a conversion event. The authors compare their approach with three competing methods on two real-world datasets and evaluate the performance in terms of conversion prediction and attribution estimation.

## Pros
1. ODE-LSTM can handle arbitrary time gaps between observations and model the probability of observation times through Poisson processes. (Section 1, Introduction)
2. ODE-LSTM outperforms other methods in scenarios where time intervals are not excessively irregular, and excels in estimating attributions compared to alternative approaches. (Section 3.3, Performance)
3. ODE-LSTM is highly consistent with Transformers in terms of attribution results on Criteo data, and has a dominating trend on Marketing sign-up data. (Section 3.3.2, Attribution Estimation)

## Cons
1. ODE-LSTM is not the best model in terms of AUC and PRAUC, and ALSTM and TCN are more robust in capturing patterns in scenarios with large and irregular time differences. (Section 3.3.1, Conversion Estimation Performance)
2. ODE-LSTM is extremely slow at both training and inference, due to its focus on continuous transitions. (Section 4, Discussion). This thing has been also pointed out in section 3.3.1. Some discussions on solutions to overcome this limitation would have been greatly welcome.
3. The authors use two real-world datasets, Criteo and Marketing Sign-up, but they are both related to online advertising and attribution modeling. They do not test their method on other domains or applications that could benefit from ODE-LSTM",1
276,"This paper talks about Tucker decomposition for ODE. The paper covers the theory of Tucker decomposition. The paper covers the complexity of the algorithm, however is unable to discuss the memory pressure. The paper also lacks the statistical comparison of the results and variability on multiple ODEs. From the workshop perspective, the paper appears to bring in a new idea, however more tests need to be done for representability.",1
277,"**Summary**

In this paper, the authors study the stochastic bandits problem in a general setting. They provide a characterization of the learnability of the model class under any zero-mean noise distribution by introducing a new complexity measure, $\gamma_{\mathcal{F}, \alpha}$. They demonstrate that the optimal query complexity of stochastic bandits can be both upper-bounded and lower-bounded by this complexity measure, indicating that it effectively characterizes the complexity of the learning problem. They further extend the measure to accommodate unbounded noise and Gaussian noise, showing that the complexity measure can still characterize the complexity of the classes in more general regimes. Finally, they propose a variant of the decision-estimation coefficient based on $\gamma_{\mathcal{F}, \alpha}$ and prove that it can also characterize the learnability of stochastic bandits.

**Strengths**

- I find it interesting that the authors introduced a new complexity measure for stochastic bandits. They establish both an upper bound and a lower bound for their measure, indicating that their complexity measure can characterize the learnability of the function classes.

- The paper is generally well-written, and the proofs appear to be both non-trivial and correct.

**Weaknesses**

- Although the paper provides a new complexity measure for learnability, the results they derive have a lower bound of $\Omega(\log 1/\gamma)$ but an upper bound of $\mathcal{O}(1/\gamma)$, which creates an exponentially large gap, making it potentially less useful for estimating the optimal sample complexity in general. I understand that the primary goal of this paper is to provide a complexity measure for learnability, but I think the decision-estimation coefficient also provides a way to characterize learnability by measuring the sample complexity. Thus, I would suggest that the authors include the value of $\gamma_{\mathcal{F}, \alpha}$ for common bandit instances, e.g., multi-armed bandits or linear bandits, to show that the proposed complexity measure is computationally feasible in general.

- The authors proposed a variant of the decision-estimation coefficient. However, there is no discussion about what differs from the original decision-estimation coefficient. I would suggest that the authors include a comparison paragraph to improve the presentation of the paper.

- Typo: there is an $\alpha$ missing in the definition of $dec_{\epsilon, \alpha}(\mathcal{F})$ on Page 9. The correct definition should be $dec_{\epsilon, \alpha}(\mathcal{F}) = \sup_{\bar{f} \in \mathrm{co}(\mathcal{F})} dec_{\epsilon, \alpha}(\mathcal{F}, \bar{f})$.


I am willing to increase my score if the authors address my concerns.",1
278,"The authors have amalgamated the strengths of EfficientSAM and LiteMedSAM methodologies to formulate Modality-Specific Strategies, leveraging the ONNX framework to enhance inference efficiency. Interestingly, a diverse array of enhancements tailored to various modalities and data dimensions are investigated. While the authors have introduced a multitude of incremental advancements in a single framework, certain pivotal intricacies remain unaddressed, necessitating further validation experiments.

1) In the context of 3D data processing, the authors employ the previous image's mask to generate prompts for subsequent images, capitalizing on the sequential image continuity. However, the segmentation quality of individual slices may occasionally be suboptimal, potentially impacting the subsequent slice's box generation. How does the author mitigate this challenge? Is there a fusion mechanism, perhaps involving a weighted combination, between newly generated and original boxes?

2) The authors experiment with introducing random sampling points as novel prompts alongside box prompts. What structural modifications on models ensue from this inclusion? Is there an adoption of a distinct prompt encoder? How are the training dynamics altered to accommodate both box and point prompts concurrently? What is the number of sampling points? Is the number of sampling points proportional to the box area?

3) Within the framework's majority voting mechanism for PET data, do all multiple views carry identical weighting coefficients? Could incorporating learnable weights potentially enhance performance further? Alternatively, is there merit in evaluating segmentation efficacy on specific views and adjusting weights through statistical methodologies for optimization?",1
279,"The paper considered the problem of k-list regression which is basically a problem of online regression (in this case with absolute loss) where the learner is allowed to make a list of k predictions and the one with the smallest loss is in effect considered. This problem can be framed as a general statistical learning problem with specific structure for the loss considered. The main challenge is to use this structure (of min over the list of losses) to obtain characterization of learnability. The paper provides characterization of learnability for both agnostic and realizable setting. The k = 1 case is the classic regression with absolute loss case and characterization for both agnostic and realizable setting are known for this case in prior literature.

The paper seems theoretically sound. I am not jumping up and down because I find the problem somewhat niche and not one that many people care about. That said, the paper is well written technically and the results are strong.",1
280,"Summary:


This presents the Unsupervised-CTRL (U-CTRL) framework, an innovative approach to unsupervised learning. The document thoroughly explains U-CTRL's formulation and objectives, demonstrating its ability to learn structured representations from unlabeled data. Extensive experiments on datasets like CIFAR-10 and CIFAR-100 showcase U-CTRL's effectiveness in clustering, image generation, and feature extraction tasks. Ablation studies emphasize the importance of different framework components. The document concludes by highlighting U-CTRL's robustness and contributions to unsupervised learning, making it a valuable resource for researchers and practitioners in this field.

Pros:
1. Unified Structured Representations: The framework focuses on learning structured representations, which can lead to more interpretable and meaningful features compared to traditional unsupervised methods. Moreover, compared with supervised-CTRL, this work simply view each sample as a new classes, providing a unified framework for learning structured and more interpretable features.
2. Versatile Applications: The document showcases various applications of U-CTRL, including image clustering, conditional image generation, and representation learning, highlighting its versatility across different domains and tasks.
3. Ablation Studies: The ablation studies provide valuable insights into the importance of different components within the U-CTRL framework, aiding researchers in understanding its inner workings and potential for improvement.
4. Competitive Performance: The framework achieves competitive performance on benchmark datasets like CIFAR-10 and CIFAR-100, indicating its effectiveness in comparison to other methods.

Cons:
1. Limited Real-World Data: The document mainly focuses on experiments with benchmark datasets like CIFAR-10 and CIFAR-100. The real-world applicability of U-CTRL may require further validation on diverse and complex data sources.
2. Hyperparameter Tuning: U-CTRL introduces two extra hyper-parameters $\lambda_1$ and $\lambda_2$. Finding optimal hyperparameters may require extensive experimentation.",1
281,"This paper proposes a variant of low rank adaptation method for SAM and MedSAM models to medical imaging tasks. 

Strengths
* The effectiveness of the adaptation on SAM is noteworthy, demonstrating significant improvements even without extensive pretraining or finetuning in the medical domain
* The clarity and comprehensiveness of the writing make the methodology, experiments, and results easily understandable
* The comparative analysis is included, benchmarking against current baselines and showcasing the proposed method's advantages clearly.

Weaknesses
* Considering LoRA is already a popular approach as a parameter efficient fine-tuning method, the novelty of method is limited.",1
282,"This paper presents a study in which Neural ODEs are used to simulate energy transfer processes in tokamaks.  The proposed models are trained using experimental data.  Validation of the proposed data-driven models is performed under various auxiliary heating conditions.

This paper is interesting and generally well-written.  I really like that the authors are using experimental data to train/validate their models, something that is not generally done in the literature.  I do feel that there is a bit of misbalance in the paper.  The very complex equations in sections 2.2-2.3 could go in an appendix.  I would recommend more detail about the architecture and how it was optimized / trained in the body of the paper, since this is for an AI workshop. and since you are showing a tremendous improvement by optimizing your model in Table 1.  There is too much right now in the Appendix - I would suggest moving some of the figures / results here into the body of the paper, since you should really be focusing on the AI/ML.

I cannot comment on the novelty of the proposed methods for the tokamak plasma application, as this is not my area of expertise.",1
283,"**Quality:**
The submission is of good quality, showcasing a well-thought-out framework (PC-X) aimed at addressing challenges inherent in deep clustering. The theoretical underpinnings are strong, and the paper does a commendable job of situating PC-X within the existing landscape of clustering paradigms.

**Clarity:** The paper is well-structured and well-written, making it easy to follow. The comparative analysis using Table 1 provides a clear picture of how PC-X stands relative to existing methods, although some definitions could have been articulated better for enhanced clarity.

**Originality:**
(a) PC-X, with its skip-connection module and unique optimization algorithm, presents a novel approach to deep clustering;
(b) The idea of making clustering centroids into legible exemplars through decoding is innovative and adds a fresh perspective to the domain.

**Significance:** The paper has the potential to further the discourse in deep clustering, especially around interpretability and efficiency.

**Pros:**
- Well-structured and well-articulated paper making it easy to follow.
- Novel framework (PC-X) with innovative components like the skip-connection module and the unique optimization algorithm.
- Rich theoretical analysis backing the proposed framework. Extensive experimentation against multiple baseline methods on several datasets.

**Cons:**
- Datasets used for experimentation are not very large or diverse, which may not fully demonstrate the universality of PC-X.
- Lack of a clear discussion on the limitations of PC-X, which could have provided a more balanced view of the framework.
- Some definitions, especially that of ""Universality"", are not clear enough, which might lead to confusion. The discussion on interpretability and efficiency could be more nuanced, and the claims could be better substantiated.",1
284,"Perhaps the more useful contribution of this paper is in leveraging GPT-4 to create synthetic data in niche domains that can be tailored for specific purposes (in this case, benchmarking models that have poor keyword overlap between the document and query).
However, the points regarding shortcoming of keyword based models is already very well known, but also in this case quite expected since the dataset is explicitly constructed to fool keyword matching. It would make more sense to not cast the retrieval model's performance as proof for a move towards embedding-similarity based retrieval (as that has been the case for many years now) but as proof that the dataset is interesting. If that is the intention, it is more beneficial to provide principles and details of the prompt used in the ChatGPT API that enabled the curation of this dataset, so that a practitioner can then apply such principles to their own use case. That would be a simple two page report detailing the challenges and innovations required and the iteration cycles that one may have to go through, along with simple strategies for checking the quality of the generated dataset.",-1
285,"**Explanation of paper:** This paper solves four benchmark PDEs (1D Poisson, 1D advection, 1D Helmholtz, 2D Darcy flow) using a variation of the physics-informed neural network (PINN) approach. There are two variations compared to the classic PINN approach. (1) Instead of using a neural network as the solution representation, this paper uses a linear sum of B-splines. Thus, the linear coefficients of the B-spline are the parameters to be updated instead of the neural network weights and biases. Splines have previously been used to replace the neural network in a PINN, e.g., [1,2], though it appears the approach here is different. (2) Instead of updating the parameters using a standard optimization algorithm such as gradient descent, the parameters are updated using a *learned optimizer*. This is similar to [3]. Compare page 3 of [3] to equations (3) and (4). Thus, the paper is applying meta-learning to the PINN framework, similar to [4,5,etc]. However, the type of meta-learning is different: previous works appear to have meta-learned loss functions and initial weights, while this work meta-learned the optimizer (see equation (4)).

**Novelty:** Papers do not have to be novel in order to be worthy of acceptance at this workshop. However, this paper explicitly claims that the proposed approach of learning an iterative algorithm to solve a PDE is “novel” and “new”. This is incorrect. Many papers, since at least 2019, have learned an iterative algorithm to solve a PDE. See [6,7,8,9]. 

Based on a literature review, I believe the novelty of this paper is in meta-learning an optimizer for the PINN framework of optimizing a PDE residual. It is possible that spline basis functions have not been used to replace neural network basis functions in the PINN framework, but I am not sure.

**Connection to traditional numerical solvers:** The first two paragraphs of section 2.2 explain the connection between traditional numerical solvers and this method. However, there are multiple incorrect statements in these paragraphs. The first sentence of section 2.2 says that
> Traditionally, numerical solvers ... iteratively [update] parameters $\theta$ based on the minimization of some criterion $\mathcal{L}_{PDE}$ (e.g. the PDE residual)

Iterative numerical solvers do not use the PDE residual to update the parameters $\theta$. Instead, they use a *weak* form of the PDE, derived by multiplying the PDE by each of the basis functions and integrating. This is an important difference, because it leads to an entirely different solution methodology. Using the weak form of the PDE leads to linear (or sometimes non-linear) systems of equations, while using the PDE residual leads to a non-linear optimization problem. Another incorrect statement is that traditional numerical solvers are iterative. Some traditional numerical solvers are iterative, but many (perhaps most) are not. Iterative numerical methods are used for elliptic PDEs, but hyperbolic and parabolic PDEs do not use iterative updates. A third incorrect statement is in the third sentence of section 2.2:
>As opposed to traditional methods, the iterative solver $\mathcal{A}$ is not specifically tailored or handcrafted to the given problem, but learned from the data.

Traditional iterative numerical solvers are not always tailored or handcrafted to the given problem. In some cases, they are. The Multigrid method is one example. In many cases, however, the goal is to solve a linear system of equations. Any method of solving a linear system (such as LU decomposition, for example) or non-linear system (such as Newton’s method) can be used. 

While these incorrect statements are not essential to the correctness of the paper, they reveal that the connection with traditional numerical solvers is not nearly as strong as the paper claims.

Essentially the only connection between this method and traditional iterative numerical solvers is that they are both iterative.

**Failure to identify the source of empirical gains:** Please read two papers: *Troubling trends in machine learning scholarship”* [10] and *Winner's curse: on pace, progress, and empirical rigor* [11]. [10] discusses four troubling trends, the second of which is
> Failure to identify the sources of empirical gains, e.g. emphasizing unnecessary modifications to neural architectures when gains actually stem from hyper-parameter tuning.

[11] discusses the same issue using different terminology:
> Looking over papers from the last year, there seems to be a clear trend of multiple groups finding that prior work in fast moving fields may have missed improvements or key insights due to things as simple as hyperparameter tuning studies or ablation studies.

[11] recommends standards for empirical evaluation that ""should be encouraged, rewarded, and ultimately required in empirical work"". The third recommendation is
> **Ablation Studies** Full ablation studies of all changes from prior baselines should be included, testing each component change in isolation and a select number in combination.

This paper claims that the empirical gains over baselines (see figure 1a) are from learning an iterative update (see equation (4)). This may be true. However, this paper does not provide enough evidence to deduce that it is true; it is possible that other factors (such as using B-splines) may be the source of empirical gains. To identify the source of empirical gains, an ablation study should be performed which tests each ""component change"" (meta-learning via equation (4) and using B-spline basis functions instead of neural networks) in isolation. It is possible that a B-spline basis representation alone would be sufficient to achieve the performance seen in figure 1a; it is also possible that using a neural network basis representation while learning an iterative update would also be sufficient to achieve the performance seen in figure 1a. Without an ablation over these component changes, it is impossible for the reader to determine what the source of empirical gains is.

**Additional comments:**
* Given that (a) learning to solve PDEs is not a novel idea, and (b) the iterative algorithms being learned are entirely different from iterative algorithms in traditional numerical solvers, the title is inappropriate and misleading. Changing the title should be a necessary (but not sufficient) condition for acceptance of this paper. I suggest changing the title to “Meta-learning the optimizer of physics-informed B-spline basis functions to solve PDEs”.
* In certain respects (such as the title, abstract, overall framing) I find the paper to be ostentatious (i.e., designed to attract attention rather than to accurately report the ideas and findings).
* Iterative methods are not typically used on the advection equation. I’m not sure using this as a benchmark problem makes much sense. 
* An advection problem with two dimensions (space, time) is usually considered 1D, not 2D.
* Is the Helmholtz equation being solved in figure 1b? I think it is, because figure 1b is identical to figure 4b in the appendix. In any case, you should clarify that in the main text.
* What PDE is being solved in figure 1a?
* Why aren’t plots like figure 1a included for every benchmark PDE? 
* ODIL [12] is a much stronger baseline than PINN (and possibly PINO) for these PDEs.


**Conclusion:** I think the concept presented in this paper -- meta-learning an optimizer for PINNs and/or physics-informed spline basis functions -- is of interest to the workshop, and could be worthy of acceptance. However, I have serious concerns about the accuracy of the paper. The paper claims to present a novel approach, but this is false. The paper claims to be inspired by traditional numerical methods, but essentially the only connection between the two methods is that one is iterative and the other can sometimes be iterative. The paper also combines two component changes without performing any ablation study, meaning that they failed to identify the source of empirical gains. I think this paper should be rejected.

Should future versions of this paper correct the three main concerns listed in the paragraph above, I would conclude that this paper would be deserving of acceptance in this workshop.

[1] Wandel, Nils, et al. ""Spline-pinn: Approaching pdes without data using fast, physics-informed hermite-spline cnns."" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 36. No. 8. 2022.

[2] Doległo, Kamil, et al. ""Deep neural networks for smooth approximation of physics with higher order and continuity B-spline base functions."" arXiv preprint arXiv:2201.00904 (2022).

[3] Li, Ke, and Jitendra Malik. ""Learning to optimize."" arXiv preprint arXiv:1606.01885 (2016).

[4] Penwarden, Michael, et al. ""Physics-informed neural networks (PINNs) for parameterized PDEs: a metalearning approach."" Available at SSRN 3965238 (2021).

[5] Qin, Tian, et al. ""Meta-PDE: Learning to Solve PDEs Quickly Without a Mesh."" arXiv preprint arXiv:2211.01604 (2022).

[6] Greenfeld, Daniel, et al. ""Learning to optimize multigrid PDE solvers."" International Conference on Machine Learning. PMLR, 2019.

[7] Luz, Ilay, et al. ""Learning algebraic multigrid using graph neural networks."" International Conference on Machine Learning. PMLR, 2020.

[8] Zhang, Enrui, et al. ""A hybrid iterative numerical transferable solver (HINTS) for PDEs based on deep operator network and relaxation methods."" arXiv preprint arXiv:2208.13273 (2022).

[9] Hsieh, Jun-Ting, et al. ""Learning neural PDE solvers with convergence guarantees."" arXiv preprint arXiv:1906.01200 (2019).

[10] Lipton, Zachary C., and Jacob Steinhardt. ""Troubling trends in machine learning scholarship."" arXiv preprint arXiv:1807.03341 (2018).

[11] Sculley, David, et al. ""Winner's curse? On pace, progress, and empirical rigor."" (2018).

[12] Karnakov, Petr, Sergey Litvinov, and Petros Koumoutsakos. ""Solving inverse problems in physics by optimizing a discrete loss: Fast and accurate learning without neural networks."" PNAS nexus 3.1 (2024): pgae005.",-1
286,"- The authors demonstrated how a two-step hierarchical diffusion model can generate anatomy-aware, high-fidelity 3D CT images.
- Generating anatomical structures along with the volume, conditioned on the radiology report, appears to be a promising approach.
- The paper is well-written and clearly explains the method.
- Figure 1 could be improved by providing explanations for each component.
- Extending the results to include higher-quality volume generation would help illustrate the trade-offs.",1
287,"Summary
The paper presents a novel method to improve fairness in machine learning models for electronic health records without using demographic data. It constructs a ""graph of gradients"" to identify underrepresented groups based on model gradient similarity. Weights are learned to increase the exposure of disadvantaged groups. Evaluated on diagnosis prediction tasks, this approach significantly enhances fairness metrics like equalized odds and disparate impact compared to prior algorithms. The paper argues for an interdisciplinary perspective spanning technical, medical, and sociological factors when examining algorithmic fairness in healthcare.

Strength
•	Proposes an innovative graph of gradients method to represent demographic groups and identify underrepresented populations for bias mitigation.
•	Theoretical analysis demonstrates gradients are more closely correlated with demographics than input features under reasonable assumptions.
•	Evaluation of two datasets shows significant improvements in fairness metrics equalized odds and disparate impact over state-of-the-art algorithms.

Weakness
1. The assumptions should be listed before the theorem, not in the appendix
2. The assumption that model accuracy and input features strongly correlate with demographic groups is quite strong and may not always hold in practice. The authors do not provide empirical evidence to support this.
3. The soft grouping method using a graph of gradients is interesting, but the authors do not provide much intuition or analysis into why this works better than prior methods.",1
288,"Need to explain in details why with distillation, the results improved with that large margin, which much higher than the baseline.",1
289,"In this paper, the authors address the hyperplane clustering problem in the presence of outliers. They introduce the Hyperplane Arrangement Descent (HARD) algorithms and provide a comprehensive theoretical analysis. In my view, this work represents a significant accomplishment.

Comments:

1. It would be beneficial to include specific details regarding the computation of $b_k^{(t+1)}$ and elaborate on their computational complexity. Additionally, a comparative analysis of the computational complexity of your proposed method with other approaches based on different loss functions would enhance the paper's clarity.

2. Figure 2 needs further clarification. Please define the x-axis to ensure its meaning is clear to readers. Furthermore, could you explain why the running time of the red lines is higher at $K=4$ than at $K=5$ in Figure 2(c)?",1
290,"Zebra introduces a probabilistic framework for modeling PDEs taking inspiration from the language model community in NLP.


**Strengths**:
- A new approach, from the prism of generative model, to train foundation model for PDEs.
- No explicit incorporation of PDE parameter values in the model.
- Yet another way to perform the *latent evolution* of PDE dynamics.
- Natural support for continuous (a.k.a. discretization-free) modeling.


**Weaknesses**:  
- No separate *validation* set. Hence, the *test* set is somewhat ""seen"" by the model.
- Generalization ability to unseen parameter distribution (OOD) is not tested.
- No experiments on 2D and 3D PDEs, making the generalizability of the proposed approach to higher dimensions uncertain.

**Questions**:
- For the benefit of the broader SciML community, will the codebase be made public upon acceptance?  

> We pretrain Zebra and a selection of neural operators/solvers on distinct families of PDEs, evaluating their proficiency in learning diverse dynamics.

- Were both the Advection and Burgers' datasets combined and a single Zebra model was trained? If yes, how was the specific PDE identified?

**Suggestions for improvement**:
- Make notations in Figure 1 consistent with the Problem Setting in Section 2 or vice-versa.",1
291,"**Summary**

This paper proposes a modified approach for NLU tasks called Recap Deliberate and Respond (RDR). Authors consider a traditional neural network approach that just combines embedding of the natural language input with an emdedding of relevant external subgraph and train a classifier model on top of this with cross entropy losses. The proposed RDR approach modifies this by adding two additional losses to the final cross entropy loss - a) paraphrase loss on text embedding b) graph embedding loss on graph embedding.

Experimental results on GLUE benchmark shows the proposed method slightly outperforms traditional approach on BERT, ROBERTA and ALBERT models

**Strengths**

1. Using paraphrasing loss and graph embedding loss for NLU is interesting
2. This paper is well organised and reasonably clear

**Weaknesses**

1. Limited experimental results and the improvement is less than 1%. Comparisons with other SOTA methods for GLUE will be helpful
2. Its not very clear how RDR addresses the limitations of existing works discussed in Introduction

**Questions**

1. How does the Language Model in traditional method differs from the Paraphrasing Model in RDR?",-1
292,"The authors extend nnUNet to a bounding box-based model that concatenates a binary mask of the bounding box into an additional channel to the model. They fine-tune nnUNet using this strategy on the SA-1B dataset (natural images) and MedSAM's provided training data, stemming from 11 medical imaging modalities. 

The paper is written in a clear and easy-to-follow way, and I did not find any typos or formatting mistakes. However, I believe that the paper is not in the challenge template since the padding on the left and right sides is different from the rest of the papers I had to review. I would advise the authors and meta-reviewers to check this for the final camera-ready submission. 

The paper is complete and presents all the needed details to reproduce the results, especially since nnUNet is widely used and requires little explanation to run such a pipeline. However, I am not familiar with the concept of patch-wise inference and the authors do not provide enough detail to understand how this actually works. How large is each patch? The authors state on page 4 that ""We only predict on a patch, which extends by half the patch-size around the bounding box prompt"". However, this is not clear enough, and could easily be elaborated in the form of an additional equation in the camera-ready paper.

For better completeness, the authors can also estimate the FLOPs and CO2 eq (for a single epoch and extrapolate for the whole training) and add them to Table 2 so that it fits the same details as the rest of the papers in the challenge paper track.

Overall recommendation:
I think that the paper has enough details to reproduce the training and evaluation results and lacks only small things that could be easily added in the camera-ready version. Hence, I vote for an acceptance of the manuscript.

Small comments:
Fig. 2: The PET example is barely visible. I would crop to the non-black part of the image and zoom-in so it can be seen what the predictions of the models actually are.",1
293,"The paper introduces an incremental few-shot object detection framework based on meta-learning networks. Specifically, the authors leverage the recent ONCE meta-learning network to learn class codes for new categories, enabling online addition of new classes for object detection without retraining. The paper highlights that training the meta-learning network alongside the detection network led to conflicts, resulting in limited generalization to new classes. To address this, the authors propose two strategies to enhance training effectiveness:

1. Utilizing Grad-CAM for coarse object localization in ImageNet,  significantly expanding the number of object categories and images during training to improve the meta-network's performance.
2. Freezing the detection network during the meta-training phase to retain the ability to detect base classes.

**Strengths**:

1. **Easy to follow**: The paper introduces an innovative approach to incremental few-shot object detection, leveraging meta-learning networks and class codes for new categories. This approach can potentially have significant practical implications.
2. **Clear Presentation**: The paper is well-structured and clearly presents the proposed framework, making it accessible to readers.

**Weaknesses**:

1. **Overlap in Training Data**: The potential overlap between ImageNet and COCO categories raises concerns about the effectiveness of the model in recognizing new classes. This issue needs to be addressed and clarified.
2. **Over-reliance on Class Codes**: The heavy dependence on class codes generated by the meta-network for detection poses potential challenges when the detection network struggles to extract features from new classes. The authors should explore alternative methods to mitigate this risk.",1
294,"**Summary:**.  
The paper explores a new approach to concurrently disentangling causal variables and determining the causal relationship between them. It draws inspiration from the work of Bengio et al. (2020), but diverges by focusing on the generalization gap instead of employing a meta-objective and adaptation speed.  

**Pros:**  
•	The proposed method addresses both learning a disentangled representation of causal variables and discovering their causal direction.

**Cons:**   
•	The evaluation is somewhat limited. Specifically, it remains uncertain how the method can be extended to more than two variables and larger benchmarking datasets. Additionally, it would be beneficial to see ablation studies on edge cases, particularly the impact of choosing conditional and marginal distributions on the condition of a small entropy gap in Proposition 2 (which lies at the core of the theoretical justification of the method)

**Detailed:**    
The proposed method presents an interesting solution for acquiring both disentangled (causal) representations and the causal relationships between them. It builds upon the concept introduced by Bengio et al. (2020), but simplifies the computations to a comparison of the generalization gap. Consequently, it eliminates the necessity for defining connection-wise structural parameters and employing REINFORCE-based gradient estimators. However, I do have some concerns about this work. 

Firstly, I find the evaluation (and hence the impact) of the paper limited. The method is designed solely for setups involving two observational variables, and it does not appear readily extensible to studies involving datasets with more variables. As a result, its usefulness in recovering causal directionality in large-scale practical applications is unclear. Furthermore, the only baseline considered is the work of Bengio et al. (2020). While this is a logical baseline given the similarities between both approaches, it's worth noting that the notion of meta-learning the structural parameters of a causal graph has also been explored in more expansive and efficient studies (e.g., [2] and [3]).

Secondly, if I comprehend correctly, according to Proposition 1 (and consequently 2), the method is capable of working only with interventions on the cause variable (i.e. the causal graph cannot change between the transfer and train distributions). Consequently, there are no assurances regarding its behavior when the transfer dataset is, in fact, an intervention on the effect, thereby breaking the dependence between observed variables. Simultaneously, according to Proposition 2, the difference in generalization gap is posited as a valid predictor if the delta entropy gap between variables B and A is ""reasonably small."" However, the authors only provide an intuition that such a statement should not be violated in real-world applications. The paper does not examine any real-world datasets or distributions (or their ""approximations,"" as encountered, for instance, in BnLearn, since it is difficult to request a ""real"" dataset), nor does it conduct ablation studies on potential edge cases that could lead to the violation of the aforementioned argument. I believe the paper could benefit from a more comprehensive analysis from this perspective.

**Questions:** How is σ(γ) defined in this approach?

**References:**.   
[1] Bengio, Yoshua, et al. ""A meta-transfer objective for learning to disentangle causal mechanisms."" arXiv preprint arXiv:1901.10912 (2019).   
 [2] Ke, Nan Rosemary, et al. ""Learning neural causal models from unknown interventions."" arXiv preprint arXiv:1910.01075 (2019).     
[3] Lippe, Phillip, Taco Cohen, and Efstratios Gavves. ""Efficient neural causal discovery without acyclicity constraints."" arXiv preprint arXiv:2107.10483 (2021).",-1
295,"This paper discusses the important problem of image quality assessment (IQA), which is essential to the evaluation of many computer vision applications. It brings forward that the isolation of model-centric and data-centric approaches impedes further progress in IQA, which is not well-addressed in previous works. The argument is supported by studies of existing IQA methods. It also proposes a novel IQA framework integrating model-centric and data-centric methods, which shows superiority compared to past works. The intuitions and discussions in this paper are interesting and motivating, and I believe they can call for more attention to this important problem as well as inspire more future research.

This paper mainly focuses on ""unconditioned"" evaluation of image qualities, but it'd be more interesting to also discuss ""conditioned"" evaluations, as they are widely used in a lot of tasks like image generation, novel view synthesis (e.g. NeRF), etc. For example, data-based metrics such as FID, KID, and model-based metrics such as PSNR, SSIM, LPIPS.",1
296,"It has been shown that rotation invariant algorithms are not optimal for sparse linear problems when $n<d$. This work shows that in the presence of added noise, the rotation invariant algorithms are sub-optimal even when $d<n$. This is done by establishing a lower bound for the Bayes optimal method for a rotationally symmetrized problem. The authors also show much better upper bounds for non-rotationally invariant for the same problem. Another interesting component is the analysis of gradient flow trajectories of popular optimization methods on the same problem. 

Strengths: This is mostly a well-written and well-motivated paper. I found the findings to be very interesting and insightful. The analytic trajectories of the continuous-time versions of a variety of algorithms in section 3 are strong contributions. The Appendix contains detailed theoretical results about upper bounds on EG, approximate EGU algorithms, spindly network, and priming methods.

Weaknesses: The main weakness is that the authors assume much is already known to the reader. For someone who does not remember details of EG or EGU algorithms, it would be very useful to give some intuition or remind the reader why some of these are non-rotationally invariant. 

Questions/suggestions: 

1)	Is it possible to move some of the theorems from the appendix to the main paper? I understand the need for brevity under space constraints, but I feel that even if one of two important theorems can be moved, it will give a more concrete picture of the differences between the errors.

2)	From Figure 2 c) it seems that EGU+/- gets bad as time grows. However, Theorem 8 shows the error upper bound only for T=Theta(sqrt(d)). I tried to follow through with the proof to see how much of it could be extended for a larger T but I was not successful. Some discussion on that (also for the other theorems) connecting to Figure 2c) would be useful. 

3)	Is there a typo in Eq (7) inside the square root?

4)	There are many short forms, LS, LLS, RFM, EGU, GD, etc. While some are obvious, it will be better if the authors write the full form the first time any of them show up.",1
297,"Contribution:
The authors made two contributions in their work: 1) clear definition of hallucination within the medical field, breaking it down into two types: Object Hallucination, which involves incorrect or fabricated details about objects, and Domain Knowledge Hallucination, which pertains to inaccuracies in medical knowledge or practices. 2) they developed a new tool called Med-HVL, designed specifically for the medical domain, to detect and evaluate these hallucinations.

Pros:
Its an interesting glimpse into the bias of LLM pretrained into a large amount of medical data. A nice extension of the work would be to systematically compare and benchmark those hallucinations across multiple dataset and models.

A few remarks:
- in the figure, gt caption and gt observation are the same. Is there a gt caption without irrelevant info that would not be the gt observation? it would be nice to have a different example in the figure
- ""Object"" in this context seems incorrect and can be confused with support device. Maybe a more suitable term would be anatomical structures?",1
298,"This abstract presents an approach to building and benchmarking an AI system trained on Common Factors Theory using NLP techniques. Using labeled data, the work aims to use synthetic and generative technologies to generate and validate rare user cases. However, the model/method details are not clearly stated.

Pros:
* Applying common factors in AI development is a relatively novel idea
* Data in use is comprehensive and potentially sufficient

Cons:
* Method detail is not clearly stated (model architecture, how training is done etc.), and how Common Factors is integrated/reflected is not clear from current writing
* What is the difference between this work and the work supervised to detect different common factors? It would need more work to distinguish the contribution of this work and existing works.
* Vague connection with foundation models",-1
299,"The paper presents a JAX-based sparsity library for machine learning research. JaxPruner provide concise implementations of popular pruning and sparse training algorithms with minimal memory and latency overhead. The Optax gradient transformations for implementing algorithms is interesting. The paper is well written with appropriate code snippets to elucidate usage. Minimization of memory and run-time overhead by compressing binary masks for representing sparsity and incorporation of N:M sparsity are important features to have. However, I still feel the coverage of various popular pruning baseline algorithms are still missing (eg. SNIP, GrasP, SynFlow etc) if the focus is research. I find the further experiments section very interesting and informative. Some typos need to be fixed immediately (eg. Section 6- Concusion -> Conclusion). Overall, it is an important tool for sparse community and I recommend acceptance.",1
300,"**Strengths**

- Novel Data-Driven Approach: The paper introduces a novel approach to simulate traffic at urban intersections using data-driven methods. The use of real-world data to train trajectory forecasting models is commendable, as it aims to reflect real-world complexities in traffic dynamics.
- Comprehensive Methodology: The methodology is thorough, encompassing data collection, statistical analysis, generation of prior trajectories, and trajectory refinement. The integration of Gaussian Mixture Models (GMMs) and deep-learning models like TrajNet++ for refining trajectories enhances the simulation's realism.
- Clear Visualization and Documentation: The paper includes detailed figures that illustrate the workflow and results effectively, enhancing understanding of the complex processes involved.
- Important potential use: the discussion of this work's future work of incorporating the model with graphics engines is a very important and valuable direction.

**Weaknesses**

- Topic of The Workshop. This work discusses the simulation of humans and traffic. However, the discussion of the role of humans in the traffic is missing. Will humans be important in this research direction? How will humans affect the traffic (an interesting multi-agents question)?
- Model Complexity and Computation Cost: The reliance on sophisticated models and high-end GPUs (like NVIDIA A100) might limit the accessibility of the proposed system for users with fewer computational resources.
- Generalization Concerns: While the simulation provides good results in a controlled environment, the paper does not thoroughly discuss how the system performs across various types of intersections or under different traffic conditions.
- Potential for Overfitting: Given the detailed customization of the models to specific datasets, there is a risk of overfitting. More robust validation using diverse external datasets could strengthen the findings.",1
301,"This paper introduces a novel finite state machine variant called Counting Reward Automaton (CRA), capable of modeling any reward function expressible as a formal language. This mitigates the limitations of existing approaches that they can only handle regular language expressions, whereas this work permits the use of unrestricted grammar. Hence, this framework can handle a larger set of tasks than the existing works. The authors have also demonstrated that this framework supports using LLM-based formal language definitions from natural language task descriptions.

Strengths:
* This paper is well-written and well-explained.
* The CRA automata is novel and can model reward functions expressible as recursively languages.
* This paper also represents a sample efficient learning technique.
* The framework also supports the use of LLM to translate the NL task description into a formal language.

Weaknesses:
* Even if this paper demonstrates a very strong theoretical analysis of the contributions. However, it has lack of empirical studies to showcase the benefits.
* Interested to see how ChatGPT can be used to generate formal language specification from NL? what are the limitations? Very less amount of details have been provided. What kind of quality has been performed over automatic FL generation using ChatGPT?",1
302,"**Main review**
This paper uses Gaussian complexity to derive generalization bounds that are rank dependent. Specifically, the authors first consider the per-layer Gaussian complexity and use Maurer's Chain rule to analyze it. The derived bound is on the Gaussian complexity is $O(\dfrac{\sqrt{h}\sqrt{r}}{\sqrt{m}}(\prod_{i=1}^LC_1^{(i)}\|W_i\|^2 + \sum_{i=1}^LC_1^{(L-i)}C_2^{(i)}\sqrt{r}\prod_{i=1}^L\|W_i\|^2 ))$, where $h$ is the width, $L$ the depth $C_1^{(i)},C_2^{(i)}$ are constants for each layer $i$.



The alternative analysis through Maurer's Chain rule is interesting. However, it is unclear whether the derived results improve upon prior work even when $L>r$. Looking at the equation above, we can see that if $C_1, C_2$ are equal, for example, to 2  the derived bound becomes $O(\dfrac{\sqrt{h}\sqrt{r}}{\sqrt{m}}(2^L+L\sqrt{r})\prod_{i=1}^L\|W_i\|^2)$, which is always larger than $O(\sqrt{\dfrac{L^3rh}{m}}\prod_{i=1}^L\|W_i\|^2)$.  According to [1] ""The constants $C_1$ and $C_2$ as they result from the proof are rather large,
because they accumulate the constants of Talagrand’s majorizing measure theorem and generic chaining"", which results in the contribution of this work being limited. 
 
[Above I rewrote eq. 5, which is used to derive the bound on the Gaussian complexity (please correct me if I missed anything).]


**Questions**

1. Could the authors clarify how they derive Theorem 2? 
2. Regarding the constant $C_1^L$, which is exactly this constant in the last sentence before sec. 4.5? 
3. In eq. 5 should $C_2, C_1$ have the indicators $i$ as well? 

[1]:Maurer, Andreas. ""A chain rule for the expected suprema of gaussian processes."" Theoretical Computer Science 650 (2016): 109-122.",-1
303,"**Quality:**
The submission demonstrates a methodical approach to understanding catastrophic forgetting in MLLMs through the introduction of the EMT framework. The empirical validation is well-executed with examinations of several open-source fine-tuned MLLMs and a deeper dive into fine-tuning LLaVA.

**Clarity:** The paper is structured in a manner that elucidates the problem, the proposed solution, and the evaluation method which enhances its clarity.

**Originality:**
(a) The introduction of the EMT framework appears to be a novel contribution to the field;
(b) The paper delves into an area that seems less explored in the context of MLLMs, which adds a degree of originality to the work.

**Significance:** The insights garnered from the study, particularly around the effects of fine-tuning, are pertinent and could be instrumental in guiding future work in MLLM fine-tuning.

**Pros:**
- Rich experimental design providing a robust empirical analysis of catastrophic forgetting in MLLMs.
- Introduction of the EMT framework as a novel method to evaluate catastrophic forgetting in MLLMs.
- The paper addresses a relevant and challenging problem in the domain, which could stimulate further research.

**Cons:**
- The work may benefit from a stronger theoretical foundation to support the empirical findings.
- The significance of the contribution may not be very clear or substantial, as noted, and is heavily skewed towards an empirical study rather than novel theoretical or practical contributions.
- A more detailed exploration of the EMT framework's post-processing methods and their implications could provide a fuller understanding of the evaluation process.",1
304,"The work ""Computational Pathology at Health System Scale – Self-Supervised Foundation Models from Billions of Images"" is an interesting report from the conducted experiments. The reviewer would like to claim that the problem stated by the Authors is of high interest to broader public (benchmark of recent Foundation Models on pathology dataset). The important thing is that the Authors trained their models with an extensive dataset (as it was claimed in the paper there was around of 3 billion images from around 423000 digital microscopy slides). The goal of the work is clearly given. However, the reviewer would like to raise two suggestions that need to be addressed before publication:
1. The first one is related to the description of the samples. It was claimed that all of them belong to 76794 patients - but no sufficient details about the patients are given. I mean information about the sex, race, age... etc. All these details can allow reader to better understand the approach (of course, I am totally aware that they could not have any alignment with the dataset itself but may have - as some of the illnesses are more probable in later stages of life).
2. I do not understand why huge amount of information is given in the form of supplementary material. I assume that all these subchapters need to be provided directly into the paper - not in the form of supplementaty material. It will be then easier to understand the whole idea as well as to compare the outcomes with the latest results.

The reviewer would like to claim that after all these corrections, the work is ready for publication.",1
305,"This paper proposes an active view selection method for NeRF. The authors propose to estimate uncertainty actively based on Hessian matrix of training parameters and then select next training views based on estimated uncertainty. Basically this is a good paper and the proposed method achieves good performance, while I have several minor concerns:

1. The paper requires further proof reading to avoid small typos. For example: (1) two “.” in “with their multi-robot systems.[6].” in Line 048, Page 1; (2) Mip-NeRF dataset should be Mip-NeRF 360 dataset in line 388, Page 6.
2. The authors claim that the proposed uncertainty estimation method is more efficient than previous method (line 064-067), while there is no corresponding experiments to prove that.
3. It would be better to provide qualitative comparison with CF-NeRF.",1
306,"This submission deals with learning PDEs using a recurrent neural network inspired by iterative solvers. Experiments with classical PDEs show the advantage of this method compared with existing methods such as PINN and PINO.

This is an important problem and very useful to speed up high-dimensional PDEs for simulations. The idea is natural and incremental. Also, the paper misses an important connection with existing work on “unrolled neural networks” for solving inverse problems that appear for example in imaging, see for example [1]. Unrolled neural networks also rely on unrolling iterations of classical optimization methods such as proximal gradient descent.

[1] Mardani, M., Sun, Q., Donoho, D., Papyan, V., Monajemi, H., Vasanawala, S., & Pauly, J. (2018). Neural proximal gradient descent for compressive imaging. Advances in Neural Information Processing Systems, 31.

more comments
Do you share the weights of the neural network across all iterations? What if you let the weights be independent across iterations. The results from unrolled neural networks were observing improved performance by variable weight training.",1
307,"This paper investigates practical hardware acceleration upon unstructured sparse training. Specifically, the authors offered a comprehensive analysis of the acceleration bottlenecks encountered by previous methods during backpropagation and then proposed a kernel-wise mask for grouping unstructured sparse weights, achieving effective acceleration during backpropagation. The efficacy of the proposed method is demonstrated through experiments on CIFAR and ImageNet. The reviewer acknowledges the contribution of this paper and also makes some suggestions as follows:

1. The author's analysis of GEMM is very thorough, which is highly appreciated. Nonetheless, I would like to raise two points. First, NVIDIA's sparse tensor core is implemented based on NHWC[1], so the T-mask itself devised for N:M pattern is acceptable. Moreover, the N:M sparsity of the network will not be applied to the situation where C0=3, which has been given in Nvidia's documentation, because it is inherently unsuitable. Secondly, I would like to point out that the authors' mentioned inapplicability of T-mask under NCHW situation can be overcome using a different, recently proposed BI-Mask[2]. Including a discussion around this might make the paper more detailed.
   
2. The kernel-wise mask is very innovative and easily understood, and its design thought that integrates hardware design is quite reasonable. It would be a significant contribution to the field if the author could open-source the related acceleration code.

3. On ImageNet, the authors mostly compared PAI methods. It would be better to compare with DST methods because accelerating training on ImageNet is more critical than smaller datasets like CIFAR. Even if the performance is not as good as DST, it can still show the user a trade-off between training acceleration and performance.

[1] Nvidia a100 tensor core gpu architecture. https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/nvidia-ampere-architecture-whitepaper.pdf, 2020
[2] Bi-directional Masks for Efficient N: M Sparse Training. In ICML, 2023.",1
308,"This paper uses an ensemble of different SAM frameworks to iteratively train the modaltily-agnostic framework. The efficiency of the inference phase is optimized by exporting the model to ONNX format for lightweight inference.

Comment:
1. My major concern is the training data. As stated by the authors, they only train and fine-tune both LiteMedSAM and EfficientSAM with only PET and Microscopy images, which is insufficient compared to the whole dataset provided by the challenge.
2. The inference time is confusion. As EfficientSAM used 1024 pixels for input resolution, inference with this large image should result as higher inference time than reported in Table 6, not to mention they are the combination of multiple framework (MedSAM, LiteMedSAM, EfficientSAM)
3. Why the reported results of Pytorch and ONNX is so different, as the ONNX models are quantized, the decrease in results is expected, but here it is higher in some modalities.",-1
309,"(1) In the paper under review, the authors consider the problem of stochastic convex optimization with Lipschitz loss and address the questions raised by Feldman (NeurIPS, 2016), Amir, Koren, Livni (NeurIPS, 2021), and Koren, Livni, Mansour, Sherman (NeurIPS 2022) concerning lower bounds on the excess risk of gradient descent and stochastic gradient descent. In particular, if the parameter dimension $d$ is of order $\Theta(n T + n^2 + \eta^2 T^2)$, they provide an example (Theorem 1) when the excess risk of the GD estimate (with a fixed step size and $T$ iterations) is $\Omega( \min\{\eta \sqrt{T} + T/\eta, 1\} )$. When $T = n$ and $d = \Theta(n \log n + n^2 + \eta^2 n^2)$, a similar lower bound holds for the excess generalization error of SGD (see Theorem 2). This means that one needs at least $\Omega(\sqrt{d})$ samples to reach a nontrivial error.

(2) The authors note that the established lower bound $\Omega(\sqrt{d})$ is weaker than the sample complexity $\Omega(\sqrt{d})$ for a general ERM (see (Feldman, NeurIPS, 2016)). However, Theorems 1 and 2 significantly improve over Amir, Koren, Livni (NeurIPS, 2021), and Koren, Livni, Mansour, Sherman (NeurIPS 2022), respectively.

(3) The paper is well written. The authors spend much efforts to put the problem of interest into the context and describe main ideas used in the previous works. They also overview main steps in the proofs of Theorem 1 and 2. I find this important, because the appendix is quite long and I could not check it carefully during the review period. I only have a couple of minor remarks listed below.

(4) The authors mention a follow-up work (Livni, 2024) where the author proved a stronger $\Omega(d)$ lower bound on the sample complexity of GD and bridged the gap between the performance of GD and ERM. However, Livni (2024) was inspired by the ideas of the present paper. For this reason, I think that the follow-up result of Livni (2024) does not belittle merits of the present work. Besides, the question whether a similar bound holds for SGD is still open.

(5) There is a line of research studying the performance of ERMs and GD in the case of strongly convex and exp-concave losses (see, e.g., (Koren, Levy, NeurIPS, 2015), (Klochkov, Zhivotovskiy, NeurIPS, 2021), (Puchkin, Zhivotovskiy, COLT, 2023)). Is it possible to establish similar lower bounds in these scenarios?


Minor remarks.

(i) The expressions $1/\eta T$ and $1/\eta n$ are slightly confusing (see pp. 3, 4, 6, etc.). I would replace them by $T/\eta$ and $n/\eta$, respectively.

(ii) Please, mention that $\mathbb B^d$ in Theorems 1 and 2 stands for the unit ball in $\mathbb R^d$. This notation was not introduced before.",1
310,"**Summary**:

The authors present comprehensive work towards building a Foundation Model for computational pathology. They motivate the need for an FM in pathology, providing a background of existing work in the field. They present three models based on the Visual Transformer Architecture combined with two SSL algorithms, DINO and MAE.  They have compiled a significant dataset for the pretraining of their FM using SSL and perform benchmarking on multiple downstream tasks. Their approach shows higher AUC for most tasks over the baselines they have used.

**Pros**:

- The models proposed by the authors showcase a clear superiority in performance to the baselines.
- The authors have collected an impressive amount of data pre-training their FM, alluding to their collected dataset being an order of magnitude larger than any other data collected in the field.
- The authors have done a good job of investigating the training behavior of their models, and have indicated potential next steps for extending their work, all of which I agree with. 
- I am glad the authors have discussed open-sourcing their model, as I view their data collection and FM as valuable contributions to the field of pathology.

**Considerations**:

- Can the authors provide some reasoning regarding the generally poor performance observed across the proposed models and baselines for Task 6: `Institution 2
lung cancer immunotherapy outcome prediction`? It appears that this dataset has the largest label imbalance across the different tasks the authors are testing for. Could that be the reason? 
- Authors use validation AUC to indicate performance, but AUC as a metric captures an aggregate performance of the model across different operational thresholds. When operationalizing an FM for a clinical setting, one often faces the dilemma of considering the ideal operational threshold of classification (especially in the binary case which is the case with a lot of the downstream tasks the authors test their models on). This is a minor nitpick, and maybe something the authors can show in supplementary material. However, I would be interested in the tradeoffs their FM makes on sensitivity vs specificity at a given threshold for the various downstream tasks.
- It is interesting to note that ViT-large with MAE performs worse in most cases than the two ViT models trained with DINO (in three cases, worse than the baseline). Can the authors comment on why they think this is? Did they explore ViT-large with DINO? If not, could they comment on why?
- The authors have provided multiple examples of SSL models pre-trained on pathology data, could they comment on why they didn't use some of those methods as baselines along with ResNet50?

**Quality**: 

The overall quality of the paper is good. 

**Originality**:

The authors pre-train their models on a very large corpus of pathology data, which they indicate is larger than any corpus of pathology data collected before. While the authors have used some off-the-shelf methods like DINO for their SSL strategy, the scale of the data they have pre-trained their models on encourages me to believe in the novelty of their SSL approach. This is further reflected by excellent performance in downstream tasks with their proposed approach. However, I am a little concerned with the lack of variety in their chosen baselines, I would like the authors to add some more baselines that use SSL as a pre-training strategy to firmly indicate the superiority of their SSL approach.

**Significance**:

The authors' contributions to the field of pathology with their FM and their collected corpus of data could potentially be very significant for the field of pathology. The authors have correctly identified a list of follow-up questions based on their approach which could further help assert the significance of their FM if they are answered. 

**Miscellaneous Comments**:

- Could the authors elaborate a little more about GMA, as this is not a method I am familiar with? My assumption was the spatial distribution of the tiles of a single slide would be necessary for the downstream prediction of the slide as a whole, since you do not have tile-level annotations.  Yet. the authors state in benchmark training that GMA does not consider the spatial distribution of the tiles in its prediction. I would appreciate it if the author clarified why GMA's property of not considering the spatial distribution of tiles works here.",1
311,"The paper studies the relation between (single test point) transductive learning (which concerns in-expectation performance guarantees for permutations of n+1 fixed examples) and PAC learning (which concern high-probability performance guarantees from i.i.d. samples).  Such relations are well known in the realizable case (with a sharp transductive-to-PAC transformation appearing in the recent work of Aden-Ali, Cherapanamjeri, Shetty, and Zhivotovskiy, 2023).  The main contribution of this work is extending this relation to the agnostic setting: effectively providing a confidence-amplification tool for converting in-expectation epsilon excess error guarantees into high-probability 1-delta guarantees of excess error O(epsilon), at only the expense of an additive (1/epsilon^2)log(1/epsilon*delta).  The result holds in an abstract setting, with general label spaces and bounded loss functions.

I believe this result is interesting, and will be a nice addition to the learning theory toolbox.

The actual technique is essentially similar to that of Aden-Ali et al. from the realizable case, based on applying the in-expectation learner to a sequence of prefixes of the data, and constructing a final predictor based on the resulting set of hypotheses (e.g., the simplest strategy for this is to construct a randomized predictor that uniformly samples from these hypotheses at test time, though they also discuss constructing non-randomized predictors which select one hypothesis via a validation set).  The analysis, though rooted in the arguments of Aden-Ali et al., is more nuanced than the realizable case, in several ways that make this a non-trivial extension (for instance, being careful not to incur multiplicative increases in error rate, and accounting for different competitor functions for the different prefixes).

A second contribution is an analysis of transductive agnostic learning for the special case of binary classification.  In this case, they argue that a discounted edge density of the agnostic one-inclusion graph is bounded by O(\sqrt{n*VC}), via a connection to the empirical Rademacher complexity.  This translates into an expected excess error O(\sqrt{VC/n}) in the agnostic transductive setting, which matches the known optimal guarantee for the i.i.d. setting.

Altogether, I believe the results would be nice to have in the published literature, as they should be useful for future work on agnostic PAC learning in certain settings where there is ongoing development (e.g., the multiclass setting).

Comments for the authors:

- The paper is citing Asilis, Devic, Dughmi, Sharan, and Teng (2024) as proposing the agnostic one-inclusion graph predictor.  But actually this is a well-known idea introduced much earlier in the work of Phil Long (1999) ""The Complexity of Learning According to Two Models of a Drifting Environment"".  (indeed, among some of us in the community, orientations achieving O(\sqrt{VC/n}) excess risk have been known for some time, though I believe your paper will be the first appearance of this in a publication)

- It is mentioned in a couple places (e.g., page 3) that the transductive setting was first proposed and studied by Haussler, Littlestone, and Warmuth (1994).  But in fact it originates in the work of Vapnik and Chervonenkis who studied it in substantial detail (in both realizable and agnostic settings, both in leave-one-out type guarantees and high-probability variants); e.g., see their 1974 book, or Vapnik's 1982 or 1998 books.

- An important natural comparison to include is techniques for online-to-batch conversion, which are essentially based on similar martingale-type concentration arguments for applying a learner to prefixes.
See for instance the literature rooted in the article ""On the Generalization Ability of On-Line Learning Algorithms"" by Cesa-Bianchi, Conconi, and Gentile (2004).

- In Theorem 2, is the epsilon(n) in the log a typo?  i.e., should it just be epsilon?",1
312,"This works uses conjugate kernel (CK) as an efficient approximation of neural tangent kernel or NTK when the latter is used to increase the accuracy of physics-informed deeopnets in operator learning. Using two examples on Burgers’ and wave equations, the authors show that using CK, while insignificantly affecting the accuracy of the model, can reduce the training times (compared to cases when NTK is used). 

The main idea of the paper is to use the Gram matrix of the Jacobian of the DNN with respect to its last layers’ parameters. This matrix is used to tune the coefficients of the different terms that appear in the loss function (data loss terms and PDE residuals) of a PI-DeepONet. The contribution of this paper is to use eq. 8 instead of eq. 7 for updating the weights. 

I do not believe the paper makes sufficient contributions to the field to warrant its presentation in this workshop. This is especially the case since the results section lacks rigor. It is unclear if this method can be scaled up to cases where, e.g., the PDE has 3D spatial variables or has multiple outputs (e.g., the navier-stokes equations). It is also unclear why the authors are comparing their approach to a fixed-weight, i.e., to be fair, you can compare your approach to an adaptive weight scheme that is not based on NTK or CK (e.g., based on the moving average of the gradient magnitudes which are already available during training).",-1
313,"This paper studies the latent space of StyleGAN, a family of GAN-based generative models. Attributes editing by modifying the latent code of StyleGAN is an important task while existing works can hardly edit an attribute without other undesired changes. This paper tries to understand if this is because of the intrinsic limits of the entangled latent space, or, just because the existing works are not good enough at disentangling. They hypothesize that a low-rank feature space can be extracted from the StyleGAN high-dimensional feature space, where universal editing directions can be reconstructed from *micromotions*. Empirical results verify this hypothesis and show that the low-rank subspace can be used for high-quality editing.

Pros:

1. GAN-based generative models have shown impressive results in generation and editing. The understanding of it is relatively under-explored. This paper adds new insights in this track.

2.  The proposed low-rank subspace analysis is technically sound and interesting to me.

3. Empirically, the results support the proposed hypothesis and show better results of using it for high-fidelity editing over other approaches.

4. The paper is well-written, logic clear and neat.

Cons:

1. One concern is that only StyleGAN-v2 is evaluated, while the paper actually attempts to answer a question for the general StyleGAN family. I wonder if the conclusions found on StyleGAN-v2 can generalize to other StyleGAN models.",1
314,"This manuscript proposes a new method for high-dimensional Frechet SDR by augmenting a weighted inverse regression ensemble with a nonconvex penalty. Overall the reviewer finds this paper easy to follow, and the contributions are clear, hence would like to recommend a “clear accept”. Several minor comments:
1. In line 61, perhaps the authors can consider using a single \cite{} to contain all bibs, so that the citations will appear as [16-27].
2. The reviewer could be wrong, but the formulation in equation (4) looks very similar to a sparse dictionary learning problem. More precisely, for each input data vector $(x_i,y_i)$, we want to use at most $d$ elements $x_i$ to represent $y_i$. The reviewer thinks it would be great if the authors could elaborate more on the connection between the proposed objective function with the sparse dictionary learning problem (especially in the non-convex optimization setting). Note that there is a vast number of papers in the sparse dictionary literature if the authors would like to add some related papers, perhaps the authors could use [1] as a potential starting point. But feel free to ignore this suggestion, if the authors find this suggestion not relevant.

[1] Zhang, Yuqian, Qing Qu, and John Wright. ""From symmetry to geometry: Tractable nonconvex problems."" arXiv preprint arXiv:2007.06753 (2020).",1
315,"This paper applies the  Generative Pre-trained Transformer (GPT) model for photoplethysmography (PPG) signals. This is interesting and valuable. The point of using a logit-Laplace loss, instead of a MSE loss to train the model is also very insightful. My main concern about this paper is how can we make sure the converge when only using 5% of the data. We know transformers are data-hunger architectures. What is the limitation of such a model? As the paper mentioned in the future they will train the model using more data, I assume we will get the answer later. In general, this is an interesting and valuable paper for PPG-related tasks.",1
316,"The paper presents a hierarchical volumetric text to image model. The authors integrate a use of mask annotations to stabilize the generation process to improve generated results. The model is trained on a custom dataset with pseudolabeled anatomical annotations. The metric scores on the custom dataset seem rather low thus some reference values to set the methods into perspective might be helpful. Additionally, it would be great to see the individual impact of each considered mask in the process. What happens when omitting what?
Overall the idea seems nice and interesting and as such i tend towards accepting the paper.",1
317,"This paper explores the intrinsic properties of GAN hermitian spaces. The authors demonstrate that subtle movements can be represented in low-rank spaces derived from StyleGAN latent space. These micromotion features are decoded using short text or video clips as reference points. Besides, this micromotion knowledge can be transferred to different face images, even from diverse domains like paintings and sculptures. Yet, this work is great, a few questions arise:
(1). First of all, the authors have only experimented on StyleGAN-V2, and I think the generalizability of the method should be verified on more StyleGAN families, perhaps even on diffusion models.
(2). The article shows extraordinary generation results that demonstrate excellent micromotion decoupling and manipulation capabilities, but there is a little bit of blurring on the generated images in Figure.5 as well as in the upper part of the figure in Figure.7(a), Is this imperfection a natural outcome of the method, or could there be room for refinement?
(3). The experiments and supplementary experiments show some remarkably good generated results, but the presentation of the results in Figure.11 seems to be a bit blurry and distorted, could it be replaced with a clearer one?",1
318,"Albeit proper references are provided about previous work on related topics, the reader should be provided with a self-contained description of the mathematical backgrounds, which the reviewer finds insufficient in the current version of the paper
For instance:
1. What is the functionality of the learnable context vectors? Why are they important? 
2. What is the formula of the regularization function context? Are there multiple definitions available? Any guidelines on how to choose one over the other? 

Additional discussions that the reviewer considers important, but are missing from the discussion about the context vectors: 
1. How is the size of the context vectors chose? I see that you have a discussion about this in the appendix, but this is a serious limitation of the approach that should be mentioned in the main text as well. 
2. Is it possible that trajectories provided by different environmemnts eventually collapse onto the same values of the context vector? What would this imply? No details are provided about this neither in the numerical results nor in the conclusions",-1
319,"## Summary

This paper compares three Genomic Foundation Models (HyenaDNA Tiny, GenaLM, and Nucleotide Transformer) against each other on the ClinVar dataset for gene sequence classification. Then the best model is compared against the state-of-the-art traditional genomic model (SNPred). I do not work in the genomics space; I work in adjacent domains (healthcare, language models), so I can see that the comparisons the authors are trying to make may be valuable to other genomics researchers. However, this manuscript reads more like a review paper than one describing new research. It is missing key details of experiments and a clear description of fine-tuning and evaluation datasets is missing, making it hard to interpret results.

## Pros
* Well written detailed description of prior work in this domain
* Detailed metrics comparison of transformer-based foundational models in genomics against state-of-the-art traditional models like SNPred.
* tSNE embedding visualization helps visually explain performance gap between models

## Cons
* Too much of the manuscript is focused on introduction/background/related work and too little on experiment and discussion. Some of the background is helpful to readers not in the genomic space, but overall should be reduced by at least 1 page to make space for experiment and broader discussion of results. Otherwise, this submission reads like a review paper rather than an original experiment paper.
* Nit pick: Formatting of text in Table 1 is suboptimal. To make it more readable, consider using abbreviations and describe abbreviations in table legends.
* Nit pick: Formatting of Table 3 is odd. There are 6 significant figures reported for SNPred and the other models, but only 2 significant figures for Nucleotide Transformer. Be consistent.
* Table 2 reports comparison of three Genomic Foundational models using Accuracy, Precision, Recall, and then the best one (Nucleotide Transformer 250M) is compared against SNPred in Table 3 using AUC ROC and AUC PR.  It seems like it would be more straightforward and clearer to just report AUC ROC and AUC PR for all 3 models in a single table along with SNPred.
* Authors describe that 10 models were fine-tuned, but then only report a single result per model. It is unclear whether there was further model selection from the 10 models or if evaluation results were aggregated, etc.
* Larger HyenaDNA models were not compared due to compute resource constraints.
* Surprising to me that Nucleotide Transformer 500M performs worse than Nucleotide Transformer 250M and there is no discussion of why this is the case.
* Fine-tuning and Evaluation datasets are not well described. Would recommend a table that describes pertinent statistics for each dataset and split that is used.",-1
320,"Summary:
- This position paper investigates the role of language models and neurosymbolic systems for solving ARC. It proposes to use a hybrid approach, combining the strenghts of LLMs and math-inspired neural architectures.
Further, it suggests using data augmentation in order to advance the abstraction and reasoning abilities of neural models.

Strengths:
- Summary of current approaches at solving ARC
- Advocation for a combination of neural networks with the rigor of mathematical logic

Weaknesses:
- While this position paper includes a brief summary of current and potential future approaches of solving ARC, it does not really provide any novel insights (compare (Bober-Irizar and Banerjee 2024)).
- Human collaboration:  On one hand this is not the point of ARC (see Chollet 2019). On the other hand, the potential for improvement would be quite small, as humans are already very good at solving ARC (LeGris, Solim, et al. ""H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark."" arXiv preprint arXiv:2409.01374 (2024)).
- Data augmentation: While data augmentation might certainly help with ARC, it is unclear if it actually helps neural models in achieving the generalization required to solve ARC, or if it only tries to move the test-tasks in-distribution.
- The idea of combining neural architectures with math-inspired principles is interesting, however not novel.
(Wang, Ruocheng, et al. ""Hypothesis search: Inductive reasoning with language models."" arXiv preprint arXiv:2309.05660 (2023)) and (Barke, Shraddha, et al. ""HYSYNTH: Context-Free LLM Approximation for Guiding Program Synthesis."" The Thirty-eight Conference on Neural Information Processing Systems (2024)) and (Kalyanpur, Aditya, et al. ""Llm-arc: Enhancing llms with an automated reasoning critic."" arXiv preprint arXiv:2406.17663 (2024)) have already proposed and evaluated similar ideas.
- Deep-learning guided program synthesis has been used quite extensively in the latest ARC Prize 2024, so the ideas have been known for a while (Chollet, Francois, et al. ""ARC Prize 2024: Technical Report."" arXiv preprint arXiv:2412.04604 (2024).)

Relevant papers not properly cited, e.g. 
 - Bongard Problems (M. Bongard. Pattern Recognition. Spartan Books, New York, 1970.)
 - AlphaGo (Silver, David, et al. ""Mastering the game of Go with deep neural networks and tree search."" nature 529.7587 (2016): 484-489.)
 - DreamCoder (Ellis, Kevin, et al. ""Dreamcoder: Bootstrapping inductive program synthesis with wake-sleep library learning."" Proceedings of the 42nd acm sigplan international conference on programming language design and implementation. 2021.)
 - Early works on using language/LLMs for solving ARC, e.g. (Camposampiero, Giacomo, et al. ""Abstract visual reasoning enabled by language."" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.) and (Acquaviva, Sam, et al. ""Communicating natural programs to humans and machines."" Advances in Neural Information Processing Systems 35 (2022): 3731-3743.)

Overall, many of the points brought up in this position paper follow the work by (Bober-Irizar and Banerjee 2024), with limited novelty in its ideas.",-1
321,"The paper explores MCTS-based approach for automatically generating process supervision data. It would be better if a few things are clarified:

(1) What does 'm' stand for in Equation 1?

(2) Why wasn't the proposed approach compared to other MCTS-based approaches like: 

Luo, Liangchen, et al. ""Improve Mathematical Reasoning in Language Models by Automated Process Supervision."" arXiv preprint arXiv:2406.06592 (2024).
Wang, P.; Li, L.; Shao, Z.; Xu, R.; Dai, D.; Li, Y.; Chen, D.; Wu, Y.; and Sui, Z. 2024a. , Math-shepherd: Verify and reinforce llms step-by-step without human annotations. (comparison with this will help evaluate the efficacy of the reward score function proposed)

(3) Process Supervision data size - what is the size of data used for training? How many problems from Math or GSM 8k was used? I suppose two sets of training data is used for each dataset - Math and GSM-8K.",1
322,"The paper studies online imitation learning in an MDP. At each step, the learner must either take the optimal action, or query an oracle that supplies the optimal action (possibly with noise). The goal is to query the oracle as infrequently as possible.

The problem statement is clean and well-motivated, and the results are reasonably comprehensive. The most significant improvement over previous work in my opinion is that the results hold in an online setting, rather than requiring independent trajectories from the environment.

In terms of weaknesses, there are still large gaps between the upper and lower bounds for settings where the oracle is noisy. Also, the proof techniques rely heavily on existing methods in active learning, but I am not overly concerned about the lack of novelty, as I think the results fill a missing gap in the literature.

The authors should strongly consider providing more of the intuition behind the algorithms. While the first algorithm is straightforward enough, ReliableApprentice is difficult to parse, and chasing down the references did not help. Otherwise, the paper is quite well-written and easy to follow.

Also, I think that there is a missing conjecture? Conjecture 18 asks whether the query complexity can be reduced to match the lower bound in Theorem 12, but the lower bound in Theorem 9 has also not been matched, so why not make a similar conjecture about it?",1
323,"## Summary
This paper attempts to address the important problem of training fair and unbiased Machine Learning (ML) models in clinical settings, when some demographic information about individuals or groups is not available due to privacy or other reasons. To mitigate this, the authors propose to use the model gradients as a method for grouping samples together, based on the intuition that the gradients may carry information about the unknown demographic features. They construct a graph where samples with similar gradients are grouped together, and use it to learn their weights, within the context of an adversarial weighting algorithm. They run experiments on two different medical datasets, and show that their method can improve fairness significantly without much loss in accuracy.

## Strengths
- The idea of using the gradients as a (soft) grouping mechanism, and the intuition that they may be correlated with the unknown demographic features is interesting. The authors also attempt to justify this intuition theoretically, using concepts from information theory.
- The empirical results of their resented adversarial weighting algorithm seem promising, and are competitive against the baselines tested.   

## Weaknesses
- In my personal view, the biggest weakness of the paper is clarity: some descriptions are dense, and some parts are hard to follow. The paper would benefit a lot from addressing this. For example, in section 3, notations such as U(h) are suddenly introduced in the text, without explanation. Similarly, in section 4, the method description is not easy to follow. Moreover, it would also benefit the paper to briefly explain the related background material, such as e.g. the Rawlsian Max-Min fairness objective, or some prior methods.
- The experiments presented are on small Neural Networks, although the emphasis of the symposium is on Foundational Models.

 ## Overall Assessment
Overall, I believe the ideas introduced in the paper are valuable, and the empirical results promising. My greatest concern is the clarity of the presentation, and I'm willing to increase my assessment if that is mitigated.",-1
324,"Strength:
The method outperfomrs state-of-the-art models: the method yields significantly better performance on diagnois production and heart failture prediction for two MIMIC datasets. 


Weak points and suggestions: 
1. Missing important related work on bridging ICD code with LLM:
(1) ""DRG-LLaMA : tuning LLaMA model to predict diagnosis-related group for hospitalized patients""
(2) ""CPLLM: Clinical Prediction with Large Language Models""
2. Unclear writing:
(1) This sentence is confusing to read: “But there is still a significant gap between the primary language, i.e., natural language, with the model’s hidden represntation” 
(2) In the 'Performance of Memorization' section, what is the sample size? How many ICD-9 codes were assessed? 
3. Presentation error: 
(1) Missing citation: ""The events are normally presented in medical code format, such as ICD-9 disease codes, with a large candidate space to choose from (13,000 disease candidates in ICD-9) (?)""  
(2) Figure 1 is difficult to read and could benefit from additional labeling.",-1
325,"The authors present a very interesting idea for this competition and accompany it with a well-written and exhaustive report. 

I specifically want to highlight the following contributions: a detailed investigation of the training data, well-explained failure cases of MedSAM, a very insightful analysis of an approach for interpolation for 3D images, and a good presentation of the results.  

There are no problems with this submission to the workshop, and I believe it fulfills all the requirements for the competition's write-up.

### Additional Feedback

* The reference to LiteMedSAM at the start is missing (but is provided later in Section 2.8.
* In some cases, like in Section 2.7., the authors mentioned that classical approaches did not work for a certain modality. I think it would still be highly insightful to share which approaches the authors tried but did not work! 
* ""For all 2D images, except the ones predicted by MedSAM, we keep the largest connected component and fill all the holes within it."" 
 This is very interesting, but it is not given any attention in the results. Did this make the performance much better? Do the authors, by chance, have an ablation study of this? 
* In the provided code, the README could be updated to reflect your specific code changes and contributions. 
* While reading the abstract and introduction, it seemed to me that your final submission would consist mostly of a traditional non-deep learning approach, but the opposite was the fact, as seen in Table 1 or Figure 1. I suggest reiterating the abstract and introduction to reflect this so that both do not oversell the results or confuse the reader.",1
326,"This paper studies the sample complexity of aggregations of proper learners in multiclass learning. The authors proved that for hypothesis classes with finite graph dimension $d_G$, the majority vote of ERMs on subsets selected by some algorithms achieves a sample complexity of $O((d_G+\log(1/\delta))/\epsilon)$, which matches the lower bound they show for any majority vote of ERMs on certain classes of graph dimension $d_G$ and DS dimension 1. They also improve the lower bound of a single ERM on such classes. Finally, they prove the existence of hypotheses classes of DS dimension 1 for which any learner that achieves error strictly below 1/2 cannot be expressed as any function of finitely many proper learners. 

Pros: The paper is organized and presented clearly. The problem studied is important in multiclass learning. The results are original with considerable contribution to the understanding of proper learners in multiclass learning. 

Cons: I think the results and analysis for the two lower bounds (sec. 3.2 and sec. 4) are more interesting and significant. It would be better to move the lower bound sections to the front of the upper bound section in the first 12 pages. The proof for the upper bound is quite standard, so I believe it can be moved to the end of the paper so that the first 12 pages can be used to present the derivation of the lower bounds and the concept of properness numbers. 

Is there a typo in Lemma 6? I think the RHS of the inequality should have $\bar{\mathcal A}$ instead of $\mathcal A$.",1
327,"Scope:
The manuscript deals with narrow AI for answering questions over domain specific Knowledge graph. The motivation of the research is to devise a way to reduce hallucinations from LLM responses, find a Knowledge graph for question answering system (KGQA) to increase the factuality of LLMs using logical programming.

Strength:

•	The experimental results were reported on standard MetaQA dataset. The MetaQA dataset consists of questions that require reasoning over a given knowledge graph having 134,741 facts and 9 relation.
•	Reduce hallucinations from LLM responses, find a KGQA to increase the factuality of LLMs using logical programming.

Weakness:

1.	There is little novelty in the manuscript. Please justify the novelty of your work. 

2.	Architecture diagram of the proposed methodology is missing. The author is suggested to draw the architecture diagram highlighting the contribution of author in existing area of research.


3.	To further validate the performance of system MFAQ dataset may be used along with MetaQA. MFAQ is a multilingual FAQ dataset publicly available. It contains around 6M FAQ pairs from the web, in 21 different languages. Although this is significantly larger than existing FAQ retrieval datasets, it comes with its own challenges: duplication of content and uneven distribution of topics. 

4.	How your work is different from Mihindukulasooriya, N., Tiwari, S., Enguix, C.F. and Lata, K., 2023, October. Text2kgbench: A benchmark for ontology-driven knowledge graph generation from text. In International Semantic Web Conference (pp. 247-265). Cham: Springer Nature Switzerland.

5.	The mathematical representation of the manuscript is weak. Refine the equations and add more logical representations of your work.

6.	Author need to further elaborate their findings with evaluation measures like BLEU METEOR, ROUGE, Exact Match, accuracy (A), hallucination rate (H), and missing rate (M) for better evaluation of the proposed work.

6.	The paper is not written well, there is lack of clarity, cohesion, and connectivity. Improve the writing of paper to help the reader to understand the methodology. 

7.	The related work section is  on weaker side and  author is suggested to update it with recent research paper as listed below:

I.	Mihindukulasooriya, N., Tiwari, S., Enguix, C.F. and Lata, K., 2023, October. Text2kgbench: A benchmark for ontology-driven knowledge graph generation from text. In International Semantic Web Conference (pp. 247-265). Cham: Springer Nature Switzerland.

II.	Wu, Y., Hu, N., Qi, G., Bi, S., Ren, J., Xie, A. and Song, W., 2023. Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for Knowledge Graph Question Answering. arXiv preprint arXiv:2309.11206.

III.	Heyi, Z.H.A.N.G., Xin, W.A.N.G., Lifan, H.A.N., Zhao, L.I., Zirui, C.H.E.N. and Zhe, C.H.E.N., 2023. Research on Question Answering System on Joint of Knowledge Graph and Large Language Models. Journal of Frontiers of Computer Science & Technology, 17(10), p.2377.

IV.	Sun, K., Xu, Y.E., Zha, H., Liu, Y. and Dong, X.L., 2023. Head-to-Tail: How Knowledgeable are Large Language Models (LLM)? AKA Will LLMs Replace Knowledge Graphs?. arXiv preprint arXiv:2308.10168.

V.	Taffa, T.A. and Usbeck, R., 2023. Leveraging LLMs in Scholarly Knowledge Graph Question Answering. arXiv preprint arXiv:2311.09841.

VI.	Lehmann, J., Gattogi, P., Bhandiwad, D., Ferré, S. and Vahdati, S., 2023, September. Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering. In European Conference on Artificial Intelligence (ECAI) (Vol. 372, pp. 1348-1356). IOS Press.


Overall assessment:
Not recommended to be published in NuCleaR 2024.",-1
328,"Paper proposes NeuRLP solver that uses differentiable quadratic programming to solve ODEs as an alternative to traditional solvers. The solver is used within the proposed Mechanistic NN block that consists of an ODE representation whose parameters are learned with an neural encoder. Output of the MNN block is obtained by solving the corresponding ODE. 


Strengths:
1. NeuRLP uses differentiable quadratic programming with equality constraints to solve the ODE. Method can be extensively parallelized, even across time steps. Table 2 and Figure 18 show that proposed method is significantly faster than the traditional solvers like RK4, especially on longer sequences. This component can be beneficial in many SciML methods that incorporate ODE within the architecture.
2. NeuRLP is able to solve ODEs with nonlinear terms using auxiliary variables in the quadratic programming problem. 
3. Experiments using NeurLP and MNN show improvements in forecasting tasks in ODEs and PDEs. 

Weaknesses:
1. Section 2 can be clarified to better distinguish the ""ODE discovery"" and ""Prediction/forecasting"" cases of the MNN models. Currently, these cases seem disconnected and require a back-and-forth with Appendix. 
2. Nonlinear ODE discovery experiments: I am not convinced if the proposed MNN method is better than SINDy for discovering ODEs.
	1. In Appx B.3, MLP(X) is used to obtained a nonlinear representation $\tilde{X}$ of X and the ODE is learnt over this representation. But the loss function seems to enforce that $\tilde{X} = X$ which negates the use of this MLP. This can also be seen from the learnt equations in C.1 that do not contain the effect of MLP. 
	2. When the ground truth dynamics has a nonlinear function applied at **last**, e.g., tanh or of the form p/q, MNN is given the exact form of this function whereas SINDy is not. I believe it should be easy to adapt SINDy to the case when this final function is known and nonlinear.  
3. Since the paper claims interpretability, it would be good to show the equations learnt within MNN for all experiments (e.g., n-body experiments). 
4. Please provide the following details in the paper: 
    1. What was the exact family of ODEs $U_x$ used in experiments (e.g., what were $g_k$)?
    2. What was the maximum number of ODE terms used in experiments? Do the proposed methods work even with large number of ODE terms (during both discovery and prediction)?
   
Overall, NeuRLP proposed in the paper is novel and significant for the SciML community. Some clarifications are required for its proposed use in the MNN architecture (especially for ODE discovery).",1
329,"Well written paper proposing a pipeline capable of predicting cardiovascular diseases. Custom models are used with a RAG layer to retrieve predictions.

The evaluation is well thought out. Overall a good contribution.",1
330,"**Strengths:**
- The authors effectively demonstrate how various prompting techniques can lead to superior performance compared to models finetuned/pretrained on domain-specific data. This experimentation showcases the practical utility of these techniques for open-source models, benefiting the community.
- The paper provides clear and comprehensive background details, making it easy to follow.

**Weaknesses:**
- It is essential for the authors to include an abstract and adhere to the formatting guidelines specified in the AAAI-24 Author Kit.
- The authors have failed to cite papers referenced in Figure 1.
- Figure 2 suffers from clarity issues, possibly due to colour choices. Reproducing results from open-sourced models like Meditron would ensure consistency in the computing environment. The same applies to models such as Med42, Clinical Camel, and PMC-LLaMA.
- The evaluation of the authors’ claims is limited. Experimentation across different model architectures and sizes would provide stronger support for their assertions.
- The lack of code release for their OpenMedLM prompting platform needs to be addressed.",1
331,"#### Summary
This paper tackles the challenge of enabling neural architectures to generalize beyond their training distributions.
 By employing logic puzzles as a controlled testbed, the authors propose a novel graph-based approach coupled with reinforcement learning (RL) to model scalable logical structures. 
The key contributions include a multi-agent RL framework leveraging Graph Neural Networks (GNNs) for reasoning, insights into the role of architectural inductive biases, reward system designs, and recurrent modeling in achieving extrapolative reasoning. 

---

#### Strengths

1. The paper effectively identifies generalization beyond interpolation as a critical challenge in machine learning. Using logic puzzles as a testbed provides a well-defined, scalable, and interpretable framework.

6. The introduction of the PUZZLES benchmark and a graph-based interface for logic puzzles enriches the resources available for studying generalization in controlled environments.

2.  Representing puzzles as graphs provides a flexible and scalable way to handle tasks of varying complexity. The dual use of decision and meta-nodes in GNNs captures local and global constraints effectively.

3. The experiments are comprehensive, spanning multiple puzzle types, varying sizes, and different architectural choices (GNNs vs. transformers). The evaluation metrics (e.g., extrapolation to x4, x9, x16 larger puzzles) are robust and directly aligned with the paper's goals.",1
332,"The paper presents the first benchmarking study of three different Genomic Foundation Models in predicting gene pathogenicity. The interpretive capacity of each model is significantly affected by factors such as preliminary training, context length, and resolution. Conventional approaches have limitations in enhancing model interpretation and heavily rely on specific features. The study underscores the potential of Foundation Models to address the complex challenges associated with genomic data analysis.

Quality and clarity:
- The quality is clear, and the tables and figures are generally understandable. Small notes: Figure one axis should either be made larger or removed, Tables could have standard errors
- The paper is generally well-written and free of grammatical errors
 
Originality and significance:
- Nucleotide Transformer exhibits better generalizability and accuracy performance compared to other models.
- The excellent performance of Nucleotide Transformer can be attributed to its extensive pretraining on over 3200 diverse human genomes, which sets it apart from other models on various genome benchmark datasets.
- Nucleotide Transformer solely utilizes genomic sequences for gene pathogenicity prediction, whereas other approaches rely on different features.

Weaknesses
- Limited Explanation of Embeddings, as they fail to properly distinguish between pathogenic and benign variants. How can this be addressed?
- Lack of Comparison with Non-LLM Models: The study primarily focuses on comparing different Genomic Foundation Models and LLMs. However, a comprehensive evaluation should also include comparisons with non-LLM-based approaches to assess the relative advantages and disadvantages of using LLMs for gene pathogenicity prediction.
- Computational limitations could be addressed by LORA or other efficient NLP techniques",1
333,"**Summary:** The paper proposes a new way to compute second-order differential operators using automatic differentiation. Authors extend on the recent results of the Forward Laplacian method by Li et al. to add arbitrary second-order differential operators with provably faster and lower memory calculations. The paper showcases results on MLP with/without Jacobian sparsity.

**Strengths:**
1. The paper reads well and is easy to follow. I enjoyed reading the paper.
2. The authors address a significant concern on the efficient calculation of second-order differential operators.
3. Convicing analysis of performance in domains of both time and memory.

**Areas of Improvement:**
1. The paper does not mention efficient higher-order derivative calculations like Taylor mode AD [bettencourt2019, tan2023]. The works relate greatly, and I would like to see performance comparisons.
2. How well does this technique generalize to compute arbitrary higher-order derivatives?
3. Open-source software: Do the authors plan to present their algorithm as open-source software?

[bettencourt2019] Bettencourt, Jesse, Matthew J. Johnson, and David Duvenaud. ""Taylor-mode automatic differentiation for higher-order derivatives in JAX."" Program Transformations for ML Workshop at NeurIPS 2019. 2019.

[tan2023] Tan, Songchen. Higher-Order Automatic Differentiation and Its Applications. Diss. Massachusetts Institute of Technology, 2023.",1
334,"Raskhodnikova et al. (2021) introduced the problem of privately generating a sample from an unknown target distribution given i.i.d. samples from it. The goal is to design an algorithm A with the following properties:

1. A takes as input a dataset S of n i.i.d. samples from an unknown distribution D over a domain X, where D belongs to a known family C of distributions.
2. A outputs a point x from X such that the distribution induced by A(S) is within a total variation distance of at most alpha from D.
3. A satisfies differential privacy with respect to S.

This problem is trivial without the privacy constraint, as the algorithm could simply output the first point in S. However, Raskhodnikova et al. (2021) demonstrated that with differential privacy, this can be as challenging as privately learning the distribution D itself. Ghazi et al. (2023) extended this work to additional families of target distributions (including multi-dimensional Gaussian distributions) and presented improved results for product distributions.

This paper explores an extension where the task is to output m samples rather than just a single sample (referred to as ""multi-sampling""). The authors introduce two possible notions of utility: a ""weak"" variant and a ""strong"" variant. Both require that the output random variables are mutually independent and identically distributed. The weak variant requires that the marginal distribution of the output is close to the input distribution, while the strong variant requires that the product distributions are close.

The authors present transformations from the single-sample case to the weak-m-sample case, and from the weak to the strong-m-sample case. This allows them to adapt algorithms from prior work to the multi-sampling setting. Additionally, they provide improved constructions for distributions over [k] and Gaussian distributions (under different assumptions about the information available to the private mechanism). Finally, they leverage a recent result by Kontorovich (2024) to derive a negative result for strong multi-sampling.

The extension to ""multi-sampling"" is a natural and worthwhile direction. The algorithms and proofs presented are elegant.  One potential limitation is that the results, in hindsight, may appear somewhat straightforward.  Overall, this is a solid paper and I recommend it for acceptance to ALT.",1
335,"Summary:

The paper describes the development of a segmentation network, designed in the light of the “CVPR 2024: Segment Anything In Medical Images On Laptop” Challenge. In contrast to the original SAM and MedSAM publications, the authors train a SAM-like model with a SWIN-T backbone from scratch on the provided and external datasets. Further distilling the SWIN-T encoder to a lightweight RepViT-M0.6 encoder results in a performant and efficient model, beating the LiteMedSAM baseline in all three metrics - DSC, NSD and inference speed.

Strengths:
- Simplicity: The contribution leverages well-known encoder backbones and concepts for knowledge distillation, resulting in an efficient yet high-performing final model.
- Resource Efficiency: The non-distilled network already matches the inference speed of the LiteMedSAM baseline. Moreover, the proposed model is not only efficient during inference but also significantly more efficient during training compared to the original SAM architecture.
- Reproducibility: The code for the challenge submission is available on GitHub, ensuring complete reproducibility.

Weaknesses:
- Comparison to MedSAM: The network is trained on a larger dataset with additional data sources, as detailed in Table 9. It is unclear whether the improvements of the proposed model are due to this larger training dataset or the different architecture and training pipeline. This question is particularly interesting since the proposed model does not use the pretrained SAM checkpoint but is trained from scratch.
- Size of External Dataset: It would be beneficial to include the dataset size of the external data, similar to the information provided in Table 1.

Overall:
The submission represents a solid contribution to the challenge, improving upon the LiteMedSAM baseline in both performance and efficiency. The mentioned weaknesses are either outside the scope of a challenge submission or could be easily addressed.",1
336,"The authors present a vision transformer with minimal additions as well as training recipes that make their model competitive with all SOTA models (and even better at certain lead times) for the problem of weather forecasting. 
 Strengths:
1. The paper is clear, well-written and presents some contributions that are novel.
2. The paper could have significant impact as they adapt the philosophy of CV/NLP and scale transformers for the weather domain without major changes to the transformer backbone. This can be very useful to researchers in this domain and to obtain scaling laws.
3. The model outperforms SOTA graphcast and pangu models as well as numerical PDE baseline IFS in RMSE/ACC metrics.
4. The paper presents ablations on the modifications of ViT to show their improvements and also demonstrate some minimal scaling laws w.r.t patch size and #parameters of the ViT.

Weaknesses and questions:
1. Loss weighting, multistep finetuning are already present in SOTA models such as graphcast. It will be useful if the authors clearly laid out their contributions in bullet points and for others appropriately referenced where they are from in their sections.
2. The variable aggregation seems to add a lot of memory pressure. For the cross-attention, I would need to store local_batch * V * h/p * w/p * D which is a lot and can easily become bottlenecks at higher resolution. Please comment on how this method will scale. 
3. Further, for 2. you add more parameters as well as compute as well. I'm not sure how fair then the comparison is in Fig 6b. Can the authors comment on time per epoch for ViT with weather embedding and ViT without weather embedding assuming everything else stays exactly the same? Same for mem consumed. This would help the reader gauge how scalable the model is and what the cost associated with the weather embedding is -- I assume it doesn't come for free.
4. The compute comparison is between different resolutions. For ex: the authors say pangu takes 15 days to train a model. But they operate on 32x (721/128 * 1440/256) finer data. By comparison, stormer takes 1 day. With 32x finer data, the model would take 1000 days assuming quadratic complexity of the ViT. I think this should be acknowledged -- because a researcher can, in principle, train pangu/graphcast on lowres data and get away with lesser compute. 
5. Relating to 4, I'm wondering what the effect of resolution is on RMSE? While it is averaged spatially, coarser fields have lesser fine-scale structure and hence it is possible to get better RMSEs. Have the authors looked at spectra? This also might be useful to motivate Fig 9 (right) as smaller patch sizes may give better spectal metrics.",1
337,"This paper explores a dual approach to align AI in human-like reasoning, combining structured neural-symbolic methods with the adaptive capabilities of Large Language Models (LLMs). Focused on the Abstraction and Reasoning Corpus (ARC) as a benchmark, it highlights how these techniques can complement human problem-solving and advance abstraction and broad generalization in AI systems.

1) The paper effectively underscores a critical limitation of current AI systems: their inability to generalize and reason abstractly in human-like ways. The emphasis on ARC as a benchmark for ""broad generalization"" is well-motivated, presenting a relevant challenge to AI research.

2) The discussion of DreamCoder and Large Language Models (LLMs) highlights their complementary strengths. The hybrid approach proposed by leveraging neural-symbolic techniques alongside foundation models shows thoughtful integration of existing tools. In particular to overcome abstract reasoning, intuition, and contextual understanding where LLMs still struggle.

3) While the paper promotes structured architectures inspired by mathematical logic, it does not convincingly argue why such structures alone would suffice to bridge the gap between current AI capabilities and human reasoning. I would appreciate more clarity and examples on the mathematical structures and tools that the authors claim should be used.",1
338,Good paper!!!,-1
339,"With the proposed method, the authors are predicting the fine mesh solution from the coarser mesh solution. Once the mapping is learned, the trained networks can be applied with varying field variables (say, velocity) or geometric shapes. 

In my opinion, the obtained results are not good, especially for the Euler equations, where it is important to capture shock waves with good accuracy and at exact locations. The author(s) needs to work harder before solving such problems.",-1
340,"In this work, the authors address a critical issue of evaluating the hallucination of LVLMs in a clinical context. As the authors assert, developing methods to assess hallucinations of these models in a quantitative and automated way is important. For this, the authors employ the CHAIR metric used in image captioning and propose a new domain knowledge hallucination metric. The authors present an initial evaluation of LLaVA-Med using the metric on the MedICAT dataset. 

Comments:

- The authors address an important issue regarding hallucination of LVLMs in a clinical context.
- The proposed metric seems reasonable, however, the fact that an additional LLM is used obtain ground truth object observations is questionable. LLMs themselves are not fully validated in terms of their performance, so a proper evaluation/validation study of this step is necessary
- For assessing object hallucination and domain knowledge, the authors utilize cosine similarity of embeddings with BioBERT. Again, although the method addresses scalability, careful validation of this method for assessment is needed.
- Minor: the figure seems to be assessing GPT-4V whereas the text is evaluating LLaVA-Med

Overall, the work addresses an important issue and presents a reasonable set of metrics for assessing hallucination. Although the study is preliminary, the work will garner relevant discussion, in particular regarding the usage of existing models (such as BioBERT and GPT-4) for assessing other LVLMs.",1
341,"OpenMedLM proposes a platform employing prompt engineering techniques to optimize the performance of open-source large language models (LLMs) on medical question-answering benchmarks, achieving state-of-the-art (SOTA) results without fine-tuning. Using the Yi 34B model, OpenMedLM surpasses previous SOTA results on MedQA, MedMCQA, PubMedQA, and MMLU medical subsets through few-shot prompting, chain-of-thought (CoT) prompting, and self-consistency strategies. The study emphasizes the potential of prompt engineering in enhancing the capabilities of generalist LLMs for specialized tasks like medical question answering.

**Strengths**
- Innovative Approach: The study introduces a novel use of prompt engineering as a viable alternative to fine-tuning, offering a cost-effective method for enhancing LLM performance in specialized domains.
Comprehensive Evaluation: It evaluates the model across multiple benchmarks, thoroughly assessing its capabilities in medical question-answering tasks.
- Clear Methodology: The methodology, including using few-shot prompting, CoT prompting, and self-consistency, is well-articulated, offering clarity on the process and potential for replication.

**Weaknesses**
- Generalization Concerns: The study's focus on a single LLM (Yi 34B) raises questions about the generalizability of the findings to other models.
- Lack of Comparative Analysis: While it compares OpenMedLM's performance with that of the Meditron model, a broader comparison with more models, especially those using different fine-tuning approaches, could have provided a more comprehensive view of its relative performance.",1
342,"The authors present a novel method for unsupervised deep metric learning by representing data with piecewise linear manifolds. This simple representation allows neighborhoods to be linearly approximated. 

Pros:
+ Provides good intuition for their approach
+ Clear motivation
+ Validated their approach against numerous other methods

Cons:
- Method description is fairly long and involves many variables, so an algorithm/pseudocode block would enhance the clarity.
- Limits of their work not explicitly stated
- Choice of GoogLeNet, a fairly old model, over other models is not explained

Questions:

1) The loss function is a sum of three components (point, proxy, and neighborhood). Is there a reason to weight these the same i.e. would performance improve by adding the flexibility to weight them differently?

2) What is the reasoning behind choosing GoogLeNet for your experiments? How does the method perform with different architectures and larger models?",1
343,"This paper proposed a new algorithm for deep metric learning based on estimating the piecewise-linear local manifold. Nearest-neighbor based sampling and proxy vectors are used to mitigate the issue that a random batch doesn’t contain enough samples to form a local manifold. Compared to other metric learning methods, the proposed method achieves significantly better performance.

Overall, this paper is clear and well written. The method and experimental results are clearly presented. The proposed method is motivated in terms of encouraging sample points to come closer to the local manifold formed by neighboring points, but the resulting loss function seems much more complicated than it needs to be. First, there’s very little motivation provided for the particular form of similarity metric s proposed in Section 3.3, besides transforming the projected distance and orthogonal distance to the required numerical range. There’s also no motivation as of why ɑ and ꞵ needs to be multiplied together in equation (2).

It is also interesting that in the actual experiment, the authors mixed this distance term with other simpler terms like L2 distance and cosine similarity again. This happens in equation (6) (7) and (8). A δ parameter is included to adjust the importance of similarity s and other terms. However, in Figure 3, when δ decreases, it only has a very minor effect on the accuracy result, indicating that the other, simpler terms are doing most of the heavy lifting.

The proposed method also contains many extra implementation details that other metric learning methods do not have, for example, using nearest neighbor sampling to form a batch. In the self-supervised learning literature, it is well known that this alone can provide significant performance improvement[1]. Therefore, it will be necessary to study what design choice contributed to the improved performance and by how much.

Although it is nice that the authors achieved significant improvements in their benchmark results, it is at the expense of many more hyper-parameters involved, as well as a more convoluted and ill-motivated design. It would be more interesting to see experiments and analysis about how this improvement is achieved and what principle it reveals.

[1] Debidatta, Dwibedi. Et al. With a Little Help from My Friends: Nearest-Neighbor Contrastive Learning of Visual Representations. arXiv:2104.14548v1",-1
344,"Authors present the use of LLM to improve psychotherapy sessions integrating common factors approach into LLM to provide feedback.
The paper is certainly original. It would enhance the clarity and understanding of the paper if authors present more detail on how the system is built, the interpretation of the metrics and how the system can improve the quality of visits. I would also appreciate a discussion on the ethical or social implications of using this type of technology in the medical setting.",1
345,"I don't see the novelty of the paper. The authors pre-train a transformer and then fine-tune for task specific downstream problems. 
The novelty might be in the use case - stochastic dynamical systems - but there is a lot of good work in this topic that is not even mentioned here. Also, the writing could be improved, it is hard to understand.

For instance: 
Alexandre Cortiella, Kwang-Chun Park, Alireza Doostan,
Sparse identification of nonlinear dynamical systems via reweighted ℓ1-regularized least squares
Computer Methods in Applied Mechanics and Engineering",-1
346,"The authors demonstrate a ""general purpose"" GPU-accelerated global optimization method for inverse problems based on HybridPSO-LBFGS framework, which allows for parallelization across objective function evaluations and uses differentiability to accelerate convergence. The method is evaluated on a benchmark optimization test problem as well as to neuralODE training. The paper is well-written and the work is original and new based on the reviewer's knowledge of prior literature in this area of optimization methods. The proposed method can certainly speed up optimization problems encountered in SciML.

The authors should elaborate on the multi-start optimization scheme with L-BFGS and how it was parallelized on GPUs. On the other hand, it seems that the developed approach for HybridPSO-LBFGS is only going to be efficient in Julia. So, the method is not ""general purpose"" contrary to what the authors say in the Conclusion and Future Work section.",1
347,"The authors studied the convergence rates of the unadjusted Langevin algorithm (ULA) and the proximal sampler using the measure of $\Phi$-divergences. The class of $\Phi$-divergences cover a wide range of metrics and divergences such as KL, chi-squared, TV, and Hellinger. 

The generality and the tightness of both of the main convergence results are very welcomed. This is a nice unification of many different analyses arising from different papers, but conveniently and cleanly summarized into these general results. While the proofs are not the necessarily the most complex, both main results are fairly clean extensions of Vempala and Wibisono (2019) and Chen et al. (2022). I did not carefully analyze every step of the proof, but the framework makes sense to me, and the results are strongly believable as they recover existing results for KL divergence. 

I have several questions for the authors. 

1. The convergence result of Theorem 1 for ULA is for the biased stationary distribution of ULA $\nu^\eta$. While this result is interesting in its own right, I believe the most desirable type of guarantee is for $\nu$. Essentially, there are two components missing to achieve this: (a) a bias characterizing the ""distance"" between $\nu$ and $\nu^\eta$ (b) a type of ""triangle inequality"" for the $\Phi$-divergence to characterize the gap using this bias. Can the authors firstly comment on the technical challenges involved with this extension? Secondly, can the authors add a discussion on this limitation in the main text, in particular with respect to the dimension dependence of the bias? I will not hold this second question negatively against this paper, as I simply prefer the limitations to be clearly communicated. 

2. While the $\Phi$-divergences cover a large class of desirable divergences, can the authors discuss the possible extension to the Renyi divergences? There is a sense that Renyi divergence is a better measure of convergence guarantees than chi-squared, in particular the initial conditions will not introduce an exponential dependence on dimension. 

3. The main results on proximal sampler assumes access to the RGO, which is why the current convergence guarantee is independent of dimension. Can the authors comment on how some of the numerical procedure to implementing the RGO might introduce additional dimension and other dependence for the convergence guarantee? In particular, would we recover the results of Chen et al. (2022)? 

A couple of further minor points. 

1. Can the authors move the definition of the $\Phi$-Sobolev inequality up to before the Theorem statements, as it is the most important assumption of this paper? 
2. Would the authors require $\Phi$ to be twice differentiable as the Fisher information now contains $\Phi''$? If it is not required, then for the case of total variation for example, how should I interpret the Fisher information with a delta functional? 

At this point, I will recommend a ""weak accept"", but I would be happy to raise the score if the authors can address my questions above.",1
348,"># Quality
The work is of high quality, as it demonstrates a thorough understanding of the clinical domain and the challenges of building a clinical large language model (CLaM). The authors justify their choice of foundation model clearly. They also address several modeling challenges, such as long context window, medical jargon, and abbreviation expansion. Their models are evaluated using both next-token prediction and blind pairwise comparison with other popular LLMs, showing superior performance in patient clinical data structuring.

># Clarity
The work is well-written and organized, with clear problem formulation, methods, results, and discussion. The authors provide sufficient details and explanations for their data collection, model training, and evaluation methods, including several appendices with examples of their models’ outputs, ethical considerations, and reproducibility statement.

># Originality
This work is indeed original as it introduces a novel family of CLaMs designed for patient clinical data structuring, a crucial yet intricate component of clinical workflows.

># Significance
This work is significant, as it addresses a critical problem of structuring clinical notes into clinical data, according to international interoperability standards.

># Pros
* This work tackles an important area of healthcare and has a lot of potential significance.
* The work evaluates the models using both next-token prediction and blind pairwise comparison with other LLMs",1
349,"Strengths:
Combines approach of think fast and slow.  The results show that the technique works.

Weaknesses:
1. Lack of motivating examples to support the proposed approach. I don't understand why the authors are first doing neural and logical reasoning in a fallback manner, there can also be a case that they could be executed parallelly - a voting based technique combining the approaches (in cases where the symbolic latency is less) can work better?

Formatting:
1. It is difficult to parse and understand the table 
2. It would be much easier to split it into two and have the techniques as rows and metrics as columns.",1
350,"The paper studies the problem of comparative learning, a variant of PAC learning that allows labelling to come from one hypothesis class while the learner’s performance is measured against another (possibly different) hypothesis class. The authors derive precise conditions under which the learner performance is linear or quadratic in $1/\epsilon$. 

Quality: 
- The proof techniques and arguments are sound. The bounds on linear and quadratic dependence on 1/\epsilon rely on established techniques and are derived by relating the comparative learning framework to that of agnostic PAC learning under deterministic labels. 

Clarity: 

- The paper is mostly clear, and I did not spot a missing definition. There are many definitions of properties throughout the work, such as one-sided mutual graph dimension, which could benefit from being simplified/joined with other definitions for ease of reading. However, I understand that this is not always possible and it seems that these precise definitions are necessary for the results. 

Originality:
- The paper seems to continue along the lines of the initial paper (Hu and Peale (2023)) which, to the best of my knowledge, proposes this comparative learning framework. Nevertheless, this paper is distinct from previous papers in that it precisely characterizes when linear vs. quadratic dependence in 1/\epsilon arises. 

Significance:
- I find the results in the paper to be significant for learning theory and more broadly for the communities of model distillation. It is interesting and novel, at least from my perspective, to see learning bounds that are not majorly governed by the standard VC dimension. 

Recommendations and Questions:
- Typos: “the the” bottom of page 8. “of learning for learning” top of page 5. n \geq n_{S, B}(\epsilon, \delta) in Definition 1. “both both”, middle of page 3. “have been shown in for”, middle of page 3.",1
351,"The paper proposes a deep learning framework that integrates a cycle transformer inspired by CycleGAN and a DDI loss inspired by 4SDrug to predict the drug combination prescription. The experiment carries out with MIMIC-III dataset, indicating that the proposed model outperforms previous models by large in terms of Precision, DDI rate, and Average number of drugs in the set. 

### Strength: 
1. The experimental results are promising.
2. The model design seems reasonable.
3. The problem of predicting drug combination is important.

### Opportunity to improve:
1. The reference number of Baseline in Table 1 does not align with other citation styles.  
2. The definition of Precision needs clarification. If multiple drugs suit the patient, does hit with any of them count as 1? If it is not the case, it would be very unusual to see the Precision outperforming baselines by this far while maintaining such a small Avg #. It is extremely crucial to clarify this.
3. How is the DDI adjacent matrix defined? Without clarification, it can be very confusing. There may raise concerns if the definition of DDI is actually making sense in terms of medicine and for clinicians. 
4. I do not see why L_{EMD} can be jointly added to the loss function, even though WGAN uses it. What are set A and set B, and why is there a need to transfer A to B? 
5. Hyperparameters tuning will be very important since there are multiple loss functions. I assume adding appendices to explain how to reproduce the results and/or code would be helpful.
6. I do not think it is a good idea to call it a “foundation model”, since it has so few downstream tasks. It is not necessary to name it a foundation model just to fit in the symposium topic.",1
352,"##  Summary of Paper
The paper aims to demonstrate two things: First the authors aim to reduce the simulation-cost in producing vasts amounts of examples to train neural operators. To this end, they propose to create data examples that do not require to solve the differential equation at hand. On this data they train the neural operator to perform common pre-training tasks such as gap-filling, de-noising or de-blurring. 
Second, the paper proposes in-context learning for neural operators. The motivation is taken from the emerging abilities of LLM that can solve new tasks when prompted with very few examples. Specifically, they propose to find examples with similar **outputs** and replace the prediction for the sample at hand by the average of the sample and the similar examples.
The authors present empirical evaluations for both of these methods.
Since both the contributions are mostly independent, I will in the following refer to the first as Pre-Training (PT) and the second as In-Context-Learning (ICL).


## Fit for this Workshop
I think that both contributions are interesting for this workshop. While I think that the ICL contribution might be more uncertain overall, I think that the PT contribution will be of great interest to a lot of participants at this workshop.

## Evaluation of the General Structure and Idea
### Pre-Training
I think the pretraining topic is interesting. The authors claim that ""Unsupervised pretraining on unlabeled data has never been explored in PDE operator learning in SciML."" Independent of, whether this claim is true, I think pretraining for PDE operator learning SciML is not that different to PDE operator learning in other domains and the solutions proposed in this paper are not different to pretraining of neural networks in general. To this end, the article needs a discussion of related  work. I do not agree with the authors that this discussion can be put into the appendix, especially if it is not referenced in the article once. 
Further, the explanations in Section 2.1.1 need more explanations. Especially the first bullet point is still unclear. On the other hand, The statement of the second-order linear differential equation does not add much to understanding the paper. 
Finally, empirical evaluation is way to short. No details are provided. In the current form, The empirical results are difficult to interpret and almost impossible to reproduce as no information on the architectures or training algorithms is given. It is unclear which pretraining and how mch pretraining is done in each example. This is especially important, as the random initialization results fall short of the values of other publications. For example [1] reports an error of 0.005 at 10 000 examples for the Poisson equation beating the numbers reported for the random initialization by an order of magnitude and being on par with the pretraining.
The description of the Proxy tasks (2.1.2) is nice and I appreciate the fact that the authors do not only introduce the tasks but share their intuition why these tasks should improve the performance.

### In-Context-Learning
I am not sure about this idea of ICL. I understand the motivation, but I see a big discrepancy between the motivation and the actual implementation. In the current form, the method seems to be similar to imposing a prior on the distributions where predictions by the operator are corrected towards areas of high density in the prediction space. If the solution of the PDE is continous, this is further similar to test time augmentation (eg. [2]). I think that both of these links need to be discussed and evaluated.
The description in Section 2.2 is way to short and general. The empirical results have the same shortcomings as the empirical evaluations of the PT approach. They need a lot more explanation and introduction than provided by the authors. In the current form, the results are not convincing.

## Structure and Length of the Paper
I know that it is challenging to explain a complex topic in four pages. This makes it even more difficult to put two paper into four pages. I think the paper is not long enough to discuss both topics well enough to allow the reader to follow and unfortunately, I do not think that any of the two proposed advances are well enough discussed to be helpful to the reader. This is underpined by the fact that the authors provide multiple Appendices (A1, A2, A3, B, C, D1, D2, D3, E, F, G, H, I, J1, J2, K1; 9pages) only three of which are ever referenced in the paper.
I would recommend to focus on one of the two topics instead. 

## Conclusion
In conclusion I think the paper tries to do to much on four pages to allow for the needed scientific rigor. I find especially the PT topic interesting but I can not follow the authors arguments and conclusions in this paper. I think that the discussion of the pre training tasks in 2.1.2 is a highlight but especially the empirical evaluation is to poorly described to understand whether there is any effect. Therefore, while I think the underlying research is interesting and might be well done, the paper in the current state is not good enough. I recommend to reject this paper.

##References
[1] Hasani E, Ward RA. Generating synthetic data for neural operators. arXiv preprint arXiv:2401.02398. 2024 Jan 4.

[2] Perez F, Vasconcelos C, Avila S, Valle E. Data augmentation for skin lesion analysis. InOR 2.0 Context-Aware Operating Theaters, Computer Assisted Robotic Endoscopy, Clinical Image-Based Procedures, and Skin Image Analysis: First International Workshop, OR 2.0 2018, 5th International Workshop, CARE 2018, 7th International Workshop, CLIP 2018, Third International Workshop, ISIC 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16 and 20, 2018, Proceedings 5 2018 (pp. 303-311). Springer International Publishing.",-1
353,"This paper studies the online learning of a class $ \mathcal{H} \subset \\{0,1\\}^{\mathbb{N}} $ with computable predictors and investigates the intrinsic complexity measures that characterize this learning paradigm. The paper introduces a notion named the ""Effective Littlestone Dimension,"" defined as the maximum number $ d $ for which there exists an algorithm $ w $ such that, for any binary tree of depth $ d+1 $ with $\mathbb{N}$-valued labels, the algorithm $ w $ outputs a path in the tree that is not consistent with $ \mathcal{H} $. 

The paper demonstrates that if a class $ \mathcal{H} $ is computably online learnable, then the Effective Littlestone Dimension is bounded. However, there also exists a class with an Effective Littlestone Dimension of 2 that is not computably online learnable. The paper further investigates several special cases where a bounded Effective Littlestone Dimension implies computable online learnability, such as when the instances are bounded and for classes with an Effective Littlestone Dimension of 1.

I have verified almost all the proofs, and they appear to be correct. I find the paper interesting and believe it is suitable for publication at ALT.

**Strengths**

The main result, in my opinion, is the counterexample showing that the Effective Littlestone Dimension does not imply computable online learning, strengthening the result by Hasrati and Ben-David (2023), which holds only for the classical Littlestone dimension.

The proof is also very elegant, leveraging the key concept of ""effective closedness"" of a class $ \mathcal{H} $. This concept can be described as follows (paraphrased from the paper):

1. Let $ \mathcal{\Phi} = \\{\phi_1, \phi_2, \dots\\} $ be a computationally enumerable set  of computable functions $\phi_i: (\mathbb{N} \times \\{0,1\\})^* \rightarrow \\{0,1\\} $.
2. A class $ \mathcal{H} $ is said to be ""effectively closed"" with respect to $ \Phi $ if, for any sample $ S \in (\mathbb{N} \times \\{0,1\\})^* $ such that $ \phi_i(S) = 1 $ for all $ i \in \mathbb{N} $, then $ S $ is realizable by $ \mathcal{H} $.

This implies that, for any sample $ S $ that is *not* consistent with $ \mathcal{H} $, there exists an algorithm to certify it. Therefore, for any ""effectively closed"" class $ \mathcal{H} $ with bounded (classical) Littlestone dimension, one can also bound the Effective Littlestone Dimension by searching for paths that violate one of the $ \phi_i $s. The proof then proceeds to construct an ""effectively closed"" set that is not computably online learnable yet has a (classical) Littlestone dimension of 2.

I also find other parts, such as the result that a bounded Effective Littlestone Dimension implies the functions in the class must be computable, to be quite interesting.

**Weaknesses**

1. The proof is sometimes difficult to follow, such as Theorem 7. I suggest that the authors define ""effective closedness"" mathematically rather than describing it in words. It would also be beneficial to first state the construction, then provide the proof so that readers can better understand the meaning of ""compactness"" and ""effective closedness.""

2. I am not sure why the notion of Cantor set is even mentioned in the paper. It seems that you not only use compactness but an ""effective"" version of compactness (i.e., where the open covering should be computationally enumerable).

3. The references in the paper are very limited; the authors should at least cite literature from inductive inference, such as T. Zeugmann and S. Zilles, ""Learning recursive functions: A survey."" Even though the current paper does not consider learning in the limit, I believe many of the proof ideas share a similar spirit. Additionally, I am not sure why ""PEC-learning"" is mentioned, as it is never used anywhere in the paper.

4. There are several typographical errors; I note a few here:
    - Last paragraph of page 9: $ x \in \\{0,1\\} $ should be $ x \in \mathbb{N} $.
    - Paragraph following Proposition 6: ""this section is the the converse"".",1
354,"The paper considers the well-studied list update problem, where we are given a list of items, and upon the arrival of a requested item, we rearrange the ordering to minimize access cost. The main result of the paper is to establish that Transpose (a well-known online algorithm that exchanges the requested item with the item immediately to its left) achieves a 1+o(1) competitive ratio when requests follow an i.i.d. Zipfian distribution. Additionally, the authors provide interesting experimental evaluations of Deep RL algorithms for the list update problem.

Strengths

The list update problem is a fundamental problem in online algorithms. The results presented are interesting and appear to answer a conjecture posed in 1976. The authors provide a clear proof sketch, with the proofs being non-trivial and technically sound.  At the same time, the experimental results that the authors provide are interesting and I also liked the idea of trying to interpret the behavior learned by the Q-Learning algorithms. 

Weaknesses

I believe that the significance of the results is somewhat limited, as they pertain specifically to the stochastic setting for niche family of distributions.

Overall Evaluation

I overall enjoyed reading the paper. I believe it provides interesting results and techniques. Despite the weaknesses that I mentioned above, I believe it should be considered for acceptance.",1
355,"I was impressed with the way you analyzed and handled the characteristics of the image forms in the scribble-based interactive segmentation technique, respectively.
There appears to be an error in the reference to figures in section 4.8. Also, providing the sources of the various datasets used in the challenge would improve the clarity and reproducibility of the study.",1
356,"The list update problem is a very old problem in data structures, asking for an algorithm to maintain a set of items stored as a linked list (in arbitrary order) while answering queries that seek to access items in the list. The list may be reordered in response to the queries, and efficient algorithms for list update reorder the list so that the frequently accessed items appear near the beginning. The Move-To-Front algorithm (MTF) was shown to be 2-competitive by Sleator and Tarjan in a seminal discovery that gave birth to the study of competitive online algorithms. The list update problem under an i.i.d. access pattern was studied by McCabe, and Rivest (1976) showed that the Transposition algorithm (which swaps the accessed item with its predecessor) is at least as good as MTF under every i.i.d. access pattern, in terms of average cost.

The present submission proves a conjecture of Rivest, that the Transposition algorithm is asymptotically optimal (its average cost exceeds the optimum by only a 1+o(1) factor as list size tends to infinity) for Zipfian access distributions. The proof consists of assuming without loss of generality that items are numbered in decreasing order of access frequency, and showing that when j is significantly greater than i — say, when $i$ is at least $\log n$ and $j$ is greater than $i + i^{0.9}$ — then the probability that $j$ appears significantly earlier than $i$ (i.e., $i^{0.15}$ or more positions before $i$ in the list) is negligible, when the ordering is sampled from the stationary distribution of the Transposition rule. This is accomplished by a carefully-constructed accounting system in which states violating the condition are mapped to states satisfying the condition, in a way that allows for comparison of probabilities of the two state sets. 

The second main contribution of the paper is a set of experimental results on using deep Q-learning for optimizing over list update policies. I found the experimental setup described in Section 4 to be ill-motivated and potentially riddled with errors. I would appreciate if the authors could address, in their response, the following issues that seemed problematic to me. 
1. The paper describes a quadratic state space in which the state at time $t$ is the pair $(r_t,L(r_t))$ consisting of the requested item and its position in the list. The paper claims that under this state representation, the state transitions are Markovian, i.e. the probability of transitioning to $(r_{t+1},L(r_{t+1}))$ given the full past history is equal to the probability of transitioning to $(r_{t+1},L(r_{t+1}))$ given that the previous state was $(r_t, L(r_t))$. I believe that's true for trivial policies that never reorder the list, but false for policies that reorder the list. For example, let's consider the MTF policy and a 3-element list with items {1,2,3}, each with equal access probability. Then $\Pr((r_2,L(r_2)) = (1,2)  | (r_1,L(r_1)) = (2,2),  (r_0, L(r_0)) = (3,3)) = 0$; if 3 is requested at time 0 and 2 is requested at time 1, then the list ordering under the MTF policy will be 2,3,1 at time 2, so if item 1 is requested at that time it will not be found in position 2. On the other hand, $\Pr((r_2,L(r_2)) = (1,2)  | (r_1,L(r_1)) = (2,2), (r_0, L(r_0)) = (1,3)) = 1$; if the first two requests are 1 at time 0 and 2 at time 1, then the list ordering under the MTF policy will be 2,1,3 at time 2, so if item 1 is requested at that time it will certainly be found in position 2. This indicates that the state transitions are not Markovian as claimed.
2. You say that $\max(j,i)$ is the agent's reward in step $t$ if $x$ is queried, found in position $i$, and moved to position $j$. I assume the training objective is to _minimize_ the expected value of $\max(i,j)$, not to maximize it. If so, I think ""reward"" is a confusing term and should be changed to ""cost"".
3. I'm confused why you are using deep Q-learning rather than tabular Q-learning given that the state space is only quadratic in $|L|$, and $|L|$ in your experiments does not exceed 1000. For Markov decision processes at this scale, the computational resources required for tabular Q-learning would not be prohibitive.
4. Test sequences of length 3000 seem quite short, when L=500 or L=1000. The mixing time of the Markov chain is at least linear in L, so I would expect the policy's average cost on a test sequence of length 3000 to exhibit strong correlation with the initial condition. Do you have evidence that the average costs observed on a length-3000 test sequence are representative of the long-term average, even when L=500 or L=1000?

My evaluation is that the paper is not appropriate for ALT. There are two aspects to this evaluation. 
* The theoretical contribution sketched in Section 3 and detailed in Appendix A. I appreciate the resolution of Rivest's conjecture about the performance of the Transposition policy under Zipfian access distributions. These results resolve an old open problem about average-case analysis of list update policies and deserve publication somewhere. I question whether ALT is an appropriate venue because I do not really see any connection to learning theory. One could say that the Transposition algorithm is ""learning"" the access distribution by reordering the list, but to me it seems this stretches the definition of learning theory to the point where the average-case analysis of any algorithm whatsoever would be considered ""learning theory"" if the analysis showed that the algorithm achieved near-optimal performance on its input distribution. To wit, the Transposition algorithm is completely memoryless and encodes no information about learned parameters of the access distribution. (To the extent that the algorithm is ""learning"" such information, its knowledge is encoded in the state of the list itself, because the Transposition algorithm has no internal state.) 
* I am doubtful of the experimental contributions in Sections 4 and 5 for the reasons detailed earlier in this review.

UPDATE AFTER AUTHOR RESPONSE: The authors acknowledged an error in Section 4 and provided me with some important context about Section 5, raising my evaluation of both sections. I am raising my score accordingly.",-1
357,"This paper sketches the idea that more information is necessary to complete syllogistic reasoning, and these necessary information shall be acquired through a process of knowledge discovery. Authors did not list any references. 

Authors follow the early method of verbal analysis, and strictly distinguish ""a man"" from ""all men"". That is, from ""a feature of all men"" we can deduce ""a feature of a man"".  To deduce ""Socrates has a feature"", we shall first deduce ""Socrates is a man"". ""All men"" denotes a set, which corresponds to a predicate. This predicate applies for an instance. If its value is true, this instance is a member of the set, otherwise, this instance is not a member of the set. What authors propose is the need and the discovery of such a predicate. 

In the analysis of the Barbara syllogism, authors suggest ""all B"" --> ""B"" and ""all B are A""--> ""B be A"". In the term of set-theory, ""all B are A"" means that set B is a sub-set of set A, ""B be A"" means that set B equals to set A (let B be A). So, here, the analysis is incorrect (nor necessary).",-1
358,"This work presents a noise guided analysis for Physics-informed neural networks (PINNs) to solve differential equation problems. 
The paper is well written and some conclusions on the performance of the UQ-PINN are demonstrated on the Poisson equation with additive noise.",1
359,"**Summary:**

The paper focuses on fine-tuning the 7B and 70B Llama-2 models on a dataset compiled from several open medical datasets, evaluating the performance gap between LoRA fine-tuning and full-parameter fine-tuning. Experiments conducted on several medical benchmarks led to good performance on some of the benchmarks, outperformed only by models trained at a larger scale (GPT-4) and models pre-trained on medical corpora (MedPaLM-2). To ensure a fair evaluation, the paper also introduces a decontamination pipeline to remove potential common samples between the training and the testing splits of the benchmarks.

**Strengths:**

1. The evaluation benchmark is thorough, encompassing a wide set of medical benchmarks, thus enabling a more in-depth analysis.

2. The dataset introduced by the authors seems fairly comprehensive and suitable for the clinical domain, and the performance obtained by the Llama models trained in the paper realistically substantiates this.

3. The focus on data decontamination for a fairer analysis by the authors is appreciated and makes their results more relevant.

4. The overall work presented in this paper is very relevant to the topic of the venue.

5. The elaborate (for a short paper) description of the hyperparameters to enable reproducibility is appreciated.

**Weaknesses:**

1. The theme of the paper revolves around parameter-efficient fine-tuning vs full-parameter fine-tuning. However, the claim that parameter-efficient fine-tuning achieves results close to full-parameter fine-tuning is a well-known research artifact. The authors themselves note that the results are in line with prior work for LoRA vs full-parameter fine-tuning in other domains. I would recommend the authors adjust the paper to better describe their main contributions towards the compilation of the training dataset from open medical sources and the data decontamination pipeline, with a lesser focus on parameter-efficient fine-tuning vs full-parameter fine-tuning.

2. I recommend the authors describe the instruction tuning methodology in greater detail in the main paper, if space permits, else in the appendix.

**Other recommendations:**

There is a typo in the caption for Table 1, where GPT-3.5 is incorrectly mentioned as GPT-3.4.",1
360,"The authors propose to use ECG examination records (text) to classify heart defects. This is in contrast to the more ""classical"" approach of using directly ECG data.
To my understanding, at inference time this method would rely on a doctor first describing the ECG to produce the ECG examination record which would then be used as input to the model. I wonder if this is something that limits its applicability. In the introduction the authors note that there is a lack of cardiologists, but this method would not alleviate that issue.
The authors first apply a classic few-shot strategy using a llama2 variant that was pre-trained on a curated version of a public dataset of ECG notes. They note a low performance with this strategy.
Then they finetune the model on their dataset (1006 cases) and observe a marked improvement. Notably, there are no descriptions of whether they split the data in training and validation or of any cross-validation strategies. Additionally, pre-training and finetuning are done for very few epochs 10 and 15 respectively.
Then the authors use RAG to include context from similar cases to aid in the prediction. They can only include 1 or 2 retrieved samples before running out of tokens with a standard RAG strategy. The RAG strategies improve the performance. But I have several issues here. i) The knowledgebase for RAG is the same training cohort. This seems a major issue. ii) If the retrieved context includes a diagnosis, the model may just use the retrieved diagnosis. It may be beneficial to investigate this potential issue.
To include more context, they propose a context fusion model based on cross-attention. Then the entire context coming from the RAG portion boils down to a single vector if I understood correctly. This seems to improve performance further.
In general I would have liked to see baselines of performance using ECG data to compare if there could be benefits of the LLM strategies based on ECG reports.
I was confused about the ""standard values"" I could not find a description of them. They are mentioned only once in the text but they appear in the results table.
It would have been good to see the number of cases in each type of case: single, double, triple.",-1
361,"Strengths:
* This paper is clear and thorough in presenting the development of Rep-MedSAM.
* The results are compelling, indicating that the methodology introduced by the paper can significantly improve performance relative to the baseline.

Weaknesses:
* The paper does not sufficiently explain why Rep-ViT is favored over TinyViT when both are smaller ViT variants with similar sizes (Rep-MedSAM params: 10.57 M, LiteMedSAM: 9.66 M).
* The rationale for why excluding 80% of the CT dataset could contribute to training set diversity during pretraining distillation is not well-explained.
* The term “pipeline training” is not explained within the context of this paper. This stage appears to take a significant proportion of the overall training time compared to other stages; however, the focus remains on the pretraining distillation. Additionally, what distinguishes pipeline training from finetuning? Were any modules frozen during finetuning?
* While the paper highlights improved inference speed with the reparameterization technique of Rep-ViT in the result section, it does not address whether this technique affects the segmentation performance in terms of DSC and NSD scores on the challenge's tasks. Including an ablation study on this aspect could strengthen the paper.
* In Figure 3’s caption, it should be “qualitative results” instead of “quantitative results.” Additionally, including the baseline’s visualized segmentation results in the comparison would provide a clearer benchmark for evaluating improvements.
* Typo: In the first paragraph of Introduction, it should be “after which we fine-tune the whole pipeline.”",1
362,"The paper is about proving (both upper and lower) error bounds for the optimal decision rule in the binary independent case when sensitivity and specificity are not the same. The authors provide three bounds, an expression for the error in terms of TV distance (Thm 1), and then an upper (Thm 2) and a lower (Thm 3) bound of the same expression. 

The results look correct to me, and the paper is well written. 

Let me also add that I am a bit surprised to hear that such results are original. I am not on top of this specific literature, but how do these results compare to standard lower bound approaches, e.g., Le Cam ?",1
363,"### Summary
A Mixture of Neural Operators (MoNO) is introduced that trains multiple Neural Operators, each of them learning to predict a target frame $x_{t+1}$ on basis of a particular frame from the past. A gating network decides on the weighting of each Neural Operator's contribution to the final solution. This approach allows the explicit incorporation of multiple historic frames to base a prediction of the next frame.

### Strenghts
- Appealing idea that tackles a relevant problem in temporal dynamics forecasting.
- Clear problem statement and paper organization.
- Proper experimentation supports the claims.

### Weaknesses
- Training/inference time and memory trade-off between single vs multi NODE model would be informative to assess the applicability of the introduced method.
- The statement ""This leads the neural operator to focus on modeling second-order deteriorating rollout performance"" needs some verification (referencing prior work or experimental results).
- Can you show some empirical results to underline your statement ""This design encourages a cooperative interaction among the neural operators, where adjustments in operator’s parameters induce compensatory adaptations across the ensemble, ensuring a cohesive towards minimizing residual prediction errors.""? It would be great to see what actually happens in the background, i.e., how $R_{\theta}$ adjusts its weights, or whether a single Neural Operator basically dominates all contributions to a prediction.

### Questions
- How would you expect your method to compare to multi-step forecasting methods, where a single model is trained to predict multiple forecast horizons, such as described in **Dynamics Forecasting** paragraph in Section 4 of [[1]](https://arxiv.org/abs/2306.01984)?
- Have you tried to play with the inputs of the gating network $R_{\theta}$? I'm wondering, whether $R_{\theta}$ would benefit from receiving the respective outputs of the individual Neural Operators.

### Minor Comments
- Around the middle of page two, a reference seems to be missing (""See ?? for further details."").

### References
[1] https://arxiv.org/abs/2306.01984",1
364,"## Summary
This paper proposes to merge kernel methods with DNNs with applications to solving PDEs. In particular, they propose Corrective Residuals (CoRes). 

## Strengths
- Nice theoretical analysis and guarantees of the proposed method
- Clear overview of SciML methods in the intro and references
- Nice experimental results on broad set of canonical PDEs including the hyperbolic Burgers and Eikonal equation.
- The paper is well-written.
- Very important that the proposed methods satisfies the BCs/IC as the number of sampled
boundary points increases and is independent of the domain geometry and the potential noise corrupting the data. Typically this is ignored in many ML approaches, so it is nice to see the authors include it with theoretical proofs.
- Very detailed appendix

## Weaknesses
- Please provide reference to the first sentence of sentence 3 that kernel methods such as GPs have less extrapolation and scalability powers compared to deep NNs.
- Baselines: I think kernel based Neural Operator methods, e.g., FNO (Li et al., 2020) and Multi-wavelet Neural Operator (Gupta et al., 2021) should be compared to as well since these methods also use a kernel approach within DNNs rather than just comparing to GPs and PINNs",1
365,"This paper presents a significant study focusing on the lexical characteristics of the healthy aging population using natural speech datasets and psycholinguistic metrics. The results reveal that parts of speech distribution vary with gender, while lexical concreteness correlates with age, contributing valuable information to the understanding of language variation in aging. The following points could be considered:
1. It would be beneficial to include a comparison with existing studies on younger populations or those with cognitive impairments.
2. Given that the study is based on Singaporean English speakers, how do you anticipate the findings to generalize to other English-speaking populations or languages?
3. How were the audio recordings standardized across participants to minimize environmental and technical variations?",1
366,"I was involved in the reviewing of a previous iteration of this paper. There were correctness concerns before, which (as far as I can tell) have now been mitigated in the current submission.

This paper is concerned with the evaluation of the $k$-out-of-$n$ threshold function, under the model where each input bit can only be queried noisily. Specifically, the model assumes that each input bit query is i.i.d., and modeled by a Bernoulli coin with bias $p$, with the same bias $p$ across all the bits. The paper gives matching upper and lower bounds up to a $1+o(1)$ factor in query complexity in the regime where both $k = o(n)$ (and symmetrically $n-k = o(n)$) and $\delta = o_n(1)$, and bounds that match up to a factor of 2 for general $k$.

Both the upper and lower bounds are tackled by case analyses depending on the value of $k$ (though the regime splits are different for the upper and lower bounds). The lower bound was proven by a combination of the two-point method and a genie-aided-algorithm argument. The upper bound was given by two algorithms in two different regimes. One minor comment is that I wish the authors would explain why the regime split in the upper bound is exactly at that point. Currently the algorithm descriptions in Section 4 are a little bit prescriptive and not as well-motivated as the lower bound.

Overall, I think the paper uses an interesting combination of techniques (even if many are existing techniques, but the uses are interesting, e.g. the MaxHeapThreshold use after filtering a lot of bits), and the result itself is significant in that it tackles and yields substantial progress on the sharp constant question. Given that (for me) there are no longer any correctness concerns, I advocate for accepting the paper.",1
367,"This paper derives generalisation bounds for deep neural networks using the fact that weight matrices exhibit low-rank bias, and utilising a novel approach based on Gaussian complexity as the mathematical toolkit. In particular, the authors derive the Gaussian complexity of rank-constrained deep Lipschitz networks and use it to derive a generalisation bound. The bound is then compared to existing norm-based bounds (typically based on Rademacher complexity) and the rates are better/on par. Using this bound, they are able to show that neural collapse in the intermediate layers may be favourable in terms of generalisation. 

Using low-rank bias and neural collapse to improve complexity-based generalisation bounds is, to my knowledge, a novel research direction and it is definitely interesting as it is in line with the current understanding of how neural networks perform. Gaussian complexity also seems like a promising new mathematical toolkit to derive generalisation bounds.

Strengths:
- The low-rank bias in generalisation bounds is underexploited and this is one of the first results in this direction.
-Gaussian complexity as a tool to derive generalisation bounds is also underexploited, and the paper is able to derive rates on par with/better than existing toolkits with this new approach.

Weaknesses:
- There is a new factor $C_1^L$ which appears in the generalisation bounds, which is not present in norm-based bounds (but the rates with respect to other quantities, the depth L and the maximum rank r, are better than these bounds).
- The bounds are not algorithm-dependent whereas low-rank bias is algorithm-dependent (but this is a shortcoming of all complexity-based bounds not only Gaussian complexity).

Questions:
-In the paper you say that you believe that the factor $C^L_1$ is an artifact of the proof and can possibly be dropped. Could you provide more intuition or explain in more details how you think the factor can be dropped?",1
368,"The paper provides new lower bounds for gradient descent as well as stochastic gradient descent through a nontrivial modification of the Feldman construction. The results are crisply stated. The contributions are meaningful and the proof techniques are non-trivial extensions of previous lower bound constructions. The memorization trick for the gradient descent so that the descent step finds the bad solution u_0 is specially interested. 

Some parts of the introduction could use more background to link the classical results with the modern ones. For example, the discussion about the uniform convergence bounds and the sudden shift to the discussion about the modern regimes which the authors call “practical” is a bit too much of a jump unless the reader is already familiar with these settings. I would suggest adding more context about how the uniform convergence settings can be too restrictive to be applicable in practical machine learning. Similarly there is no discussion of the Koren 2022 result, it is mentioned directly as one of the contributions saying the authors achieve improvement in dimension dependence of the “empirical risk” (quotes mine, but the authors use italics without explaining what it is and how it is difference from the generalization error that they have been discussing in the rest of the introduction). Further down the sentence about failure of uniform convergence and lack of stability in GD vs SGD is too vague. 

Section 3.1 needs a re-write. What is the optimization problem? Is it min of h over all w in U? what is V in eq 6? How is the probability of any u \in U being = V_i for any i equal to 0.5? I had to read the Feldman paper to understand the construction. 

Do the proposed constructions, especially for the SGD setup, extend of any first order method? 

Disclaimer: I have not gone through all the proofs given the short review time.",1
369,"The authors proved results of PAC bounds by keeping the gradients of the loss function in mind. In particular, given that the of the loss functions have ''well-formed'' gradients (i.e. obeying Sobolev inequality) 
	and has gradient decaying to 0 near the origin (flatness), 
	this PAC bound could potentially give a ''fast'' $\frac{1}{m}$ rate (in a ''flat'' scenario), as opposed to the ''slow'' $\sqrt{\frac{1}{m}}$ rate (typically achieved by generalists). 
	This seems to be an important contribution and could be of theoretical interest. 
	On the other hand, a quick lookup on the following handout https://arxiv.org/pdf/2110.11216
	(which in my opinion the authors should cite given that it gives a very good overview to PAC-Bayes bound) suggests that this is not the first time a $\frac{1}{m}$ bound can be achieved. 
	Some examples (as per the handout) : 

- The noiseless regime where $\mathbb{E}_{\theta\in\rho} [r(\theta)] = 0$ (using Theorem 3.4 as per the handout); 
		
- More generally the Bernstein condition assumption (c.f. Section 4.2 of this handout). 

Given this, I suggest that the authors look into these regimes and argue the novelty of their work as compared to these past results. 
	
One other drawback from what I understand of this paper is that, it is not clear to me when does the ``flatness'' assumption hold? 
	In addition, for the additional assumption needed for $\ell$ in Gibbs prior, are these assumptions generally applicable? 
	To address this, I suggest the authors to characterize 1-2 examples (writing as a lemma) where the gradient vanishes, 
	as well as distributions that satisfy such Poincare inequality. 
	Without such examples it is hard to gauge how applicable are these assumptions (and therefore harder to gauge contribution). 
	
An example (I would imagine) is when neural nets training reaches a local minimum. 
	It is probably useful to cite or establish some results on the flatness degree achieved in terms of number of samples and number of steps.

--------
Edit: the questions I raised turned out to have already been addressed by the author in the first draft, so I am going to change my rating.",1
370,"Existing neural fields architecture for PDE solving lack components that preserve symmetries in data. And this work introduces an SE(n) equivariant approach to augment CNeFs with geometric properties such as roto-translation.

**Strengths**:
- generalization to geometric transformations of ICs
- learning equivariant latent evolution
- Roto-Translation in the latent space

**Weaknesses**:
- Limited set of experiments.
- No separate validation set. Hence the model might have been tuned on the test set.

**Questions**:
- How was the 50% and 5% observed points selected?
- How to decide which PDEs possess SE(n) symmetries?
- How to choose the optimal number of latents?

**Suggestions for improvement**:
- The importance of steerability on high dimensional PDEs can be emphasized.",1
371,"Pros:
---
- The writing is clear and the paper is well-structured.
- The idea presented is novel, leveraging both sparse input and sparse models in the distributed training setting to further enhance efficiency.
- The experiments are sufficient.

Cons/Other Comments:
---
- I'm curious to know: if we sparsify and train the entire network instead of using a pre-trained ViT as feature extractors, will the proposed method still be effective?
- Perhaps I overlooked something, but I'm unclear on how to choose the fixed mask.
- With only 25% of parameters in a 4-worker setting, there appears to be a significant performance drop.
- It would strengthen the argument if the authors could provide actual training times in the distributed setting with varying worker counts.",1
372,"## General comments
The paper introduces enhancements to Fourier Neural Operators, incorporating
group convolution and channel shuffling, aiming for improved efficiency and
accuracy in solving partial differential equations. The approach is evaluated
through benchmarks, showing significant performance enhancements. The
methodology combines theoretical foundations with empirical validation. The
document is structured to clearly outline the contributions, facilitating
understanding among readers with interests in scientific computing and data-
driven modeling.
The work is ready for publication, offering valuable insights and advancements
without the need for further modifications.",1
373,"This work details a PINN for modeling calcium dynamics, with application to Transcranial Magnetic Stimulation (TMS). The work is exploratory in nature and mentions that the goal is to extend the work to full neuron model and to simulations that extend over several minutes.

I know little about TMS, but I can appreciate the effort it appears to have taken to construct this PINN. 

Some experimental details are unclear, particularly with respect to the training/val/test data splits. It looks like the PINN is trained and tested on the same temporal range `t=[0,1]`, and I would have expected to see some results where it was trained on, say, `t=[0,0.8)` and tested on `t=[0.80,1]`. The results in Figure 2 and Figure 3 look great! However, the current test split likely isn't challenging enough to inform about how well this model will generalize in practice. An ablation study to quantify the improvement gained by using the `sin` activation function instead of `tanh` is missing as well.",1
374,"In reviewing this manuscript, it is clear the authors can intellectually articulate the focus of their study. They were able to explain the rationale of their research as well as their results. 

I would encourage the authors to discuss the results of their RBD model in the abstract.” At present, the abstract states their ""LM-based approach outperforms traditional machine learning methods"" but does not state any results.

Overall, I believe this is a strong work from the authors.",1
375,"This paper proposes a RL-based approach to fine tune a relatively small LM with limited samples (~1000) to outperform the SOTA  for the task of text-to-sql. The paper was well written and the experiment and preliminary results seem to be good. 

Here are some strengths of this paper: 
1. Relevance of this paper’s topic is high: The paper picks a relatively difficult problem: text-to-SQL, which has big impact if such task can be solved to the accuracy of human-level performance (accuracy for SQL engineers is more than 93% according to IBM text-to-SQL generator study). It is of great interest to many industry practitioners as well.
2. Applying a modified EUREKA PPO algorithm for reward function generation: this paper uses the EUREKA PPO with multiple trials on the same sample to generate reward function. EUREKA is a gradient-free, evolution search-based algorithm, which performs well without any reward templates etc. 
3. Evaluation of the experiments is good: this paper uses 1 LLM for reward function generation, and then uses another smaller LLM for fine tuning using the reward function generated by the previous step . These two steps then iterate until reaching some stopping criteria. The results seem solid, although improvement comparing with the previously published results is not that significant, but still reasonably better!

Some weakness of this paper:
1. Better clarity of presentation: The paper refers EUREKA at the introduction section and the SQL environment setup, but did not mention EUREKA any more in the experiments section when it describes the PPO . It would be better to describe how the EUREKA configuration is different from the PPO reference it cites. Also, it would be better to describe EUREKA and PPO in the background/introduction section together and then compare if they would use one vs another in a more clear way.
2. Choices of LLMs to the impact of the approaches: since this paper only uses 1 LLM llama-3-405b-instruct for reward generation and 1 LLM flan-t5-base for fine tuning using the generated reward function, it is not clear whether the choices of LLM will matter. In particular, the latest OpenAI GPT-4o vs. other SOTA code optimized pertained LLMs are not being evaluated . The baseline model chosen for fine tuning is also not necessarily representative and it is not clear. So it is not clear whether the choice of these LLMs in this paper is arbitrary, hence it is hard to tell whether the RL approach is really impactful enough if some other LLMs are used.
3. Choices of sample size for fine tuning is not well justified: while the paper tries to suggest that they use a small size of samples (1000 samples) , it is not clear how they come up this size. I would like to see some scaling experiments where they can change the size of fine tuning samples from some smaller samples and then scale to larger size: for example, from 100 samples, to 500, 1000, 5000, 10,000, etc, to see the impact of the size of the samples on the final performance of the SQL generation fine-tuned model. 
4. DPO vs. PPO choice: it would be interesting to see if the paper can also address if DPO is applicable for this use case, where human preference can be directly optimized/fine tuned. That will change the approach but it is worthy clarifying , at least in the background section.

Overall, this paper seems to have some good ideas and experiments with a few weaknesses, but it is good enough for the workshop to accept this for presentation and discussion.",1
376,"**Abstract and Introduction**

The paper introduces DOR3D-Net, a novel architecture focusing on 3D hand pose estimation using a combination of dense ordinal regression and joint regression loss. The premise is based on overcoming the high computational costs and inaccuracies associated with earlier dense regression methods by utilizing binary classifiers for depth estimation.

**Technical Soundness and Innovation**

The technical framework is solid, leveraging the strengths of transformers for feature extraction and introducing a novel DOR module for 3D localization. This dual approach is innovative in its handling of depth estimation, addressing the significant challenge of precision in 3D pose estimation tasks. However, as noted below, the idea of using ordinal regression is not entirely novel, echoing techniques used in full-body pose estimation tasks as indicated by references to similar works. 

**Critical Observations**

- Although the results are promising, the paper would benefit from a deeper exploration into the failures or limitations of the proposed method, especially under challenging conditions such as extreme occlusions or very rapid hand movements.
- The computational efficiency, although addressed, might still be a concern for real-time applications, as transformers are generally more computationally intensive. Exact comparisons in terms of inference time against other methods under similar hardware conditions would add more depth.

**Pros and Cons**
- **Pros:**
  - The innovative combination of joint and ordinal regression losses enhances model performance and robustness.
  - The method achieves state-of-the-art results, which are well-supported by extensive experiments and comparisons.
  
- **Cons:**
  - The novelty is somewhat diluted by the similarity in approach to existing methods in related fields, which could be a point of contention regarding the claimed contributions.
  - The paper does not address the limitations related to occlusions thoroughly, which are critical in real-world applications of hand pose estimation.

**Discussion and Questions**

The discussion around the pipeline's close resemblance to the original Swin Transformer and the modifications in stage-3 could have been more detailed, offering deeper insights into the choices that led to these design decisions. The absence of a follow-up on handling occlusions, as noted in the review, also leaves a gap in the discussion that could be crucial for practical applications.

It would be beneficial to test the model in real-world scenarios, possibly integrating it with real-time video input to evaluate performance dynamically. Expanding the discussion on the model's limitations by analyzing more thoroughly the conditions under which it fails could guide future improvements.

**Conclusion**

Overall, the paper presents a well-thought-out approach to tackling the problem of 3D hand pose estimation, introducing a robust method to handle the complexities associated with depth data. Despite the challenges in novelty and handling occlusions, the results are compelling, though some areas may require further exploration and validation in real-world conditions.",1
377,"The paper presents an innovative use of Gauge Equivariant Convolutional Neural Networks (L-CNNs) for determining Fixed Point actions within SU(3) gauge theory, addressing critical computational challenges in nuclear physics simulations. This method not only preserves gauge symmetry but also showcases a more efficient parametrization than traditional approaches, marking a significant step forward in the field.

This work provides a novel application of Gauge Equivariant Convolutional Neural Networks (L-CNN), demonstrating a more efficient parametrization of Fixed Point actions. The paper provides an in depth investigation of L-CNNs for the chosen task and, while the results expectedly show that the bigger the network the better it works, it is an appreciated exploration.

It would have been interesting to also have a comment on the generalizability of the model, together with the challenges of implementing the model for such a specific task and how would this hinder future explorations. 

Despite these areas for potential expansion, the paper is well-composed and the research meticulously conducted. Its contributions to computational physics are clear, and it stands to inspire further innovation. I recommend acceptance.",1
378,"This work has no major difference than the baseline.

As in https://github.com/bowang-lab/MedSAM/blob/LiteMedSAM/
the baseline is already using the distilled TinyVit model from the original Vit.

The image encoder, prompt encoder and mask decoder are all the same with baseline.

Only improvements are made on data augmentations, data sampling and model quantification, which are marginal in innovations.
Besides, model quantification is not explained in details.

Speed seems to be similar as in baseline, and no average speed is provided.",-1
379,"Authors propose CHAos-RObust-Transformers, an attention based memory architecture which augments actor-critic reinforcement learning algorithms for controlling chaotic PDEs using only partial observations.",1
380,"The paper considers the problem of human-AI collaboration in solving Rubik's cube. The idea is to enhance assisted RL by first learning the reward functions from trajectories (IRL). The results demonstrate that the resulting system is able to get close to human behavior. 

The paper is interesting in that it solves a challenging problem with an intuitive solution. The results look good.

The relevance of the paper to mathematical discovery and neural models is unclear. There are no algorithmic contributions as it is a methodological paper (which I do not hold against the paper). Since there are no fundamental research contributions, it becomes harder to evaluate its relevance to the workshop.",-1
381,"#### The approach involves a sophisticated hierarchical model that synthesizes high-resolution 3D medical volumes from textual descriptions found in radiology reports. This process is segmented into several core components, emphasizing the integration of a pre-trained text-encoder (Medical BERT) for linguistic feature extraction, a text-guided low-resolution 3D diffusion model for initial volume synthesis, and a super-resolution 3D diffusion model for enhancing detail and anatomical accuracy.


### Strength 
#### 1. the paper utilizes a hierarchical diffusion model that begins with low-resolution image synthesis, advancing to detailed high-resolution outputs. This methodology ensures both the efficiency of computation and the integrity of generated volumetric data.

#### 2. By incorporating Medical BERT for text feature extraction, the model effectively leverages deep learning advancements in NLP to understand complex medical terminology and descriptions, enriching the synthesis process.

#### 3. The inclusion of segmentation masks for core anatomical structures (lung lobes, airway, vessels) within the synthesis process significantly enhances the anatomical plausibility and detail of the generated images, setting a new standard for medical image generation fidelity.

### Weakness 

#### 1. The model's performance is directly tied to the quality and detail of the input radiology reports. In scenarios where such reports are lacking in detail or contain inaccuracies, the system's ability to generate precise and anatomically accurate images may be compromised.

#### 2. Despite efforts to manage memory use efficiently, the model's advanced capabilities and the need for high-resolution outputs inherently demand considerable computational resources, which may limit accessibility for some research and clinical settings.

### Questions: 
#### 1. Could you elaborate on the steps you've taken to simplify the implementation of your hierarchical model for users without a deep technical background in AI or medical imaging?

#### 2. How does the model handle variations in the quality of textual descriptions in radiology reports? Are there mechanisms in place to ensure the reliability of image synthesis when faced with ambiguous or incomplete textual data?

#### 3. The paper focuses on lung CT images. Can the methodology be adapted for other types of medical imaging or conditions? If so, what modifications would be necessary?

#### 4. Could you discuss any measures taken to address potential biases in the datasets used for training the model? Additionally, how do you ensure the model's robustness across diverse patient demographics?",1
382,"An interesting benchmark  with good reproducibility.  Clear explanation and well written demonstrating how LLMS can be used to detect instances of race-based medicine.

Pros - Potentially an interesting read for a clinical audience who would like to know the feasibility of having such a model being run 'in clinical practise'.

Cons - This style of paper is very common (prompt crafting + evaluation) and can be criticised as not contributing anything novel to the field.",-1
383,"This paper presents a pruning methodology which yields speed-ups of sparse neural networks in both forward and backward passes. The key intuition comes from how forward / backward passes are calculated in GEMM. As I understand it, the method prunes weights at the level of a single weight kernel, as indexed by input AND output channel. This guarantees that sparsity can be exploited to accelerate both forward and backward passes. This idea seems quite intuitive and simple. The results section shows that this pruning approach yields speed-ups on par with structured (channel-wise) pruning while exhibiting the accuracy of unstructured pruning. Authors also show results for dynamic sparsity training, which is an added plus. I rate this paper quite highly, as it shows real speed-ups on real hardware used by a large number of practitioners / researchers today.",1
384,"The authors have convinced me that USD is worth investigating for data storage, when AI/ML operations over 3DPC images is being done.  Their ""NSC"" is apparently a useful way to convert between 3DPC and NS representations.  No concern is given to processing time, suggesting that the ground-truth-preserving and cost-optimized results of NSC are of high enough value in themselves to ignore such overhead initially.  The same is true for the particulars of the NSC method--they are not inevitable, and have cost, but the fact that the NSC includes iterations through an object library, allowing for transformations, seems to make NSC's versatility more prominent than its speed.


What I don't know yet:
* what, if any, selection procedure was used to yield the particular semantic segmenter they used, and/or its invocation parameters?
* what data storage savings are realized by using NS representations (in USD, in this case)?  I can easily infer that they must exist, but since the authors explicitly state that 3DPC representations are inefficient, I'd like to see a contrast.
* how does the computational overhead of using NSC's central algorithm compare with the computational overheads associated with voxel-based CNNs and graph-based approaches?
* what is it about USD that makes it, as opposed to other storage formats, especially suitable for this purpose?  Again, I can see that it probably is (due to extensibility and ecosystem), but all we're told is that USD is considered versatile and user-friendly in ""production houses"", and has ""high-performance capabilities"".  I infer that ""permits use of things like pointinstancer"" is one such capability, but again not explained.
* what drove their selection of USD rendering engine?  Which one was it?  If it didn't matter which one, I'd like to see that asserted.  
* what example AI/ML research workflow would this be a part of?

There are places where the paper's text flows poorly (below).  More importantly, while length limit can explain the persistence of my ""unknowns"" above, I think that (e.g.) USD could have been given more of an introduction at the sentence or paragraph level.  Also wanted to see some elaboration on the nature or quantity of the space/expressiveness ""efficiency gains"" that NS or USD representations offer.  Both of these things even within a space constraint.

If the paper had addressed those things, or had gone for the 8-page length and addressed items like my ""remaining unknowns"" more, and/or otherwise usefully lengthened the paper, I'd consider it an 'above threshold'.

Suggested text replacements (there might be another place or two where a pronoun doesn't match its referent in number):

Page 1:

* This lacks a verb:  ""Recent advancements in 3D computer vision, including enhanced semantic segmentation (Barbosa and Os´orio 2023), robust object pose estimation techniques (Zhu et al. 2022), and the integration of 3D vision into autonomous systems (Singh and Bankiti 2023).""
* ""Symbolic representations of data offer computational efficiency and storage benefits, making it an attractive choice for low-dimensional data. However, its limitations""
'representations' is plural, so should say 'making them an attractive choice' and 'their limitations'.
* ""USD is embraced...""  USD is not defined here, so I can tell it has nice features, but not what it is.

Page 2:

* (BTW Section 2 title contains the string ""Scens using USD"".  It should have ""Scenes"".)

* ""requires substituting part"" should say ""requires substituting parts"".

* ""related to the object in question"" should say ""related to the objects in question"".

* ""reconstruct symbolic representation of the object"" should say ""reconstruct symbolic representations of each object"".

* ""This research avenue holds the promise of seamlessly combining the advantages of compact 3D scene representation in this efficient data structure than point cloud.""  The word ""than"" leads me to look for two things being compared, but I don't see that happening here.

* ""These neuro-symbolic hybrid representations stored in USD formats...""  I think this is referring to data stored using the 'pointinstancer' schema.  The term 'hybrid' appears nowhere else in the paper--I'd like it to do so, or else not appear here.",-1
385,"The authors experimented with using LLM to detect whether LLM responses contain debunked race-based content. It's an important topic to explore and the results help us to better understand how current available LLMs may respond to race-based medical questions. 

13 questions were used to generate the responses from LLMs. It's unclear whether the set of the questions are representative enough for the study. 11 out of the 13 questions contained direct mentions of races in the question themselves, while 2 questions were fairly general. There is no comparison between the two to see if there is significant difference. Since direct mentions of the races may be more likely to generate race-based responses, the result responses set may have significant higher race-based responses compared to real life clinical uses cases, which may bias the evaluation results. 

The paper also didn't discuss on how the safe guard mechanism in proprietary and/or open source models may affect the model responses. In appendix, the author mentioned that MedPalm-2 simply rejects to answer some of the questions due to the content filter. This type of content filtering is a common practice and it may change constantly without any notice, especially for proprietary models, which puts a lot of uncertainty on the evaluation results.",1
386,"**Summary**

The paper studies SGD under the random reshuffling scheme for the linear regression problem. Concretely, the authors provide the limit of the iterate (average in every epoch) and study the generalization error. In addition, the authors also give some asymptotic analysis on the batching. In summary, I think the problem is worth studying since random reshuffling is commonly implemented in practice but with fewer theoretical studies.

**Major points**

In Eq. (B.2), should $\prod_{j:\tau(j)<\tau(b)}(I-\alpha W_{\tau (j)})X_b^\top \eta_b$ be $\prod_{j:j>\tau^{-1}(b)}(I-\alpha W_{\tau (j)})X_b^\top \eta_b$ or $\prod_{j:j>b}(I-\alpha W_{\tau (j)})X_{\tau(b)}^\top \eta_{\tau(b)}$? I can't see why the current form holds. Could the authors elaborate more on this equation? Even under the current form, the following derivation seems incorrect because the current $W_{\tau(j)}$ is also different from $W_{j}$ in Eq. (3.1).

Since the above issue is a fundamental step in the paper, I can't verify the subsequent proof in a further step. I would be happy to improve my score if the authors could provide a convincing explanation during the feedback period.

**Minor points**

1. Page 21, the third line in the proof of Theorem 2, the second $\beta_k^{(b)}$ should be $\beta_k^{(b-1)}$.

2. Though the paper focuses on the linear model with random reshuffling, many works considering the general case are missing, which I believe should be also added as the background. Here, I list some of them but not all. The authors should be more careful 

    - Gurbuzbalaban, Mert, Asu Ozdaglar, and Pablo A. Parrilo. ""Convergence rate of incremental gradient and incremental Newton methods."" SIAM Journal on Optimization 29.4 (2019): 2542-2565.

    - Haochen, Jeff, and Suvrit Sra. ""Random shuffling beats SGD after finite epochs."" International Conference on Machine Learning. PMLR, 2019.

    - Nguyen, Lam M., et al. ""A unified convergence analysis for shuffling-type gradient methods."" Journal of Machine Learning Research 22.207 (2021): 1-44.

    - Nagaraj, Dheeraj, Prateek Jain, and Praneeth Netrapalli. ""Sgd without replacement: Sharper rates for general smooth convex functions."" International Conference on Machine Learning. PMLR, 2019.",1
387,"Summary: The paper introduces an approach to enhance literature retrieval from PubMed for encephalitis-related research. The approach is based on a transformer-based embedding model that, given encephalitis-related queries, retrieves relevant PubMed literature. Unlike prior keyword-based searching systems, the proposed method is able to identify articles relevant to a query even when the exact keywords are absent from the query. To build the embedding model, the authors first created a dataset of thousands of query-document pairs. Specifically, they used ChatGPT to generate queries from the document as it has the ability to understand the variance of encephalitis representations and capture various semantics of the document.

Comments and suggestions:

1. Comparing the performance to that of a keyword-based searching system seems insufficient. Would it be possible to use a pre-trained, high-quality embedding model to perform this task? I believe recent advancements in retrieval-augmented generation (RAG) would provide useful techniques for this task.
2. How do we ensure that a general-purpose model like ChatGPT understands encephalitis literature, as I suppose it belongs to long-tail distribution?
3. The link for [1] is missing.
4. It is stated that the ""Biopython"" library is used. However, the ""Biopython"" library I know of is a biological sequencing tool (https://biopython.org/), which is not related to this paper.
5. The paper would benefit from a large-scale quantitative assessment of the model's performance. This addition would provide a clearer understanding of its efficacy compared to existing methods.
6. I think adding a graphical diagram would be beneficial to better outline the pipeline.",1
388,"**Summary:** This work proposes to utilize class hierarchy in different setups using symbol manipulation.

**Strengths:** 
- Thorough experimental evaluation.
- Clear presentation of the ideas.

**Weaknesses:**
- In some tasks, the gaps are comparable with baselines. Confidence measurement should be presented.",1
389,"Overall, the author proposes a novel algorithm for learning Average-Reward MDPs. Compared with previous work, the algorithm achieves a near-optimal regret guarantee without prior knowledge of the diameter or the uniform mixing time.

However, I have the following concerns about this work:

1. The definition of the Average-Reward MDP is complex and unclear. For instance, there is no formal definition provided for key terms such as the diameter and hitting time.

2. Although the proposed algorithm achieves a near-optimal regret, it is important to note that the algorithm relies on a generative model that provides the transition dynamics for arbitrary state-action pairs. When comparing this with previous work in Tables 1 and 2, it is necessary to indicate whether an algorithm uses a generative model to ensure a fair comparison.

3. In the Proof Sketch section, the author discusses the Bernstein-type concentration analysis for the proposed algorithm, which is the key part in achieving near-optimal regret. However, another important contribution of this work is that it is parameter-free. It would be beneficial to include further discussion on how the algorithm removes the requirement for prior knowledge of the diameter while maintaining optimal performance.

4. The claim in the introduction that ""finite sample properties of average-reward plug-in approaches have never been theoretically examined"" seems too restrictive. As shown by the author in the table, several algorithms have already achieved finite sample complexity.",1
390,"DeepONet is a framework for operator learning that learns a basis of functions from data and represents functions as linear combinations of the bases. Both the basis functions and the network that predicts the coefficients of the linear combination are learned jointly. Following recent work (POD-DeepONet, BasisONet), this paper proposes AutoBasisEncoder that separates these into two steps: learning the basis function using an autoencoding objective and the learning the coefficients. Empirical results show improved performance on Darcy flow equation and the Navier-Stokes equation datasets over DeepONet and the ability to interpolate over different resolutions of data.

### Strengths
- The paper is easy to follow (although some discussion on related work can be improved; see weaknesses).
- The proposed approach improves over DeepONet on two datasets, highlighting the the effectiveness of disentangling basis learning from coefficient learning.

### Weaknesses
- The proposed method is simplistic in nature and the empirical analysis is also limited. This makes the overall contribution marginal, especially in the context of works such as BasisONet.
- Discussion on related work needs improvement. In particular, the differences from POD-DeepONet and BasisONet need to be highlighted more to better position the work.

### Questions
- Why did the authors not compare with BasisONet given its similarity to the proposed method? 
- Why did the authors not use any interpolation techniques for POD-DeepONet in Table 2? Can they not be used?
- Why is POD-DeepONet missing from Fig. 3?",-1
391,"The paper introduces Neural Parameter Regression or NPR for operator learning. The idea of the paper is to encode the imposed initial condition into a latent space which is then mapped to the solution space via a secondary neural network. The latter NN additionally takes (x, t) as inputs and avoids trivial solutions by reparametrizing the output such that the model learns the deviation from the initial conditions. 

I believe the paper has a novel idea but it is not analyzed with sufficient depth. I can see the following main issues with the current state of their approach: (1) in high spatial dimensions, how would you handle the large encoding space (i.e., the method does not seem to scale well to cases where the initial condition is specified in 3D), (2) any version of the model considered in Table 1 has much more parameters than DeepONet so I am not confused about its higher performance (i.e., a fair comparison would assign roughly the same number of parameters to each model), (3) is the method able to handle local features (e.g., high frequency or large gradients)? The examples used are very simple. (4) the method is discretization dependents (due to discretization of u0) so perhaps you can use PCA to remove this limitation.",-1
392,"The strengths of the paper include its emphasis on high quality and clarity, showcasing SoftTiger's superior performance compared to established models like GPT-3.5. The clear articulation of objectives and addressing challenges in healthcare workflows adds to the paper's credibility.
The originality and significance of SoftTiger's approach in tackling critical subtasks within healthcare are commendable, contributing to its innovative standing. The acknowledgment of both the advanced capabilities and scalability of SoftTiger, with two configurations catering to different research needs, adds to its appeal.

However, the potential challenges or cons associated with SoftTiger, such as the risk of hallucination due to the statistical nature of language models and the dependency on the volume and quality of training data. Recognizing these limitations is essential for a comprehensive evaluation.",1
393,"Summary: This paper studies multi-class learning in the classic PAC setup which generalizes the more familiar binary classification setting. The authors investigate the role of proper learning strategies and their aggregations. Their main motivation for doing so is because it has long been known that very reasonable proper learning strategies (specifically \emph{any} empirical risk minimization (ERM) algorithm) are nearly optimal up to a logarithmic factor, and more recently it has been demonstrated that ""simple"" combinations of these strategies via majority vote classifiers learned on subsets of the full training sample can remove this log factor, and are hence optimal. The authors state that there are three main contributions in their paper:

1) The authors show that applying the aforementioned optimal majority voting on top of vanilla (multiclass) ERM also provides a way to achieve tighter and ``log free'' sample complexity bounds based on the Graph dimension, which is one of many generalizations of the VC dimension. This result is analogous to the binary classification setting as the Graph dimension is the notion that naturally allows one to obtain ERM learning guarantee (i.e. uniform convergence bounds) for multiclass learning.

2) The authors show that for any choice of graph dimension d, there is is a hypothesis class $\mathcal{H}_d$ with DS dimension 1 (hence learnable by a recent characterization of multiclass learnability) target function $h^\star$ and hard realizable distribution such that: (i) There is a bad choice of ERM algorithm that requires at least $\Omega(d\log(1/\epsilon)/\epsilon + \log(1/\delta)/\epsilon)$ samples to learn, mirroring the lower bound for ERM in the binary setting. Their construction is based on combining the usual hard class for multiclass learning called the ""Cantor class"" with a coupon collector argument. Previously, the only lower bound for such bad ERMs  did not have this log factor from below. (ii) Show that any majority voter based on this bad ERM algorithm that aggregates any arbitrary number of functions learned using this ERM algorithm on subsamples of the data must suffer error $\Omega(d/\epsilon + \log(1/\delta)/\epsilon)$. I believe this matches a comparable lower bound by Daniely and Shalev-Shwartz 2015 that holds for proper learners, though I don't believe the authors make this comparison, at least with reference to the graph dimension?

3) The authors study a more abstract notion of aggregating proper learners. Importantly, their notion of aggregation cannot always be expressed as majority votes. Their main result in this setting is showing that there are learnable function classes for which any learner must have infinite ``properness number"" which is the quantitative measure of how improper a learning algorithm is that the authors introduce.

In summary, their results improve our understanding of the failure modes of using proper learner as a fundamental building blocks in learning strategies employed in the multiclass setting.

The paper is very clear and the proofs are very easy to follow. It is good that the gaps in the sample complexity upper/lower bounds for the \emph{worst case} ERM have been resolved. In particular, it is very nice to see that the delicate combination of the classic coupon collector bound and the typical ``hard'' instance for ERM in the multiclass setting works out. Also, the authors more general result regarding more abstract aggregations of proper learners being bad learning strategies is interesting.

Regarding the upper bound detailed in contribution 1) above, it seems that up to some very minor technicalities, the proof is almost an immediate consequence of the results in the binary case. This is fine for the sake of comparing to the matching lower bound for majorities in contribution 2), but I am bit confused why this is phrased as a contribution on the level of the other main results?

The authors says ""It is natural to ask whether taking majorities of ERMs can help us learn classes that have infinite Graph dimension"". As the authors are aware, it is well known by now that for the worst case ERM, the sample complexity scales like $\Omega(d/\epsilon)$ (which the authors improved upon in contribution 2). Given that we we should view this majority voting as machinery built in order to shave off the log factor that stems from uniform convergence, I don't see why this would be a natural question to ask.
 
Finally, given the strong similarity to existing lower bound construction (e.g. Daniely et al. 2015 in your references) to both lower bounds, it would be nice to also compare and contrast the lower bound construction in contribution 3 to that of existing work that focused on proving lower bounds for proper learners (as was done for contribution 2).

Some very minor comments on presentation: 

in leamma 6, you may want to not use $y$ inside the probability $\mathbf{P}_{S \sim \mathcal{D}}[L_D > y]$ since it is confusing to also use it for labels. Also in the proof, whenever you use the upper bound when translating from majority vote failing to the average classifier failing, you use an equality rather than an inequality. 
In the proof of theorem 13 you use some notation for projection $\mathcal{F}|_S$ that I dont think was introduced?",1
394,"**Summary**

This paper studies online learning over a convex set K where the learner's goal is to minimize ""full swap regret"", that is, the difference between the learner's loss and that of the best arbitrary swap function mapping from K to K. The authors show different regret bounds under different conditions on the loss functions, using a general framework that applies the well-known Blum and Mansour's reduction (from swap regret to external regret) to a discretization of K. However, two new ideas are needed: 1) in the case with strongly convex loss function, it is important to let the external regret algorithm learn over K itself but not its discretization (in order to utilize the strong convexity), and 2) in all cases, a good combination of discretization scheme and rounding procedure (tailored to the loss structures) is required.

The paper also discusses two applications of their results on calibration. For traditional L2 calibration, they show that using their full swap regret result for strongly convex and smooth losses, one can achieve a T^{1/3} bound, improving the best known \sqrt{T} bound. Then, the authors also propose a discretized version of L2 calibration, where the predictions have to be a multiple of some \epsilon, and show how to achieve improved regret based on optimizing full swap regret over a piecewise linear approximation of the original strongly convex loss. This last result requires a new no-external-regret algorithm for nearly-strongly convex functions, which might be independent interest.

**Assessment**

The paper studies a very interesting and natural question. In fact, I believe that the result for the simplest case with only Lipschitzness assumption is a folklore, but going beyond this simplest case and showing that improvement is possible under different common assumptions on the loss functions is very neat. The technical ideas, while not very deep, are also very interesting and potentially useful for other problems in my opinion. The implication for both traditional L2 calibration and the proposed discretized version is somewhat surprising to me.

My two main complaints for the paper are:
1) There are no discussions at all for lower bounds in each case.
2) The paper needs a better organization and some polishing on writing. I listed a bunch of typos/mistakes below, but the key issue in my mind is that the main text does not contain sufficient concrete discussions of the proposed algorithms. 


**Questions**
1) Can the authors comment on lower bounds? I believe this is generally a very challenging question.
2) Algorithm 4: is it clear how to find the set K^\eps(x_\perp) efficiently?


**Minor comments**
1) References in the very first paragraph (and some other places) should be \citep instead of \citet.
2) Page 6, the \phi-regret paragraph: there is an extra Mansour et al. and Farina and Pipis.
3) Page 7, second paragraph: xt should be x_t.
4) Please formally define dist().
5) Definition 14: (R^d)^k should be R^k instead?
6) Eq. (1): I believe the definitions of H(x)[s_{i(x)}] and H(x)[s_{i(x)+1}] are swapped. 
7) Not sure why Lemma 15 is stated using \sum_t -- things should hold for each t.
8) Middle of Page 12: Lipschitz -> Lipschitz function
9) Def of learning rate above Thm 18: what is c?
10) Last line of the main text: Appendix B.2 should be B.3 actually.
11) For all pseudocodes: writing \ell_t for all t as the input of the algorithm is misleading (since they are revealed one by one).
12) Statement of Thm 10 is a bit confusing since Algorithm 2 doesn't use any rounding procedure explicitly. I suggest making this clearer.
13) Appendix E, ""We define our rounding procedure H as follows"": I assume you meant to put Algorithm 4 immediately after this, but currently it's on the next page, which is confusing.
14) First line of Proof of Lemma 12: \ell(s) should be just s I believe.
15) Page 24: Table E should be Table 2
16) Page 25: Table E should be Table 3",1
395,"**Explanation of paper** 

This paper introduces a method for solving 1D time-dependent PDEs which they call PDEformer. The unique (or at least unusual) feature of the PDEformer architecture is that it represents the PDE being solved via a computational graph (see graph construction, figure 1). The symbolic form of the PDE is thus an input to PDEformer, and by doing by PDEformer is able to solve multiple different classes of PDEs. The goal of the paper is to develop a “noteworthy milestone” towards a so-called foundation model for PDEs, which can *generalize* over many different types of PDEs. This is certainly a worthy goal and of interest to the workshop.

I have three primary concerns about this paper.

**Result in abstract is inconsistent with results in section 3**

The abstract states the following:
> Following pretraining on data exhibiting a certain level of diversity, our model achieves zero-shot accuracies on benchmark datasets that surpass those of adequately trained expert models.

Table 1 compares five models across six tests. The three expert models are U-Net, DeepONet, and FNO. These are compared to the zero-shot PDEformer and the fine-tuned PDEformer. Table 1 shows that, on four of the six tests, the zero-shot PDEformer model does worse than the expert models. It is incorrect to say that the model does better than expert models when it does worse on the majority of benchmark problems. The abstract of the paper should instead say

> Following pretraining on data exhibiting a certain level of diversity, our model performs worse than adequately trained expert models on most benchmark datasets.

The mistake in this case was that the result reported in the abstract ""[omitted] outcomes which are deemed to be unfavourable or statistically insignificant."" This is called [outcome reporting bias](https://catalogofbias.org/biases/outcome-reporting-bias/), a form of [reporting bias](https://catalogofbias.org/biases/reporting-biases/). Reporting biases are a form of scientific misconduct.


**Weak U-Net baseline in table 1**

Table 1 compares five models across six tests. A few days ago, I spent a couple hours going through the literature, looking at other papers that reported the relative L2 error (sometimes called the “percent error”). I don’t have time to go back through the papers that I found and cite them all, but I concluded that the FNO results in table 1 all seemed reasonable and consistent with the relative L2 error reported in previous papers. I think the FNO baseline is implemented correctly and is a strong baseline.

My concern about a possible weak baseline is with the U-Net. I couldn’t find U-Nets that had solved these benchmark PDEs, but I know that on other 1D and 2D benchmark PDEs (such as the Kuramoto-Sivashinsky equation, the incompressible Euler equation, etc) U-Nets were found to work better than FNOs at solving PDEs [2,3,4]. Thus, the terrible performance of U-Nets on every benchmark problem is surprising and suggests that the U-Nets were not implemented correctly and are a weak baseline.

I believe the reason that U-Nets achieved such unexpectedly poor performance was that they were not implemented as a 1D autoregressive model (see, for example, [4]) but as a full-solution model that outputs the entire 2D (space & time) solution all at once. For this reason, the U-Net baseline is almost certainly a weak baseline.

The input should have been a 1D 256-length array, and the output the solution or change in solution at the next timestep. Instead, the input was a 256x256 array, and the output was the solution over every timestep.

Given the results of [2,3,4] where autoregressive U-Nets outperform FNOs on 1D and 2D PDEs, I would expect the same would likely occur in table 1. It is quite possible that autoregressive U-Nets would outperform PDEformer on this problem.

**Failure to identify the sources of empirical gains**

Please read *Troubling trends in machine learning scholarship* [5].  [5] discusses four troubling trends, the first two of which are

> 1. Failure to distinguish between explanation and speculation.
> 2. Failure to identify the sources of empirical gains, e.g. emphasizing unnecessary modifications to neural architectures when gains actually stem from hyper-parameter tuning.

This paper makes two statements which purport to explain, but actually are speculating. I believe that both statements are incorrectly identifying the source of empirical gains, or at minimum failing to provide sufficient evidence for the source of empirical gains.


Statement #1:
> This superior performance stems from the pretrained PDEformer’s exposure to diverse PDEs during pretraining, from which the model learns a generalizable law to outperform models trained specifically for individual PDEs.

The paper fails to provide enough evidence to make this conclusion. PDEformer trains on 500k samples of diverse PDEs, then (in 2 out of 6 instances) outperforms expert models trained on 9k samples. Yet it is very much possible that the training on diverse PDEs is not the reason that PDEformer does better in those 2 instances. Perhaps the paper is emphasizing unnecessary modifications to training procedures when gains actually stem from an improved architecture. 

To test whether it is the training procedure or the architecture that causes these empirical gains, the PDEformer architecture trained only on the 9k samples should be compared to the other expert models trained only on the 9k samples. Performing such an ablation study would allow us to identify the source of empirical gains.

Statement #2:
> This contrast highlights PDEformer’s swift and accurate adaptability, marking a significant advancement over neural operators.

Again, the paper does not provide enough evidence to conclude that PDEformers are more adaptable than neural operators. If neural operators were trained on 500k samples with diverse PDEs, perhaps they too would be more capable of being trained on a small dataset with fewer iterations. It is possible that the neural network initializations, not something inherently better about PDEformer than neural operators, is the reason for the improved adaptability. Perhaps the paper is emphasizing unnecessary modifications to architectures when gains actually stem from improved initialization.

To test whether it is the architecture or the initialization that causes these empirical gains, instead of training an FNO from scratch, compare fine-tuning of a PDEformer to retraining an FNO originally trained for a different task.


**Additional comments:**
* Line 2: is “advocate” really the right word to use here? I don’t think so.
* ""By leveraging the power of generality …” What is the power of generality? Can you explain what it is and provide references?
* What does “adequately trained” mean? What does “sufficiently trained” mean? In figure 3, the train and test loss for the FNO are both still decreasing on a logarithmic scale. Shouldn’t they be trained longer?
* How do I know that the “patch nodes” are helpful? Are they? Can you perform an ablation study where you test with and without these patch nodes?


**Conclusion:** 

I am torn between recommending acceptance and recommending rejection. On the one hand, this paper introduces an interesting architecture that is likely of interest to the workshop. On the other hand, I have concerns about reporting bias in the abstract (a form of scientific misconduct), a weak baseline (potentially leading to inaccurate conclusions), and a set of conclusions which aren’t supported by the experiments performed in the paper.

My personal recommendation would be to reject this paper. While reporting bias is sadly quite common in ML research, just because scientific misconduct is common does not mean it should be tolerated. When papers attempt to blatantly mislead readers — doing worse than baselines, but claiming to do better — I think that is clear grounds for rejection.

I will ultimately leave it up to the editor to make the final decision.


[1] Zhuang, Jiawei, et al. ""Learned discretizations for passive scalar advection in a two-dimensional turbulent flow."" Physical Review Fluids 6.6 (2021): 064605.

[2] Stachenfeld, Kimberly, et al. ""Learned coarse models for efficient turbulence simulation."" arXiv preprint arXiv:2112.15275 (2021).

[3] Gupta, Jayesh K., and Johannes Brandstetter. ""Towards multi-spatiotemporal-scale generalized pde modeling."" arXiv preprint arXiv:2209.15616 (2022).

[4] Lippe, Phillip, et al. ""Pde-refiner: Achieving accurate long rollouts with neural pde solvers."" Advances in Neural Information Processing Systems 36 (2024).

[5] Lipton, Zachary C., and Jacob Steinhardt. ""Troubling trends in machine learning scholarship."" arXiv preprint arXiv:1807.03341 (2018).",-1
396,"# Summary
This work explores the use of diffusion models in the setting of controlled partial differential equation (PDE). In this setting, the goal is to minimize a control objective $\mathcal J (\mathbf u, \mathbf w)$ that is a function of both the trajectory of the system $\mathbf u$ and the external control signal $\mathbf w$. The dynamics of the trajectory $\mathbf u$ are governed by a PDE system that depends on the control signal $\mathbf w$ and initial and boundary conditions $\mathcal c$.

The authors propose that there is a generative model of $p(u, w \vert c)$. The negative log-density of this distribution is known as a parameterized energy-based model. The controlled PDE optimization problem can be recast as minimizing the negative log-density of $p(u, w \vert c)$ with $\mathcal J(u, w)$ as an added regularization term (Equation 5).

To solve the new optimization problem, the authors first train a diffusion model to learn $p(u, w \vert c)$. The key observation is that the original diffusion model presented in [1] yields an estimate of the gradient of $E_{\theta}$ at each step (resembling Langevin dynamics). With this observation, the authors modify the standard sampling step of a diffusion model to incorporate the gradient of the control objective $\mathcal J$. This leads to an optimization routine that targets the desired objective.

The authors also propose a scheme for minimizing the impact of choice of prior on the control sequences $p(w \vert c)$. This works by tempering the density of $p(w \vert c)^{\gamma}$ (I believe there was a typo in the text that I have corrected here). Similar to the $\beta$ parameter in the original diffusion paper, $\gamma$ also changes with each step of the diffusion. Specifically, $\gamma_{1} = 0.7$ and $\gamma_{K} = 1$, so the ""prior component"" of the target distribution becomes less diffuse in later steps of the diffusion.

The authors present results on a 2-d jellyfish control task in the main body. Their proposed method outperforms all other competing methods. The optimal strategy their method found was corroborated in other works as being an effective strategy for jellyfish movement.

# Review

Overall, with an interesting method and strong empirical results, this is a nice paper that should be a strong acceptance to the workshop. In fact, I believe this would be a good candidate for a spotlight paper, since it demonstrates a nice, effective use of deep learning to solve real challenges in numerical methods.

## Originality
This paper builds upon well-established diffusion models to facilitate controlled PDE optimization. [1] commented that the diffusion sampling process resembles Langevin dynamics and follows the gradient of the log probability density. This work exploits that fact by  modifying the diffusion sampling algorithm to incorporate the gradient of the control objective $\mathcal J$. To my knowledge, this is a new idea, though I am not deeply familiar with the diffusion model literature.

## Quality
The overall quality of the work is high for a workshop paper. The method is well-explained, and the empirical evaluation is comprehensive for a workshop paper. The empirical evaluation clearly demonstrates the effectiveness of the proposed method at an assigned task.

While the quality is high for a workshop paper, I have some remarks below that should be answered in a full paper.

1. The probability distribution of $u, w$ needs to be more carefully defined and characterized. The set $\{u: \mathcal C(u, w) = 0 \}$ will have Lebesgue measure 0 on the space where $u$ is defined ($[0, \mathcal{T}] \times \Omega$). As a result, the density of $p(u \vert w, c)$ is a point mass on this space. It does not seem that this has caused any practical issues in the current empirical setting. However, samples from the trained diffusion model almost certainly do not satisfy $\mathcal C(u, w)$, and this could pose problems in situations where the ground truth simulator is not available.

2. I would like to see more theoretical results about the convergence of the control optimization to a valid solution. From my comment above (1), the solution yielded by algorithm (1) will almost certainly not satisfy $C(u, w) = 0$. It would be beneficial to know the conditions under which the solution is arbitrarily close to satisfying $C(u, w) = 0$, even if these conditions are not met in practice. Knowing the failure modes of this methodology is important for knowing the limitations and addressing them in future work.

## Clarity
The writing is clear throughout. The visuals of the experiment are quite nice. A few concepts, such as the prior re-weighting scheme, required me to reference the appendix to get a full understanding. Specifically, in the main text, it is not made clear that $\gamma$ depends on the index $k$, similar to the parameter $\beta_{k}$. However, this is likely a consequence of the 4-page limit.

## Significance
This work provides a blueprint on how deep learning can solve real problems better than classical methods, which embodies the spirit of this workshop. I also believe that this approach could be useful in a broad range of applications, even beyond controlled PDES.

## General Feedback
Currently, you train the diffusion model to estimate $E_{\theta}$ by having it target the distribution with density proportional to $\exp(-E_{\theta}(u, w, c))$. What if, instead, you trained the diffusion model to target the distribution with density proportional to $\exp(-E_{\theta}(u, w, c) - \lambda \mathcal J(u, w))$? This will lead to more weight on samples with a lower $\mathcal J$.",1
397,"This paper proposes a variant of low rank adaptation method for SAM and MedSAM models to medical imaging tasks. 

Strengths
* The effectiveness of the adaptation on SAM is noteworthy, demonstrating significant improvements even without extensive pretraining or finetuning in the medical domain
* The clarity and comprehensiveness of the writing make the methodology, experiments, and results easily understandable
* The comparative analysis is included, benchmarking against current baselines and showcasing the proposed method's advantages clearly.

Weaknesses
* Considering LoRA is already a popular approach as a parameter efficient fine-tuning method, the novelty of method is limited.",1
398,"This paper studies online submodular maximization. In particular, it investigates the unconstrained maximization problem, when the underlying function is possibly non-monotone and the feedback received by the learner is bandit. More precisely, at each time step, the learner selects a subset $A_t$ of a $d$ element ground set, is awarded $f(A_t)$, and observes a noisy version of its gain, i.e. perturbed with additive subgaussian noise. Note, the image of $f$ is contained in $[0,c]$ for some $c$.

In the offline problem, it is known that no efficient algorithm can achieve a better-than-0.5 approximation ratio, thus in this paper the natural goal is to achieve sublinear $0.5$ regret. 
The contribution of the paper is two-fold:
- On the one hand, they construct the first algorithm with instance-dependent logarithmic regret
- On the other hand, their algorithm is also comparable (although slightly worse) to the state of the art in terms of instance-independent regret bounds. 

From the technical point of view, the algorithm is based on the double greedy algorithm by Buchbinder et al. 2012, but entails carefully adapting to the online nature of the problem. In particular, the analysis is non-trivial and interesting. 

On the negative side, no lower bound is provided. In particular, it is unclear whether the $T^{2/3}$ dependence on the worst-case regret is necessary. Furthermore, the novelty of the paper is partly hindered by the fact that an algorithm with a slightly better worst-case regret rate is already known (Fourati et al 2023). Finally, to put things in the right perspective, let me mention that the naive algorithm that simply subsample each element of the domain with probability $½$ already provides a $¼$ approximation to the offline problem. Therefore it is immediate to achieve $0$ $¼$-regret.

Overall this is a nice paper, that - in my opinion - clears the bar for ALT.",1
399,"This paper presents algorithms for learning and inference under a non-linear version of dictionary learning problems. The authors consider a one-dimensional model where localized atoms (of small support) can be placed on a larger canvas in different locations while occluding one another. This resembles the way objects are composed on an image, whereby foreground objects occlude those in the background. The authors consider different version of this model (with different degrees of randomization) and study greedy-like algorithms to learn a set of prototype objects (or atoms) as well as inferring their locations (or segmentation) in a given sample. The authors put forward a key assumption that they term ""well-structuredness"", which while weak allows them to provide correctness and convergence of the studied algorithms.

### Pros:

* This paper studies a non-linear version of sparse coding problems which, to my knowledge, has not been studied so far. 
* The analysis is rigorous, and the obtained results are nice and useful - i.e. certifying the correctness of the proposed algorithms in polynomial time under mild conditions.
* The paper is mostly well written and nice to read.

### Cons

* I think the text can be improved slightly without much effort by revising some parts. (see below)
* While not necessary and orthogonal to the presented results, it would have been nice to have at least some numerical demonstration on some of the problems referred to in the motivation.

### Questions and suggestions

* I find the definition of $w$-well-structured very interesting, which the authors relate to analogous quantities of coherence (popular in the sparse coding literature). This notion, however, is defined on a finite discrete space, and requires ""exact"" matching. Even their $\epsilon$-strong version requires that no objects have substrings that match (exactly) in $1-\epsilon$ fraction of their pixels. Generalizing these notions to sequences over real values, this implies and exact match (with zero error) between the subsequences (in a $1-\epsilon$ fraction of the pixels). I wonder if the authors could consider, or at least comment on, extensions to these continuous settings where one could allow a bounded error among substrings, given by a bounded $\ell_p$ norm. I'm tempted to infer that bounded $\ell_0$ ""norm"" is already the case considered here.

* On page 5, second paragraph: ""The object with the highest depth is placed in row k, .."". I don't think this object needs to be unique. Does this matter?

* The section 2.5 on sequencing methods is a nice introduction to the algorithms they propose later. However, they directly start talking about ""segments"" without defining them formally (unlike the previous formal definitions of objects, background, scene, etc). Thus, it's a bit unclear what the authors mean. This could be easily fixed by simply making this more precise.

* I'm a bit confused by Lemma 11, and the subsequent results. There, I see that the probability of an event of relevance (seeing a L-long segment of an object... ) is at least $(1- c_1)^{k-1} * c_2 * k/m$. However, if $d\approx d'$, and $k \ll m$, i don't see how this probability could be arbitrarily controlled. What am I missing? 
Related to this, in Theorems 12 and 14, could the authors present their results with a parametric form of the failure probability?

* On Section 4, the authors explain in words what the sparse coding problems is in this setting. Though, since this is the first work considering this problem formulation, it might be nice to actually flash it out analytically (e.g. minimizing the number of chosen atoms so that reconstruction is achieved)

* 

Minor: 

* The text might benefit from some slight revision; e.g. avoiding single-sentence paragraphs (like the two ones on the first page).
* $k<<$ -> $k\llm$ on page 2.
* First sentence in Assumptions section (page 3) might have a typo (or an extra ""there""?)
* In Section 2.3, point 5, i don't think the scene operator S has been defined yet.
* Text in Fig 1 is too small to be readable.
* Why are $\epsilon$ and $\alpha$ bolded on Page 12?
* Because the atoms that the authors consider have small support and can be placed on different places of the canvas, to me this looks more like a non-linear version of a *convolutional* dictionary learning problem - see e.g. [Papyan et al, ""Working locally thinking globally: Theoretical guarantees for convolutional sparse coding""]. The authors might want to comment on these similarities.",1
400,"The paper investigates the baseline language variations in normal aging to understand cognitive changes. It utilizes NLP tools and psycholinguistic metrics to analyze natural speech data, aiming to establish a normative benchmark for aging language, which could assist in assessing cognitive aging. 
Pros: The paper used NLP tools to objectively analyze natural speech data, overcoming the subjectivity in manual assessments of language abilities, besides, it provided a detailed year-by-year analysis of linguistic characteristics influenced by age and sex.
Cons: However, there are a few limitations to this study: it excludes individuals older than 80 years and those with less than 13 years of education, which could omit valuable insights from these groups. While the approach reduces subjectivity compared to manual assessments, the choice and interpretation of psycholinguistic metrics could still introduce bias.

Overall, the study presents a step forward in understanding language variation in aging.",1
401,"The paper titled ""Deep Leakage from Model Parameters in Federated Learning"" investigates the security vulnerabilities within the Federated Learning (FL) framework, primarily focusing on the potential data leakage when transmitting model parameters. The authors highlight the importance of FL in addressing data privacy concerns and the challenges posed by the explosive growth of data. The authors set the stage by mentioning the recent advancements in gradient leakage attacks, which have raised concerns about the security of FL. They emphasize the common requirement for auxiliary information in these attacks, such as model weights, optimizers, and hyperparameters, which can be challenging to obtain in practical scenarios. Furthermore, the paper raises concerns about the security of transmitting model weights in FL, a less explored area. To address these issues, the authors propose two novel attack frameworks, DLM and DLM+, which aim to expose the potential leakage of private client data when transmitting model weights. 

To reduce the number of trained variables, the authors propose to approximate learning rate with value of the weight difference of global model divided by gradients. Doing so can get rid of learning rate and gain better performance. Empirical results verify the effectiveness of proposed method. In addition, two defenses against the proposed attacks have been presented. 

Pros:

(1) The paper is written clearly and present the main idea and methodology in a very pleasant way. I can directly understand the main mechanism of data leakage after reading the paper once.

(2) The main idea is simple yet effective. A very straight-forward modification leads to significant improvement. I believe the simplicity is a pro rather than con in this case.

(3) Empirical results demonstrate the effectiveness of the proposed method clearly. 

(4) The proposed method enjoys appealing robustness to local iteration and optimizer as well.
Cons:

(1) While promising performance is demonstrated, I would like to see the efficiency comparison between DLM+ and DLG. Does the simple change leads to higher computational cost?",1
402,"The paper explored the application of LoRA fine-tuning of Mistral 7B Instruct to classify TNM staging from unstructured pathology reports for triple negative breast cancers. Several baselines and tuning strategies are compared on a real-world data task to demonstrate the proposed fine-tuning approach could achieve better accuracy using small amount of training data. 
- Quality: the paper is technically sound and of good quality. Most claims in the paper are well supported by experiment results. 
- Clarity: the paper is well-structured and clear in experiment process and results discussion, despite that the paper lacks clarity on the clinical knowledge of TNM  categories (pls refer to the suggestion #1 below). 
- Originality: the paper demonstrates an interesting application of well-established techniques to a specific clinical task. Though fine tuning  is not a novel idea, the application to the specific TNM staging seems to be novel from practical perspective. 
- Significance: the paper mentioned potential generalization possibility of the proposed approach other clinical tasks, given the low cost and high reliability with comparison to other large language models.
Cons, suggestions or questions to the authors:
1. It'll be better to include a brief introduction of TNM staging (e.g. T stands for size of tumor, etc.) at the beginning of the paper for non-clinical audience, and also why TNM staging of triple negative breast cancers is challenging and demands the help of ML modeling and application. It will also improve the significance of the work from the clinical application perspective.
2. The paper mentioned manual labeling from subject matter experts. Would you pls provide more information on 1) how many experts are involved, 2) whether each document was labeled by multiple experts and how the final label is determined (e.g. if there's any disagreement) . More importantly, could you pls comment how to ensure the reliability and robustness of the proposed fine tuning approach towards label noise in the training data?
3. In table 1, different fine-tuning results show increasing accuracy but decreasing in confidence for ""UNKNOWN"" class. Does it indicate over-fitting problem?",1
403,"This paper presents a simple boosting algorithm that could have improved performance relative to AdaBoost in some regimes. I think the most significant contribution/novelty of this work is the analysis, which uses sample compression and stability to obtain the results. 
Overall, the paper is  mostly well written and clear. 

One possible weakness of the work is that, as it is  pointed out, the algorithm of Larsen and Ritzert (2022) gives a better performance guarantee. It is also mentioned that these existing results are ""contrived"" because they produce a ""majority-of-majorities"" hypothesis at the end. This is framed as a motivation for the given algorithm
As a reader who is not  familiar with the algorithm of Larsen and Ritzert(2022), this justification is confusing. I think perhaps the authors could included a more detailed description of this previous work, especially the majority rule used.

- Should the comment in line 12 of the algorithm be majority vote rather than weighted majority vote?
- In the 8th paragraph of page 4, $\textbf{k} (S, n)$ is a random variable, but it is written ""subsequence S' of S in the support of $\textbf{k} (S, n)$"" which is confusing. I think the definition of the randomized compression scheme can be more clear.",1
404,"The authors have introduced a ML surrogate model for learning the Protein-ligand binding dynamics. The manuscript is well written with all the relevant details explicitly mentioned. 

I have few overall concerns in this topic, please address them below

1. ML surrogates are highly dependent on the dataset they are trained for. What exactly is the motivation here to develop ML surrogates here ?
2. Is there any real time computation of MD simulation that is really needed for warranting the development of ML surrogates 
2. ML surrogates are not extrapolative in nature and perform poorly on cases outside the dataset considered for train and testing. In such as case how do we account for such outliers in online computation.",1
405,"This paper studies compression in the context of learning theory. Compression refers to encoding a subset of examples along with a reconstruction bit-string, so that the hypothesis on the entire training set can be recovered using just the compressed information. The sample compression conjecture posits that any binary concept class with VC dimension d_VC can be compressed with a size of O(d_VC). While the conjecture remains a significant open problem in learning theory, this paper lays out a series of implications. These come in three categories: (1) Multiclass classification; (2) regression, and (3) adversarially robust classifications. All of the results are derived by reduction to the binary case from the conjecture, constructing a compression scheme by assuming the existence of a compression scheme for the binary setting.
The results are significant, and the paper is well-written.
Typos: 
(pg.6) ""we have that (x,z) = (x_i, y_i) for some i --> I think it should be (x,y)
(pg. 7) ""donclude""

It would be nice to include a discussion of other learning problems (if any) that may be reducible to the binary case. Also, do any of your results cast doubts on the conjecture? (i.e. if A is reduced to B but A cannot be compressed then B cannot be compressed.)",1
406,"This paper studies the problem of PAC list regression. For each of the agnostic and realizable settings, the authors propose a family of dimensions at different scales for hypothesis classes and establish upper and lower bounds on the PAC sample complexity in terms of those dimensions, which shows that a hypothesis class is list regression PAC learnable iff the dimension is finite at all scales. Examples are presented to demonstrate the separation of the proposed dimensions. 

The problem studied is fundamental in learning theory. The contribution on PAC learnability and sample complexity is original and significant. I appreciate the idea of reducing to multiclass learning via discretization used in Algorithm 1. The writing of the paper is clear with enough motivation and introduction to both the problem and the analysis. 

However, the upper bounds and lower bounds of the sample complexity are valid in different settings and therefore cannot be compared at a fixed scale $\gamma$. In agnostic setting, the sample complexity upper bound in Theorem 12 requires $\epsilon> k^{O(k)}\gamma$ while the lower bound in Theorem 26 requires $\epsilon\le \gamma/8(k+1)$. For fixed $\gamma$, the two requirements cannot be satisfied simultaneously even if $k$ is viewed as a constant. For $\epsilon\le \gamma/8(k+1)$, the term $k^{O(k)}\gamma$ in the derived error rate upper bound is lower bounded by $k^{O(k)}\epsilon>\epsilon$ for $k>1$, which makes it impossible to upper bound the sample complexity at $\epsilon$ using the error rate upper bound. 
Similarly in Theorem 40 and 43, the upper bound requires $\gamma=\Theta(\epsilon)$ while the lower bound requires $\gamma=\Theta(\sqrt{\epsilon})$. 
I understand that the claim on the learnability in Theorem 1 and 2 is correct, but the claim that the dependence of the sample complexity on the dimension is optimal needs more explanation as dimensions under different $\gamma$ appear in the upper and lower bounds.

For the presentation of the paper, I believe it would be better if the authors can include more technical overview for the realizable setting in the first 12 pages. I also recommend the authors to include the reference to the proposed dimensions in Theorem 1 and 2 as well as Section 2.1 for readers convenience and for a comparison to the existing dimensions. Besides, I would appreciate it if the authors could comment on the possibility or difficulty in improving the dependence on list size $k$ under the current analysis. 

Finally, there are some typos. 

(1) In page 2, the ""an"" in the sentence ""only an $\alpha$ fraction of the data is clean an the rest may be arbitrarily corrupted"" should be ""and"". 

(2) In Def. 4, $h(x_i)$ should be $h_b(x_i)$.

(3) In Def. 7 and 38, the outdeg should be defined to be the cardinality of the set given. 

(4) In line 8 of Algorithm 1, $h$ should be used instead of $h^\star$ when taking $\inf_{h\in \mathcal{H}}$.",1
407,"The manuscript titled ""A Novel ML Model for Numerical Simulations Leveraging Fourier Neural Operators"" describes the use of Fourier Neural Operators for simulations of reservoir management. The main claim of the paper is the development of a novel neural operator that parameterized the integral kernel directly in Fourier space. This does not seem to be correct since the formulation is exactly the same as Fourier Neural Operators in Li et. al. 2020. The main novelty in the paper seems to be application of FNO to this steam injection problem. This is also something that is very similar to previous work: Wen, Gege, et al. ""Accelerating carbon capture and storage modeling using fourier neural operators."" arXiv (2022) and Wen, Gege, et al. ""Real-time high-resolution CO 2 geological storage prediction using nested Fourier neural operators."" Energy & Environmental Science 16.4 (2023): 1732-1741. Due to the lack of significant novelty in the paper, I cannot recommend accepting it. Some more specific comments below:
- Section 1: ""There are also a handful of ML-based surrogate approaches proposed in the literature."" Cite these works here?
- Section 1: ""novel neural operator that parameterizes the integral kernel directly in Fourier space"" How is this different from the Fourier Neural Operator (Li et. al. 2020)?
- Eq 2: Each step is just a single FNO layer?
- Section 5: ""the ML model requires only the first 10 time steps of numerical simulation results and generates the results for the subsequent 40 time steps in an autoregressive manner."" In the previous section, it was mentioned that \nu_{i+1} is predicted based on only \nu_i. How is this history of 10 time steps used then?",-1
408,"The paper presents a commendable advancement in the domain of inverse problem-solving within nonlinear dynamical systems, integrating machine learning architectures and harnessing the computational power of GPU acceleration across both NVIDIA and AMD platforms. The proposed hybrid multi-start optimization strategy, which amalgamates Particle Swarm Optimization (PSO) and the Limited-memory Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) algorithms, is an innovative approach that seeks to capitalize on the strengths of both global search capabilities and efficient local convergence properties.

The combination of PSO and L-BFGS for parameter estimation in nonlinear dynamical systems is particularly noteworthy, as it addresses a significant challenge in the field: the presence of non-convex problems with multiple local minima that can impede the effectiveness of conventional optimization methods. By leveraging the global search potential of PSO to navigate the broader parameter space and employing L-BFGS for its rapid local convergence, your strategy demonstrates a robust solution to overcoming the limitations posed by complex loss landscapes.

The reported acceleration factor of up to 8−30× in convergence speed is impressive and indicates a substantial improvement over existing methods. This acceleration not only showcases the efficiency of your hybrid strategy but also highlights the practical benefits of GPU computing in significantly reducing computation times for complex optimization problems.",1
